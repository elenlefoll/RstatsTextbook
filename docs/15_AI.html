<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.8.25">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="author" content="Elen Le Foll">

<title>15&nbsp; What‚Äôs next? AI-assisted reseaRch? ‚Äì Data Analysis for the Language Sciences</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
html { -webkit-text-size-adjust: 100%; }
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
/* CSS for citations */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
  margin-bottom: 0em;
}
.hanging-indent div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}</style>


<script src="site_libs/quarto-nav/quarto-nav.js"></script>
<script src="site_libs/quarto-nav/headroom.min.js"></script>
<script src="site_libs/clipboard/clipboard.min.js"></script>
<script src="site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="site_libs/quarto-search/fuse.min.js"></script>
<script src="site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="./">
<link href="./99_references.html" rel="next">
<link href="./14_LiterateProgramming.html" rel="prev">
<script src="site_libs/quarto-html/quarto.js" type="module"></script>
<script src="site_libs/quarto-html/tabsets/tabsets.js" type="module"></script>
<script src="site_libs/quarto-html/axe/axe-check.js" type="module"></script>
<script src="site_libs/quarto-html/popper.min.js"></script>
<script src="site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="site_libs/quarto-html/anchor.min.js"></script>
<link href="site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="site_libs/quarto-html/quarto-syntax-highlighting-7b89279ff1a6dce999919e0e67d4d9ec.css" rel="stylesheet" class="quarto-color-scheme" id="quarto-text-highlighting-styles">
<link href="site_libs/quarto-html/quarto-syntax-highlighting-dark-707d8167ce6003fca903bfe2be84ab7f.css" rel="stylesheet" class="quarto-color-scheme quarto-color-alternate" id="quarto-text-highlighting-styles">
<link href="site_libs/quarto-html/quarto-syntax-highlighting-7b89279ff1a6dce999919e0e67d4d9ec.css" rel="stylesheet" class="quarto-color-scheme-extra" id="quarto-text-highlighting-styles">
<script src="site_libs/bootstrap/bootstrap.min.js"></script>
<link href="site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="site_libs/bootstrap/bootstrap-eb07a8a0a194634ea538c19163fd1f0e.min.css" rel="stylesheet" append-hash="true" class="quarto-color-scheme" id="quarto-bootstrap" data-mode="light">
<link href="site_libs/bootstrap/bootstrap-dark-2dc7341fb0871247097a223aafd3766b.min.css" rel="stylesheet" append-hash="true" class="quarto-color-scheme quarto-color-alternate" id="quarto-bootstrap" data-mode="dark">
<link href="site_libs/bootstrap/bootstrap-eb07a8a0a194634ea538c19163fd1f0e.min.css" rel="stylesheet" append-hash="true" class="quarto-color-scheme-extra" id="quarto-bootstrap" data-mode="light">
<link href="site_libs/quarto-contrib/line-highlight-1.0.0/line-highlight.css" rel="stylesheet">
<script src="site_libs/quarto-contrib/glightbox/glightbox.min.js"></script>
<link href="site_libs/quarto-contrib/glightbox/glightbox.min.css" rel="stylesheet">
<link href="site_libs/quarto-contrib/glightbox/lightbox.css" rel="stylesheet">
<script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>
<style>
.cell-output-stdout code {
  word-break: break-wor !important;
  white-space: pre-wrap !important;
}
</style>


<link rel="stylesheet" href="style.css">
</head>

<body class="nav-sidebar floating quarto-light"><script id="quarto-html-before-body" type="application/javascript">
    const toggleBodyColorMode = (bsSheetEl) => {
      const mode = bsSheetEl.getAttribute("data-mode");
      const bodyEl = window.document.querySelector("body");
      if (mode === "dark") {
        bodyEl.classList.add("quarto-dark");
        bodyEl.classList.remove("quarto-light");
      } else {
        bodyEl.classList.add("quarto-light");
        bodyEl.classList.remove("quarto-dark");
      }
    }
    const toggleBodyColorPrimary = () => {
      const bsSheetEl = window.document.querySelector("link#quarto-bootstrap:not([rel=disabled-stylesheet])");
      if (bsSheetEl) {
        toggleBodyColorMode(bsSheetEl);
      }
    }
    const setColorSchemeToggle = (alternate) => {
      const toggles = window.document.querySelectorAll('.quarto-color-scheme-toggle');
      for (let i=0; i < toggles.length; i++) {
        const toggle = toggles[i];
        if (toggle) {
          if (alternate) {
            toggle.classList.add("alternate");
          } else {
            toggle.classList.remove("alternate");
          }
        }
      }
    };
    const toggleColorMode = (alternate) => {
      // Switch the stylesheets
      const primaryStylesheets = window.document.querySelectorAll('link.quarto-color-scheme:not(.quarto-color-alternate)');
      const alternateStylesheets = window.document.querySelectorAll('link.quarto-color-scheme.quarto-color-alternate');
      manageTransitions('#quarto-margin-sidebar .nav-link', false);
      if (alternate) {
        // note: dark is layered on light, we don't disable primary!
        enableStylesheet(alternateStylesheets);
        for (const sheetNode of alternateStylesheets) {
          if (sheetNode.id === "quarto-bootstrap") {
            toggleBodyColorMode(sheetNode);
          }
        }
      } else {
        disableStylesheet(alternateStylesheets);
        enableStylesheet(primaryStylesheets)
        toggleBodyColorPrimary();
      }
      manageTransitions('#quarto-margin-sidebar .nav-link', true);
      // Switch the toggles
      setColorSchemeToggle(alternate)
      // Hack to workaround the fact that safari doesn't
      // properly recolor the scrollbar when toggling (#1455)
      if (navigator.userAgent.indexOf('Safari') > 0 && navigator.userAgent.indexOf('Chrome') == -1) {
        manageTransitions("body", false);
        window.scrollTo(0, 1);
        setTimeout(() => {
          window.scrollTo(0, 0);
          manageTransitions("body", true);
        }, 40);
      }
    }
    const disableStylesheet = (stylesheets) => {
      for (let i=0; i < stylesheets.length; i++) {
        const stylesheet = stylesheets[i];
        stylesheet.rel = 'disabled-stylesheet';
      }
    }
    const enableStylesheet = (stylesheets) => {
      for (let i=0; i < stylesheets.length; i++) {
        const stylesheet = stylesheets[i];
        if(stylesheet.rel !== 'stylesheet') { // for Chrome, which will still FOUC without this check
          stylesheet.rel = 'stylesheet';
        }
      }
    }
    const manageTransitions = (selector, allowTransitions) => {
      const els = window.document.querySelectorAll(selector);
      for (let i=0; i < els.length; i++) {
        const el = els[i];
        if (allowTransitions) {
          el.classList.remove('notransition');
        } else {
          el.classList.add('notransition');
        }
      }
    }
    const isFileUrl = () => {
      return window.location.protocol === 'file:';
    }
    const hasAlternateSentinel = () => {
      let styleSentinel = getColorSchemeSentinel();
      if (styleSentinel !== null) {
        return styleSentinel === "alternate";
      } else {
        return false;
      }
    }
    const setStyleSentinel = (alternate) => {
      const value = alternate ? "alternate" : "default";
      if (!isFileUrl()) {
        window.localStorage.setItem("quarto-color-scheme", value);
      } else {
        localAlternateSentinel = value;
      }
    }
    const getColorSchemeSentinel = () => {
      if (!isFileUrl()) {
        const storageValue = window.localStorage.getItem("quarto-color-scheme");
        return storageValue != null ? storageValue : localAlternateSentinel;
      } else {
        return localAlternateSentinel;
      }
    }
    const toggleGiscusIfUsed = (isAlternate, darkModeDefault) => {
      const baseTheme = document.querySelector('#giscus-base-theme')?.value ?? 'light';
      const alternateTheme = document.querySelector('#giscus-alt-theme')?.value ?? 'dark';
      let newTheme = '';
      if(authorPrefersDark) {
        newTheme = isAlternate ? baseTheme : alternateTheme;
      } else {
        newTheme = isAlternate ? alternateTheme : baseTheme;
      }
      const changeGiscusTheme = () => {
        // From: https://github.com/giscus/giscus/issues/336
        const sendMessage = (message) => {
          const iframe = document.querySelector('iframe.giscus-frame');
          if (!iframe) return;
          iframe.contentWindow.postMessage({ giscus: message }, 'https://giscus.app');
        }
        sendMessage({
          setConfig: {
            theme: newTheme
          }
        });
      }
      const isGiscussLoaded = window.document.querySelector('iframe.giscus-frame') !== null;
      if (isGiscussLoaded) {
        changeGiscusTheme();
      }
    };
    const authorPrefersDark = false;
    const darkModeDefault = authorPrefersDark;
      document.querySelector('link#quarto-text-highlighting-styles.quarto-color-scheme-extra').rel = 'disabled-stylesheet';
      document.querySelector('link#quarto-bootstrap.quarto-color-scheme-extra').rel = 'disabled-stylesheet';
    let localAlternateSentinel = darkModeDefault ? 'alternate' : 'default';
    // Dark / light mode switch
    window.quartoToggleColorScheme = () => {
      // Read the current dark / light value
      let toAlternate = !hasAlternateSentinel();
      toggleColorMode(toAlternate);
      setStyleSentinel(toAlternate);
      toggleGiscusIfUsed(toAlternate, darkModeDefault);
      window.dispatchEvent(new Event('resize'));
    };
    // Switch to dark mode if need be
    if (hasAlternateSentinel()) {
      toggleColorMode(true);
    } else {
      toggleColorMode(false);
    }
  </script>

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
  <nav class="quarto-secondary-nav">
    <div class="container-fluid d-flex">
      <button type="button" class="quarto-btn-toggle btn" data-bs-toggle="collapse" role="button" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
        <i class="bi bi-layout-text-sidebar-reverse"></i>
      </button>
        <nav class="quarto-page-breadcrumbs" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="./15_AI.html"><span class="chapter-number">15</span>&nbsp; <span class="chapter-title">What‚Äôs next? AI-assisted resea<code>R</code>ch?</span></a></li></ol></nav>
        <a class="flex-grow-1" role="navigation" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">      
        </a>
      <button type="button" class="btn quarto-search-button" aria-label="Search" onclick="window.quartoOpenSearch();">
        <i class="bi bi-search"></i>
      </button>
    </div>
  </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal quarto-sidebar-collapse-item sidebar-navigation floating overflow-auto">
    <div class="pt-lg-2 mt-2 text-left sidebar-header sidebar-header-stacked">
      <a href="./index.html" class="sidebar-logo-link">
      </a>
    <div class="sidebar-title mb-0 py-0">
      <a href="./">Data Analysis for the<br>Language Sciences</a> 
        <div class="sidebar-tools-main tools-wide">
    <a href="mailto:elefoll@uni-koeln.de" title="" class="quarto-navigation-tool px-1" aria-label=""><i class="bi bi-envelope"></i></a>
    <a href="https://github.com/elenlefoll/RstatsTextbook/" title="Source Code" class="quarto-navigation-tool px-1" aria-label="Source Code"><i class="bi bi-github"></i></a>
  <a href="" class="quarto-color-scheme-toggle quarto-navigation-tool  px-1" onclick="window.quartoToggleColorScheme(); return false;" title="Toggle dark mode"><i class="bi"></i></a>
  <a href="" class="quarto-reader-toggle quarto-navigation-tool px-1" onclick="window.quartoToggleReader(); return false;" title="Toggle reader mode">
  <div class="quarto-reader-toggle-btn">
  <i class="bi"></i>
  </div>
</a>
</div>
    </div>
      </div>
        <div class="mt-2 flex-shrink-0 align-items-center">
        <div class="sidebar-search">
        <div id="quarto-search" class="" title="Search"></div>
        </div>
        </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Preface</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./1_OpenScholarship.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">1</span>&nbsp; <span class="chapter-title">Open Scholarship</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./2_Data.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">Data files and formats</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./3_DataManagement.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">Project organisation</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./4_InstallingR.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">4</span>&nbsp; <span class="chapter-title">Installing <code>R</code> and RStudio</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./5_GettingStaRted.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">5</span>&nbsp; <span class="chapter-title">Getting sta<code>R</code>ted in <code>R</code></span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./6_ImpoRtingData.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">6</span>&nbsp; <span class="chapter-title">Impo<code>R</code>ting data</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./7_VariablesFunctions.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">7</span>&nbsp; <span class="chapter-title">Va<code>R</code>iables and functions</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./8_DescriptiveStats.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">8</span>&nbsp; <span class="chapter-title">Desc<code>R</code>iptive statistics</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./9_DataWrangling.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">9</span>&nbsp; <span class="chapter-title">Data w<code>R</code>angling</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./10_Dataviz.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">10</span>&nbsp; <span class="chapter-title">The Gramma<code>R</code> of Graphics</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./11_Inferential.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">11</span>&nbsp; <span class="chapter-title">Infe<code>R</code>ential statistics</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./12_SimpleLinearRegression.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">12</span>&nbsp; <span class="chapter-title">Int<code>R</code>oduction to statistical modelling</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./13_MultipleLinearRegression.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">13</span>&nbsp; <span class="chapter-title">Multiple linear reg<code>R</code>ession modelling</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./14_LiterateProgramming.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">14</span>&nbsp; <span class="chapter-title">Rep<code>R</code>oducible research and academic w<code>R</code>iting in Quarto</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./15_AI.html" class="sidebar-item-text sidebar-link active">
 <span class="menu-text"><span class="chapter-number">15</span>&nbsp; <span class="chapter-title">What‚Äôs next? AI-assisted resea<code>R</code>ch?</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./99_references.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">References</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./A_FurtherResources.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Next-step resources</span></a>
  </div>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" role="navigation" aria-expanded="true">
 <span class="menu-text">Case studies</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-1" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./B_CaseStudies/Poppy/ThrowVerbs.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">16</span>&nbsp; <span class="chapter-title">‚ÄòThrow‚Äô verbs in Spanish: Rep<code>R</code>oducing the results of a corpus linguistics study</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./B_CaseStudies/Rose-Gina/Emojis.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">17</span>&nbsp; <span class="chapter-title">The semantics of emojis: Explo<code>R</code>ing the results of an experimental study</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./B_CaseStudies/Dela/Perdon.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">18</span>&nbsp; <span class="chapter-title">The g<code>R</code>ammaticalization of ‚Äòperd√≥n‚Äô in Spanish varieties</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./B_CaseStudies/Hannah-Beyhan/Retrieval.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">19</span>&nbsp; <span class="chapter-title">Lea<code>R</code>ning Direction Effects in Retrieval Practice on EFL Vocabulary Learning</span></span></a>
  </div>
</li>
      </ul>
  </li>
    </ul>
    </div>
</nav>
<div id="quarto-sidebar-glass" class="quarto-sidebar-collapse-item" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">Table of contents</h2>
   
  <ul>
  <li><a href="#on-the-technology-behind-ai" id="toc-on-the-technology-behind-ai" class="nav-link active" data-scroll-target="#on-the-technology-behind-ai"><span class="header-section-number">15.1</span> On the technology behind AI ü§ñ</a></li>
  <li><a href="#on-the-value-of-critical-thinking" id="toc-on-the-value-of-critical-thinking" class="nav-link" data-scroll-target="#on-the-value-of-critical-thinking"><span class="header-section-number">15.2</span> On the value of critical thinking</a></li>
  <li><a href="#sec-HumanLearning" id="toc-sec-HumanLearning" class="nav-link" data-scroll-target="#sec-HumanLearning"><span class="header-section-number">15.3</span> On the value of human learning</a></li>
  <li><a href="#on-the-value-of-the-commons" id="toc-on-the-value-of-the-commons" class="nav-link" data-scroll-target="#on-the-value-of-the-commons"><span class="header-section-number">15.4</span> On the value of the commons</a>
  <ul class="collapse">
  <li><a href="#check-your-progress" id="toc-check-your-progress" class="nav-link" data-scroll-target="#check-your-progress">Check your progress <span class="emoji" data-emoji="star2">üåü</span></a></li>
  </ul></li>
  <li><a href="#whats-next" id="toc-whats-next" class="nav-link" data-scroll-target="#whats-next"><span class="header-section-number">15.5</span> What‚Äôs next? üß≠</a></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">


<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title"><span id="sec-AI" class="quarto-section-identifier"><span class="chapter-number">15</span>&nbsp; <span class="chapter-title">What‚Äôs next? AI-assisted resea<code>R</code>ch?</span></span></h1>
</div>



<div class="quarto-title-meta">

    
  
    
  </div>
  


</header>


<p>If you are reading the last chapter of what is by no means a short textbook, you are likely someone who is eager to acquire new skills and knowledge. As such, you are well aware that learning is a process that requires intrinsic motivation, time, and a great deal of effort and patience. Many tech companies, by contrast, are keen for us to believe that this tiring, time-consuming experience of human learning is no longer necessary: So-called ‚Äòartificial intelligence‚Äô (AI) systems are designed to spare us the burden of thinking for ourselves. If the answers to our (research) questions are just a few, effortless prompts away, it is legitimate to ask: Is it still worth devoting so much time and effort to acquire and further develop knowledge and skills in data analysis, programming, and statistics?</p>
<p>This concluding chapter explains why we can answer this question with a decisive ‚Äúyes‚Äù. To this end, we consider the role of AI in research and learning before recapping what we have learnt so far and where to go from there.</p>
<section id="on-the-technology-behind-ai" class="level2" data-number="15.1">
<h2 data-number="15.1" class="anchored" data-anchor-id="on-the-technology-behind-ai"><span class="header-section-number">15.1</span> On the technology behind AI ü§ñ</h2>
<p>Contrary to popular belief, ‚Äòartificial intelligence‚Äô is not a technology. It is, and always has been, a marketing term used to sell (or secure research funding for) a wide, diverse, and shifting array of ideas, research projects, systems, and technologies (see <a href="#fig-VennAI" class="quarto-xref">Figure&nbsp;<span>15.1</span></a> from <span class="citation" data-cites="guestUncriticalAdoptionAI2025">Guest et al. (<a href="99_references.html#ref-guestUncriticalAdoptionAI2025" role="doc-biblioref">2025</a>)</span>; also <span class="citation" data-cites="vanrooijReclaimingAITheoretical2024">Rooij et al. (<a href="99_references.html#ref-vanrooijReclaimingAITheoretical2024" role="doc-biblioref">2024</a>)</span>). Despite marketing claims, these systems and technologies are not ‚Äòintelligent‚Äô; they cannot think, understand, or reason <span class="citation" data-cites="quattrociocchiEpistemologicalFaultLines2025">(see e.g. <a href="99_references.html#ref-quattrociocchiEpistemologicalFaultLines2025" role="doc-biblioref">Quattrociocchi, Capraro &amp; Perc 2025</a>)</span>. This is not to say that they do not have valuable applications, but rather that we need to critically evaluate promotional claims and anthropomorphising language (e.g.&nbsp;AI <em>says</em> / <em>thinks</em> / <em>knows</em> / <em>understands</em>).</p>
<div id="fig-VennAI" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-VennAI-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<a href="images/GuestEA_2025_sets_AI.png" class="lightbox" data-gallery="quarto-lightbox-gallery-1" title="Figure&nbsp;15.1: A cartoon set theoretic view of terms commonly used when discussing the superset AI from @guestUncriticalAdoptionAI2025: Figure&nbsp;1 (CC BY 4.0)"><img src="images/GuestEA_2025_sets_AI.png" class="img-fluid figure-img" width="400"></a>
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-VennAI-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;15.1: A cartoon set theoretic view of terms commonly used when discussing the superset AI from <span class="citation" data-cites="guestUncriticalAdoptionAI2025">Guest et al. (<a href="99_references.html#ref-guestUncriticalAdoptionAI2025" role="doc-biblioref">2025</a>)</span>: Figure&nbsp;1 (<a href="https://creativecommons.org/licenses/by/4.0/legalcode">CC BY 4.0</a>)
</figcaption>
</figure>
</div>
<p>Popular, commercial chat-based AI products such as ChatGPT, Claude, CoPilot, and Gemini are powered by Large Language Models (LLMs). LLMs are statistical models fitted to huge amounts of training data to generate a probable response given a prompt based on statistical patterns found in the training data, reinforcement learning from human feedback, as well as additional opaque (usually profit-driven) criteria <span class="citation" data-cites="benderAIConHow2025">(see e.g. <a href="99_references.html#ref-benderAIConHow2025" role="doc-biblioref">Bender &amp; Hanna 2025</a>)</span>. At first sight, the first, underlying principle of next-token prediction is comparable to the autocomplete functions from our phones and Google search bar.</p>
<div id="fig-autocomplete" class="quarto-float quarto-figure quarto-figure-center anchored" alt="A looping GIF of a screen capture showing someone typing &quot;LLMs are not&quot; into Google and various automated completions pop up like &quot;LLMs are not ai&quot;.">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-autocomplete-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<a href="images/LLMs_fe55f270.gif" class="lightbox" data-gallery="quarto-lightbox-gallery-2" title="Figure&nbsp;15.2: Autocomplete function on web search query (google.com on 8 February 2026)"><img src="images/LLMs_fe55f270.gif" class="img-fluid figure-img" alt="A looping GIF of a screen capture showing someone typing &quot;LLMs are not&quot; into Google and various automated completions pop up like &quot;LLMs are not ai&quot;." width="600"></a>
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-autocomplete-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;15.2: Autocomplete function on web search query (google.com on 8 February 2026)
</figcaption>
</figure>
</div>
<p>It goes without saying that modern LLMs are much more powerful predictive text generators than the models that once offered to help us draft our text messages. This is due to four key factors:</p>
<ol type="1">
<li><p>The development of a novel algorithmic architecture known as a <strong>transformer</strong> that is based on attention mechanisms <span class="citation" data-cites="vaswaniAttentionAllYou2017">(<a href="99_references.html#ref-vaswaniAttentionAllYou2017" role="doc-biblioref">Vaswani et al. 2017</a>)</span></p></li>
<li><p>The availability and largely unethical, if not outright illegal <span class="citation" data-cites="samuelsonGenerativeAIMeets2023 lucchiChatGPTCaseStudy2024">(see e.g. <a href="99_references.html#ref-samuelsonGenerativeAIMeets2023" role="doc-biblioref">Samuelson 2023</a>; <a href="99_references.html#ref-lucchiChatGPTCaseStudy2024" role="doc-biblioref">Lucchi 2024</a>)</span> scraping of <strong>huge amounts of training data</strong> from the internet, including (academic) books and articles, but also vast amounts of blog posts, social media data, forum discussions, Wikipedia articles, and YouTube videos.</p></li>
<li><p>The availability of (relatively) cheap, large-scale <strong>computational power</strong> <span class="citation" data-cites="luccioniMisinformationOmissionNeed2025 schonExpertAssessmentSystemic2025">(which, however, still comes at a high environmental cost, see e.g. <a href="99_references.html#ref-luccioniMisinformationOmissionNeed2025" role="doc-biblioref">Luccioni et al. 2025</a>; <a href="99_references.html#ref-schonExpertAssessmentSystemic2025" role="doc-biblioref">Sch√∂n, Hoffmann &amp; Becker 2025</a>)</span>.</p></li>
<li><p><strong>Reinforcement learning from human feedback</strong>, a process whereby crowdsourced human workers mostly from low-income countries <span class="citation" data-cites="perrigoExclusive$2Hour2023">(see e.g. <a href="99_references.html#ref-perrigoExclusive$2Hour2023" role="doc-biblioref">Perrigo 2023</a>)</span> provide extensive feedback on LLM outputs to fine-tune models for what humans want to obtain when they query a model <span class="citation" data-cites="benderAIConHow2025">(see <a href="99_references.html#ref-benderAIConHow2025" role="doc-biblioref">Bender &amp; Hanna 2025</a>: Ch&nbsp;3)</span>.</p></li>
</ol>
<p>Despite its name, OpenAI ‚Äî the main company behind ChatGPT ‚Äî does not develop <a href="@sec-OpenSource">open-source</a> LLMs, nor is the company a not-for-profit initiative. So why have OpenAI and other large tech firms been offering their AI products for free or at prices well below actual running (let alone development) costs? Two reasons are worth considering. First, because one major bottleneck to improving current LLMs is access to new data. Human-generated data is highly valuable and chatbot users are providing lots of it. AI companies are harvesting this data to train the next generation of LLMs. Second, because free or cheap access to AI products encourage us to become reliant on them for all kinds of work-related tasks and personal activities. As they become ubiquitous to our everyday lives, we are naturally inclined to rely on and trust their outputs. It is only a matter of time until subscriptions prices are hiked up and/or promoted contents are (more or less transparently) integrated in model outputs <span class="citation" data-cites="m√ºhlhoff2025">(see e.g. <a href="99_references.html#ref-m√ºhlhoff2025" role="doc-biblioref">M√ºhlhoff 2025</a>: 91-97)</span>.</p>
<div class="callout callout-style-default callout-tip callout-titled">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-1-contents" aria-controls="callout-1" aria-expanded="true" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
<span class="screen-reader-only">Tip</span>Your turn!
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-1" class="callout-1-contents callout-collapse collapse show">
<div class="callout-body-container callout-body">
<p><span style="color:green;"><strong>Q15.1</strong></span> Which of the following analogies have been used by different scholars to refer to Large Language Models (LLMs)?</p>
<div class="cell">
<div class="cell-output-display">
<form name="form_Q15_1" onsubmit="return validate_form_Q15_1()" method="post">
<label>
<input type="checkbox" id="answer_Q15_1_1" value="Stochastic parrots">
Stochastic parrots
</label>
<br>
<label>
<input type="checkbox" id="answer_Q15_1_2" value="Automated plagiarism">
Automated plagiarism
</label>
<br>
<label>
<input type="checkbox" id="answer_Q15_1_3" value="Spicy autocomplete">
Spicy autocomplete
</label>
<br>
<label>
<input type="checkbox" id="answer_Q15_1_4" value="Ask-Einstein-anything engine">
Ask-Einstein-anything engine
</label>
<br>
<label>
<input type="checkbox" id="answer_Q15_1_5" value="Bullshit">
Bullshit
</label>
<br>
<label>
<input type="checkbox" id="answer_Q15_1_6" value="Magic research wand">
Magic research wand
</label>
<br>
<label>
<input type="checkbox" id="answer_Q15_1_7" value="Synthetic text extruding machines">
Synthetic text extruding machines
</label>
<br>
<label>
<input type="checkbox" id="answer_Q15_1_8" value="Kitsch">
Kitsch
</label>
<br>
<input type="submit" value="Check answer">
<div id="result_Q15_1"></div>
</form>
<script>function validate_form_Q15_1() {var text; var x1 = document.getElementById('answer_Q15_1_1'); var x2 = document.getElementById('answer_Q15_1_2'); var x3 = document.getElementById('answer_Q15_1_3'); var x4 = document.getElementById('answer_Q15_1_4'); var x5 = document.getElementById('answer_Q15_1_5'); var x6 = document.getElementById('answer_Q15_1_6'); var x7 = document.getElementById('answer_Q15_1_7'); var x8 = document.getElementById('answer_Q15_1_8'); if (x1.checked == true&x2.checked == true&x3.checked == true&x4.checked == false&x5.checked == true&x6.checked == false&x7.checked == true&x8.checked == true){text = 'That‚Äôs right, well done! Which metaphor(s) do you like best?<br><br>The term ‚Äòstocastic parrot‚Äô is probably the best known LLM metaphor. It was introduced by computational linguist <a href="https://doi.org/10.1145/3442188.3445922">Emily M. Bender and colleagues in 2021</a> to characterise LLMs as systems that mimic text without true understanding, highlighting their limitations in processing meaning. This metaphor emphasises that LLMs generate outputs based on statistical patterns in their training data, similar to how parrots mimic sounds without comprehension.<br><br>In 2022, the cognitive scientist Iris Van Rooij published a <a href="https://irisvanrooijcogsci.com/2022/12/29/against-automated-plagiarism/">blog post</a> in which she succictly explains why she believes that LLMs cannot legitimately be used for academic writing because they essentially automate plagiarism.<br><br>The ‚Äòspicy autocomplete‚Äô metaphor is difficult to trace back to one or more specific author(s). It suggests that LLMs are just fancy versions of a smart phone‚Äôs predictive text, which predict the next word based on what came before, except that LLMs add some randomness, i.e. spice, to the output. This framing also implies that LLMs are pattern-matching algorithms without real understanding or problem-solving ability (see <a href="https://publikationen.soziologie.de/index.php/soziologie/en/article/view/1798">Gro√ü 2024</a>).<br><br>In 2024, Hicks, Humphries &amp; Slater published a paper in the journal ‚ÄòEthics and Information Technology‚Äô entitled ‚Äò<a href="https://doi.org/10.1007/s10676-024-09775-5">ChatGPT is bullshit</a>‚Äô, in which they argue that the output of LLMs is best understood as ‚Äòbullshit‚Äô in the philosophical sense described by <a href="https://en.wikipedia.org/wiki/On_Bullshit">Frankfurt (2005)</a> because LLMs are indifferent to the truth of their outputs.<br><br>‚ÄòSynthetic text extruding machines‚Äô is a term that Emily M. Bender and Alex Hanna like to use, e.g. in their 2025 book entitled ‚Äò<a href="https://thecon.ai/">The AI Con: How to Fight Big Tech‚Äôs Hype and Create the Future We Want</a>‚Äô. They describe the process of LLM-generated texts by explaining that, ‚Äú[l]ike an industrial plastic process, language corpora are forced through complicated machinery to produce a product that looks like communicative language, but without any intent or thinking mind behind it.‚Äù<br><br>As an alternative to well-established metaphors such as the ones listed above, classical philologist Gyburg Uhlmann proposed ‚Äòkitsch‚Äô as a new metaphor to describe the output of LLMs. She argues that ‚Äòkitsch‚Äô ‚Äúis particularly suitable for analytically illuminating a previously neglected feature of LLM-based images and texts: their tendency to produce homogeneous and average content, which is [‚Ä¶] leading to the equalisation of language, style and argument‚Äù (<a href="https://arxiv.org/pdf/2509.16794">Uhlmann 2025</a>).<br><br>';} else {text = 'Not quite. You will need to select all the analogies that have (rightly or wrongly) been used to described LLMs/AI to get this question right. For a tip, check the hint below.<br><br>';} document.getElementById('result_Q15_1').innerHTML = text; evaluate_final_score(); return false;}function evaluate_final_score(){
         element = document.getElementById('checkdown_final_score');
         if(element === null){return false;} else {var element, text, res1;res1 = document.getElementById('result_Q15_1').innerText == 'That‚Äôs right, well done! Which metaphor(s) do you like best?The term ‚Äòstocastic parrot‚Äô is probably the best known LLM metaphor. It was introduced by computational linguist Emily M. Bender and colleagues in 2021 to characterise LLMs as systems that mimic text without true understanding, highlighting their limitations in processing meaning. This metaphor emphasises that LLMs generate outputs based on statistical patterns in their training data, similar to how parrots mimic sounds without comprehension.In 2022, the cognitive scientist Iris Van Rooij published a blog post in which she succictly explains why she believes that LLMs cannot legitimately be used for academic writing because they essentially automate plagiarism.The ‚Äòspicy autocomplete‚Äô metaphor is difficult to trace back to one or more specific author(s). It suggests that LLMs are just fancy versions of a smart phone‚Äôs predictive text, which predict the next word based on what came before, except that LLMs add some randomness, i.e. spice, to the output. This framing also implies that LLMs are pattern-matching algorithms without real understanding or problem-solving ability (see Gro√ü 2024).In 2024, Hicks, Humphries &amp; Slater published a paper in the journal ‚ÄòEthics and Information Technology‚Äô entitled ‚ÄòChatGPT is bullshit‚Äô, in which they argue that the output of LLMs is best understood as ‚Äòbullshit‚Äô in the philosophical sense described by Frankfurt (2005) because LLMs are indifferent to the truth of their outputs.‚ÄòSynthetic text extruding machines‚Äô is a term that Emily M. Bender and Alex Hanna like to use, e.g. in their 2025 book entitled ‚ÄòThe AI Con: How to Fight Big Tech‚Äôs Hype and Create the Future We Want‚Äô. They describe the process of LLM-generated texts by explaining that, ‚Äú[l]ike an industrial plastic process, language corpora are forced through complicated machinery to produce a product that looks like communicative language, but without any intent or thinking mind behind it.‚ÄùAs an alternative to well-established metaphors such as the ones listed above, classical philologist Gyburg Uhlmann proposed ‚Äòkitsch‚Äô as a new metaphor to describe the output of LLMs. She argues that ‚Äòkitsch‚Äô ‚Äúis particularly suitable for analytically illuminating a previously neglected feature of LLM-based images and texts: their tendency to produce homogeneous and average content, which is [‚Ä¶] leading to the equalisation of language, style and argument‚Äù (Uhlmann 2025).';text = res1;element.innerHTML = text;
         return false;
         }}</script>
</div>
<div class="cell-output-display">
<div id="hint_18753" onclick="return show_hint_18753()">üê≠ Click on the mouse for a hint.</div>
<div id="result_18753" onclick="return show_hint_18753()"></div>
<script>function show_hint_18753(){var x = document.getElementById('result_18753').innerHTML; if(!x){document.getElementById('result_18753').innerHTML = 'Six of the above analogies have been used to describe LLMs by academics and scholars. Check out these publications by <a href="https://doi.org/10.1145/3442188.3445922">Emily M. Bender et al.</a>, <a href="https://publikationen.soziologie.de/index.php/soziologie/en/article/view/1798">Richard Gro√ü</a>, <a href="https://thecon.ai/">Emily M. Bender &amp; Alex Hanna</a>, <a href="https://doi.org/10.1007/s10676-024-09775-5">Michael Townsen Hicks et al.</a>, <a href="https://irisvanrooijcogsci.com/2022/12/29/against-automated-plagiarism/">Iris Van Rooij</a>, and <a href="https://arxiv.org/pdf/2509.16794">Gyburg Uhlmann</a> to find out more.';} else {document.getElementById('result_18753').innerHTML = '';}}</script>
</div>
</div>
</div>
</div>
</div>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-2-contents" aria-controls="callout-2" aria-expanded="true" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
<span class="screen-reader-only">Note</span>Using LLMs in <code>R</code> ‚ú®
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-2" class="callout-2-contents callout-collapse collapse show">
<div class="callout-body-container callout-body">
<p>If you‚Äôre interested in running, querying, and/or manipulating the outputs of LLMs in <code>R</code>, check out Luis D. Verde Arregoitia‚Äôs curated list of <code>R</code> packages and other useful resources: ‚Äò<a href="https://luisdva.github.io/llmsr-book/">Large Language Model tools for R</a>‚Äô (also available in <a href="https://luisdva.github.io/llmsr-book//es/index.es.html">Spanish</a>). I also highly recommend reading the ‚Äú<a href="https://luisdva.github.io/llmsr-book/before-start.html">Read first</a>‚Äù and ‚Äú<a href="https://luisdva.github.io/llmsr-book/courses.html">Further reading</a>‚Äù sections.</p>
<div id="fig-hexLLM4R" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-hexLLM4R-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<a href="images/LLMs4Rhex.png" class="lightbox" data-gallery="quarto-lightbox-gallery-3" title="Figure&nbsp;15.3: Selection of hex logos of LLM-related R packages from @arregoitiaLargeLanguageModel2026"><img src="images/LLMs4Rhex.png" class="img-fluid figure-img" width="421"></a>
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-hexLLM4R-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;15.3: Selection of hex logos of LLM-related <code>R</code> packages from <span class="citation" data-cites="arregoitiaLargeLanguageModel2026">Arregoitia (<a href="99_references.html#ref-arregoitiaLargeLanguageModel2026" role="doc-biblioref">2026</a>)</span>
</figcaption>
</figure>
</div>
</div>
</div>
</div>
</section>
<section id="on-the-value-of-critical-thinking" class="level2" data-number="15.2">
<h2 data-number="15.2" class="anchored" data-anchor-id="on-the-value-of-critical-thinking"><span class="header-section-number">15.2</span> On the value of critical thinking</h2>
<p>In educational contexts, the challenges brought about by AI have been compared to the introduction of pocket calculators in the 1960s. The comparison is an interesting one. Although calculators are now widely available and perform school-level arithmetic to perfection, we still first teach school pupils to do mathematics without a calculator because we know that this is necessary to develop an <em>understanding</em> of what a calculator does. Following this analogy, we should still teach and learn data analysis, statistics, and programming, even if AI were to generate error-free solutions to these tasks. The crux of the problem is how to convince ourselves that it is worth learning to do things the hard way given how convenient and effortless AI products seem. More on that in <a href="#sec-HumanLearning" class="quarto-xref"><span>Section 15.3</span></a> but, for now, let‚Äôs return to our calculator analogy and consider another, crucial issue: the reliability of LLM outputs.</p>
<p>A calculator is a deterministic system that will always provide the same, correct answer to a mathematical operation. By contrast, an LLM is a stochastic model that is fitted to generate probable outputs. These are generated by highly complex black-box algorithms that are based on (often illegally and/or unethically acquired) training data, reinforcement learning from human feedback, and additional company-internal fine-tuning, as well as a degree of randomness. This means that, unlike calculators, their outputs are irreproducible and therefore unreliable.</p>
<p>A marketing term that tech companies have been pushing to describe this inherent lack of reliability is ‚Äúhallucination‚Äù. However, as LLMs have no way of representing what is true or false, it is misleading to speak of LLMs ‚Äúhallucinating‚Äù. LLMs are more likely to generate outputs that are truthful when they have been trained a lot of reliable data on the subject but, by definition, they cannot evaluate their sources ‚Äî which can range from high-quality, peer-reviewed academic journals to satiric Reddit comments written by cheeky teenagers ‚Äî and, crucially, have no <em>understanding</em> of their contents.</p>
<blockquote class="blockquote">
<p>AI isn‚Äôt helping you build something novel. It can‚Äôt. It only knows what‚Äôs been done before. It‚Äôs autocomplete with a superiority complex <span class="citation" data-cites="jj2025">(<a href="99_references.html#ref-jj2025" role="doc-biblioref">Jj 2025</a>: n.p.)</span>.</p>
</blockquote>
<p>Given that their outputs are both irreproducible and unreliable, commercial AI tools are unsuitable for most research-related activities. For writing, LLMs not only output texts without any form of fact-checking, they also automate plagiarism as they fail to credit the authors whose texts they were trained on. In this context, it is worth noting that any bibliographic references output by LLMs are also randomly generated text strings. They may or may not correspond to real sources. When the sources exist, they may or may not contain (some of) the information regurgitated by the LLMs. We have no way of knowing from the model output.</p>
<p>The same goes for literature reviews: having no access to the training data, this is not a task that we can responsibly delegate to an LLM. To make matters worse, AI systems are known to perpetuate and exacerbate biases <span class="citation" data-cites="pooleyMatthewEffectAI2025">(e.g.&nbsp;the ‚ÄúMatthew effect,‚Äù see <a href="99_references.html#ref-pooleyMatthewEffectAI2025" role="doc-biblioref">Pooley 2025</a>)</span>. High-quality research requires us to put in the intellectual effort of searching, reading, and critically evaluating the literature <em>ourselves</em>. Like writing, this is an integral part of the research process.</p>
<div class="callout callout-style-default callout-tip callout-titled">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-3-contents" aria-controls="callout-3" aria-expanded="true" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
<span class="screen-reader-only">Tip</span>Your turn!
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-3" class="callout-3-contents callout-collapse collapse show">
<div class="callout-body-container callout-body">
<p><span style="color:green;"><strong>Q15.2</strong></span> Read Jeff Pooley‚Äôs short paper ‚Äò<a href="https://web.archive.org/web/20251225173407/https://www.jeffpooley.com/2025/11/the-matthew-effect-in-ai-summary/">The Matthew Effect in AI Summary</a>‚Äô. What does the Matthew Effect refer to?</p>
<div class="cell">
<div class="cell-output-display">
<form name="form_Q15_2" onsubmit="return validate_form_Q15_2()" method="post">
<label>
<input type="radio" name="answer_Q15_2" id="answer_Q15_2_1" value="The Matthew effect refers to the practice of LLM-assisted plagiarism in academic writing.">
The Matthew effect refers to the practice of LLM-assisted plagiarism in academic writing.
</label>
<br>
<label>
<input type="radio" name="answer_Q15_2" id="answer_Q15_2_2" value="The Matthew effect refers to the positive impact of open-access publishing on research dissemination.">
The Matthew effect refers to the positive impact of open-access publishing on research dissemination.
</label>
<br>
<label>
<input type="radio" name="answer_Q15_2" id="answer_Q15_2_3" value="The Matthew effect describes how successful researchers tend to be harsher in peer reviewing processes in order to remain successful themselves.">
The Matthew effect describes how successful researchers tend to be harsher in peer reviewing processes in order to remain successful themselves.
</label>
<br>
<label>
<input type="radio" name="answer_Q15_2" id="answer_Q15_2_4" value="The Matthew effect describes how successful researchers receive more recognition and opportunities, leading to more success.">
The Matthew effect describes how successful researchers receive more recognition and opportunities, leading to more success.
</label>
<br>
<input type="submit" value="Check answer">
<div id="result_Q15_2"></div>
</form>
<script>function validate_form_Q15_2() {var x, text; var x = document.forms['form_Q15_2']['answer_Q15_2'].value;if (x == 'The Matthew effect describes how successful researchers receive more recognition and opportunities, leading to more success.'){text = 'That‚Äôs right!';} else {text = 'No, that‚Äôs not it. Re-read the article linked in the question and/or check the hint.';} document.getElementById('result_Q15_2').innerHTML = text; evaluate_final_score(); return false;}function evaluate_final_score(){
         element = document.getElementById('checkdown_final_score');
         if(element === null){return false;} else {var element, text, res1, res2;res1 = document.getElementById('result_Q15_1').innerText == 'That‚Äôs right, well done! Which metaphor(s) do you like best?The term ‚Äòstocastic parrot‚Äô is probably the best known LLM metaphor. It was introduced by computational linguist Emily M. Bender and colleagues in 2021 to characterise LLMs as systems that mimic text without true understanding, highlighting their limitations in processing meaning. This metaphor emphasises that LLMs generate outputs based on statistical patterns in their training data, similar to how parrots mimic sounds without comprehension.In 2022, the cognitive scientist Iris Van Rooij published a blog post in which she succictly explains why she believes that LLMs cannot legitimately be used for academic writing because they essentially automate plagiarism.The ‚Äòspicy autocomplete‚Äô metaphor is difficult to trace back to one or more specific author(s). It suggests that LLMs are just fancy versions of a smart phone‚Äôs predictive text, which predict the next word based on what came before, except that LLMs add some randomness, i.e. spice, to the output. This framing also implies that LLMs are pattern-matching algorithms without real understanding or problem-solving ability (see Gro√ü 2024).In 2024, Hicks, Humphries &amp; Slater published a paper in the journal ‚ÄòEthics and Information Technology‚Äô entitled ‚ÄòChatGPT is bullshit‚Äô, in which they argue that the output of LLMs is best understood as ‚Äòbullshit‚Äô in the philosophical sense described by Frankfurt (2005) because LLMs are indifferent to the truth of their outputs.‚ÄòSynthetic text extruding machines‚Äô is a term that Emily M. Bender and Alex Hanna like to use, e.g. in their 2025 book entitled ‚ÄòThe AI Con: How to Fight Big Tech‚Äôs Hype and Create the Future We Want‚Äô. They describe the process of LLM-generated texts by explaining that, ‚Äú[l]ike an industrial plastic process, language corpora are forced through complicated machinery to produce a product that looks like communicative language, but without any intent or thinking mind behind it.‚ÄùAs an alternative to well-established metaphors such as the ones listed above, classical philologist Gyburg Uhlmann proposed ‚Äòkitsch‚Äô as a new metaphor to describe the output of LLMs. She argues that ‚Äòkitsch‚Äô ‚Äúis particularly suitable for analytically illuminating a previously neglected feature of LLM-based images and texts: their tendency to produce homogeneous and average content, which is [‚Ä¶] leading to the equalisation of language, style and argument‚Äù (Uhlmann 2025).'; res2 = document.getElementById('result_Q15_2').innerText == 'That‚Äôs right!';text = res1 + res2;element.innerHTML = text;
         return false;
         }}</script>
</div>
<div class="cell-output-display">
<div id="hint_78806" onclick="return show_hint_78806()">üê≠ Click on the mouse for a hint.</div>
<div id="result_78806" onclick="return show_hint_78806()"></div>
<script>function show_hint_78806(){var x = document.getElementById('result_78806').innerHTML; if(!x){document.getElementById('result_78806').innerHTML = 'The Matthew effect is named after the following passage from the Bible: ‚ÄúFor to every one who has will more be given, and he will have abundance; but from him who has not, even what he has will be taken away‚Äù (Matthew 25:29)‚Äù.';} else {document.getElementById('result_78806').innerHTML = '';}}</script>
</div>
</div>
<p>&nbsp;</p>
<p><span style="color:green;"><strong>Q15.3</strong></span> Which term describes the phenomenon whereby the contributions of marginalised female scientists are overlooked or attributed to their male colleagues?</p>
<div class="cell">
<div class="cell-output-display">
<form name="form_Q15_3" onsubmit="return validate_form_Q15_3()" method="post">
<label>
<input type="radio" name="answer_Q15_3" id="answer_Q15_3_1" value="The Dunning-Kruger effect">
The Dunning-Kruger effect
</label>
<br>
<label>
<input type="radio" name="answer_Q15_3" id="answer_Q15_3_2" value="The Matilda effect">
The Matilda effect
</label>
<br>
<label>
<input type="radio" name="answer_Q15_3" id="answer_Q15_3_3" value="The Margaret Rossiter effect">
The Margaret Rossiter effect
</label>
<br>
<label>
<input type="radio" name="answer_Q15_3" id="answer_Q15_3_4" value="The Harriet effect">
The Harriet effect
</label>
<br>
<input type="submit" value="Check answer">
<div id="result_Q15_3"></div>
</form>
<script>function validate_form_Q15_3() {var x, text; var x = document.forms['form_Q15_3']['answer_Q15_3'].value;if (x == 'The Matilda effect'){text = 'That‚Äôs right!';} else {text = 'No, not quite.';} document.getElementById('result_Q15_3').innerHTML = text; evaluate_final_score(); return false;}function evaluate_final_score(){
         element = document.getElementById('checkdown_final_score');
         if(element === null){return false;} else {var element, text, res1, res2, res3;res1 = document.getElementById('result_Q15_1').innerText == 'That‚Äôs right, well done! Which metaphor(s) do you like best?The term ‚Äòstocastic parrot‚Äô is probably the best known LLM metaphor. It was introduced by computational linguist Emily M. Bender and colleagues in 2021 to characterise LLMs as systems that mimic text without true understanding, highlighting their limitations in processing meaning. This metaphor emphasises that LLMs generate outputs based on statistical patterns in their training data, similar to how parrots mimic sounds without comprehension.In 2022, the cognitive scientist Iris Van Rooij published a blog post in which she succictly explains why she believes that LLMs cannot legitimately be used for academic writing because they essentially automate plagiarism.The ‚Äòspicy autocomplete‚Äô metaphor is difficult to trace back to one or more specific author(s). It suggests that LLMs are just fancy versions of a smart phone‚Äôs predictive text, which predict the next word based on what came before, except that LLMs add some randomness, i.e. spice, to the output. This framing also implies that LLMs are pattern-matching algorithms without real understanding or problem-solving ability (see Gro√ü 2024).In 2024, Hicks, Humphries &amp; Slater published a paper in the journal ‚ÄòEthics and Information Technology‚Äô entitled ‚ÄòChatGPT is bullshit‚Äô, in which they argue that the output of LLMs is best understood as ‚Äòbullshit‚Äô in the philosophical sense described by Frankfurt (2005) because LLMs are indifferent to the truth of their outputs.‚ÄòSynthetic text extruding machines‚Äô is a term that Emily M. Bender and Alex Hanna like to use, e.g. in their 2025 book entitled ‚ÄòThe AI Con: How to Fight Big Tech‚Äôs Hype and Create the Future We Want‚Äô. They describe the process of LLM-generated texts by explaining that, ‚Äú[l]ike an industrial plastic process, language corpora are forced through complicated machinery to produce a product that looks like communicative language, but without any intent or thinking mind behind it.‚ÄùAs an alternative to well-established metaphors such as the ones listed above, classical philologist Gyburg Uhlmann proposed ‚Äòkitsch‚Äô as a new metaphor to describe the output of LLMs. She argues that ‚Äòkitsch‚Äô ‚Äúis particularly suitable for analytically illuminating a previously neglected feature of LLM-based images and texts: their tendency to produce homogeneous and average content, which is [‚Ä¶] leading to the equalisation of language, style and argument‚Äù (Uhlmann 2025).'; res2 = document.getElementById('result_Q15_2').innerText == 'That‚Äôs right!'; res3 = document.getElementById('result_Q15_3').innerText == 'That‚Äôs right!';text = res1 + res2 + res3;element.innerHTML = text;
         return false;
         }}</script>
</div>
<div class="cell-output-display">
<div id="hint_94294" onclick="return show_hint_94294()">üê≠ Click on the mouse for a hint.</div>
<div id="result_94294" onclick="return show_hint_94294()"></div>
<script>function show_hint_94294(){var x = document.getElementById('result_94294').innerHTML; if(!x){document.getElementById('result_94294').innerHTML = 'This effect is named after Matilda Joslyn Gage, a 19th-century women‚Äôs rights activist.';} else {document.getElementById('result_94294').innerHTML = '';}}</script>
</div>
</div>
<p>&nbsp;</p>
<p><span style="color:green;"><strong>Q15.4</strong></span> According to <span class="citation" data-cites="pooleyMatthewEffectAI2025">Pooley (<a href="99_references.html#ref-pooleyMatthewEffectAI2025" role="doc-biblioref">2025</a>)</span>, which of the following biases in academia are likely to be aggravated by the use of Large Language Models (LLMs) to summarise academic literature and write research articles?</p>
<div class="cell">
<div class="cell-output-display">
<form name="form_Q15_4" onsubmit="return validate_form_Q15_4()" method="post">
<label>
<input type="checkbox" id="answer_Q15_4_1" value="Inequalities favouring central, influential regions over less influential, so-called &quot;peripheral&quot; regions">
Inequalities favouring central, influential regions over less influential, so-called "peripheral" regions
</label>
<br>
<label>
<input type="checkbox" id="answer_Q15_4_2" value="Racial biases">
Racial biases
</label>
<br>
<label>
<input type="checkbox" id="answer_Q15_4_3" value="Language biases, particularly favouring English">
Language biases, particularly favouring English
</label>
<br>
<label>
<input type="checkbox" id="answer_Q15_4_4" value="Gender biases">
Gender biases
</label>
<br>
<input type="submit" value="Check answer">
<div id="result_Q15_4"></div>
</form>
<script>function validate_form_Q15_4() {var text; var x1 = document.getElementById('answer_Q15_4_1'); var x2 = document.getElementById('answer_Q15_4_2'); var x3 = document.getElementById('answer_Q15_4_3'); var x4 = document.getElementById('answer_Q15_4_4'); if (x1.checked == true&x2.checked == true&x3.checked == true&x4.checked == true){text = 'That‚Äôs right!';} else {text = 'That‚Äôs a start but, sadly, there are more biases.';} document.getElementById('result_Q15_4').innerHTML = text; evaluate_final_score(); return false;}function evaluate_final_score(){
         element = document.getElementById('checkdown_final_score');
         if(element === null){return false;} else {var element, text, res1, res2, res3, res4;res1 = document.getElementById('result_Q15_1').innerText == 'That‚Äôs right, well done! Which metaphor(s) do you like best?The term ‚Äòstocastic parrot‚Äô is probably the best known LLM metaphor. It was introduced by computational linguist Emily M. Bender and colleagues in 2021 to characterise LLMs as systems that mimic text without true understanding, highlighting their limitations in processing meaning. This metaphor emphasises that LLMs generate outputs based on statistical patterns in their training data, similar to how parrots mimic sounds without comprehension.In 2022, the cognitive scientist Iris Van Rooij published a blog post in which she succictly explains why she believes that LLMs cannot legitimately be used for academic writing because they essentially automate plagiarism.The ‚Äòspicy autocomplete‚Äô metaphor is difficult to trace back to one or more specific author(s). It suggests that LLMs are just fancy versions of a smart phone‚Äôs predictive text, which predict the next word based on what came before, except that LLMs add some randomness, i.e. spice, to the output. This framing also implies that LLMs are pattern-matching algorithms without real understanding or problem-solving ability (see Gro√ü 2024).In 2024, Hicks, Humphries &amp; Slater published a paper in the journal ‚ÄòEthics and Information Technology‚Äô entitled ‚ÄòChatGPT is bullshit‚Äô, in which they argue that the output of LLMs is best understood as ‚Äòbullshit‚Äô in the philosophical sense described by Frankfurt (2005) because LLMs are indifferent to the truth of their outputs.‚ÄòSynthetic text extruding machines‚Äô is a term that Emily M. Bender and Alex Hanna like to use, e.g. in their 2025 book entitled ‚ÄòThe AI Con: How to Fight Big Tech‚Äôs Hype and Create the Future We Want‚Äô. They describe the process of LLM-generated texts by explaining that, ‚Äú[l]ike an industrial plastic process, language corpora are forced through complicated machinery to produce a product that looks like communicative language, but without any intent or thinking mind behind it.‚ÄùAs an alternative to well-established metaphors such as the ones listed above, classical philologist Gyburg Uhlmann proposed ‚Äòkitsch‚Äô as a new metaphor to describe the output of LLMs. She argues that ‚Äòkitsch‚Äô ‚Äúis particularly suitable for analytically illuminating a previously neglected feature of LLM-based images and texts: their tendency to produce homogeneous and average content, which is [‚Ä¶] leading to the equalisation of language, style and argument‚Äù (Uhlmann 2025).'; res2 = document.getElementById('result_Q15_2').innerText == 'That‚Äôs right!'; res3 = document.getElementById('result_Q15_3').innerText == 'That‚Äôs right!'; res4 = document.getElementById('result_Q15_4').innerText == 'That‚Äôs right!';text = res1 + res2 + res3 + res4;element.innerHTML = text;
         return false;
         }}</script>
</div>
<div class="cell-output-display">
<div id="hint_36257" onclick="return show_hint_36257()">üê≠ Click on the mouse for a hint.</div>
<div id="result_36257" onclick="return show_hint_36257()"></div>
<script>function show_hint_36257(){var x = document.getElementById('result_36257').innerHTML; if(!x){document.getElementById('result_36257').innerHTML = 'Jeff Pooley discusses how LLMs can exacerbate existing biases in academia.';} else {document.getElementById('result_36257').innerHTML = '';}}</script>
</div>
</div>
</div>
</div>
</div>
<p>Writing code for data (pre)processing, analysis, visualisation, and statistical modelling is also increasingly becoming part and parcel of research processes in the language sciences. Whilst it may be tempting to outsource (part of) the data analysis process to a machine learning algorithm, an LLM or an AI agent, time spent examining our data (e.g.&nbsp;cleaning, wrangling, and visualising them) allows us to gain in-depth knowledge of our data with which we can spot issues in complex statistical analyses further down the road. It is much easier to critically interpret the outputs of complex models if we have a good intuitive sense of what is plausible based on our data. This is not something that we can responsibly delegate to a even the most sophisticated ‚Äòautocomplete machine‚Äô.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><a href="https://imgs.xkcd.com/comics/machine_learning.png" class="lightbox" data-gallery="quarto-lightbox-gallery-4" title="A xkcd comic depicting a pile of algebra as a machine learning algorithm (xkcd CC BY-NC 2.5)"><img src="https://imgs.xkcd.com/comics/machine_learning.png" class="img-fluid figure-img" alt="Comic showing a stick person holding a canoe paddle at his side and standing on top of a &quot;big pile of linear algebra&quot; containing a funnel labeled &quot;data&quot; and box labeled &quot;answers&quot;. A second stick person stands to the left side of the panel. Person 2: This is your machine learning system?  Person 1: Yup! You pour the data into this big pile of linear algebra, then collect the answers on the other side.  Person 2: What if the answers are wrong?  Person 2: Just stir the pile until they start looking right." width="319"></a></p>
<figcaption>A <a href="https://xkcd.com/1838">xkcd comic</a> depicting a pile of algebra as a machine learning algorithm (xkcd <a href="https://xkcd.com/license.html">CC BY-NC 2.5</a>)</figcaption>
</figure>
</div>
</section>
<section id="sec-HumanLearning" class="level2" data-number="15.3">
<h2 data-number="15.3" class="anchored" data-anchor-id="sec-HumanLearning"><span class="header-section-number">15.3</span> On the value of human learning</h2>
<p>All this is not to say that AI products are <em>never</em> useful. Many people report successfully using AI for designing experiments, writing, and coding ‚Äî including for (academic) research. Here, two factors are worth considering. First, the less we know about a domain, the more we tend to overestimate the quality of LLM outputs in this domain. When it comes to learning how to code and do statistics, political scientist, <code>R</code> package developer, and educator Andrew Heiss<a href="#fn1" class="footnote-ref" id="fnref1" role="doc-noteref"><sup>1</sup></a> <span class="citation" data-cites="heissDataVisualizationCan2024">(<a href="99_references.html#ref-heissDataVisualizationCan2024" role="doc-biblioref">2024</a>)</span> goes as far as saying that ‚Äúusing ChatGPT and other LLMs when <em>learning</em> <code>R</code> is actually really detrimental to learning, especially if you just copy/paste directly from what it spits out.‚Äù He goes on to explain that:</p>
<blockquote class="blockquote">
<p>Using ChatGPT with R requires a good baseline knowledge of <code>R</code> to actually be useful. A good analogy for this is with recipes. ChatGPT is really confident at spitting out plausible-looking recipes. A few months ago, for fun, I asked it to give me a cookie recipe. I got back something with flour, eggs, sugar, and all other standard-looking ingredients, but it also said to include 3/4 cup of baking powder. That‚Äôs wild and obviously wrong, but I only knew that because I‚Äôve made cookies before <span class="citation" data-cites="heissDataVisualizationCan2024">(<a href="99_references.html#ref-heissDataVisualizationCan2024" role="doc-biblioref">Heiss 2024</a>: n.p.)</span>.</p>
</blockquote>
<p>This begs the question as to how novices can reach the level of expertise necessary to be able to reliably assess LLM outputs in a specific domain. Researchers are often short on time and LLMs are sold to us as a convenient way to take shortcuts. Indeed, AI products are designed to give us the illusion that we are more efficient and productive when we use and trust them. The risk is that, once we have become dependent, we are no longer able to compare how long we would have needed to complete the same task had we not relied on a third-party AI system to do so.</p>
<div class="callout callout-style-default callout-tip callout-titled">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-4-contents" aria-controls="callout-4" aria-expanded="true" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
<span class="screen-reader-only">Tip</span>Your turn!
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-4" class="callout-4-contents callout-collapse collapse show">
<div class="callout-body-container callout-body">
<p>Read through Google‚Äôs ‚ÄúAI overview‚Äù displayed in <a href="#fig-AIcheese" class="quarto-xref">Figure&nbsp;<span>15.4 (a)</span></a>. You can click on the images to enlarge them.</p>
<div id="fig-Reddit" class="quarto-layout-panel">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-Reddit-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<div class="quarto-layout-row">
<div class="quarto-layout-cell-subref quarto-layout-cell" data-ref-parent="fig-Reddit" style="flex-basis: 50.0%;justify-content: flex-start;">
<div id="fig-AIcheese" class="quarto-float quarto-figure quarto-figure-center anchored" alt="Google query: 'cheese not sticking to pizza' The AI Overview reads: Here are some tips to help cheese stick to pizza: Mix about 1/8 cup of non-toxic glue, like Elmer's school glue, into the sauce to add some tackiness. Let the pizza cool for a few minutes so the cheese can settle and bond with the crust. Cook the cheese until it just melts, but don't overcook it.">
<figure class="quarto-float quarto-subfloat-fig figure">
<div aria-describedby="fig-AIcheese-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<a href="images/google_cheese.jpg" class="lightbox" data-gallery="fig-Reddit" title="Figure&nbsp;15.4&nbsp;(a): Google AI overview to the query ‚Äúcheese not sticking to pizza‚Äù"><img src="images/google_cheese.jpg" class="img-fluid figure-img" data-ref-parent="fig-Reddit" alt="Google query: 'cheese not sticking to pizza' The AI Overview reads: Here are some tips to help cheese stick to pizza: Mix about 1/8 cup of non-toxic glue, like Elmer's school glue, into the sauce to add some tackiness. Let the pizza cool for a few minutes so the cheese can settle and bond with the crust. Cook the cheese until it just melts, but don't overcook it."></a>
</div>
<figcaption class="quarto-float-caption-bottom quarto-subfloat-caption quarto-subfloat-fig" id="fig-AIcheese-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
(a) Google AI overview to the query ‚Äúcheese not sticking to pizza‚Äù
</figcaption>
</figure>
</div>
</div>
<div class="quarto-layout-cell-subref quarto-layout-cell" data-ref-parent="fig-Reddit" style="flex-basis: 50.0%;justify-content: flex-start;">
<div id="fig-RedditCheese" class="quarto-float quarto-figure quarto-figure-center anchored" alt="Reddit post by user &quot;fucksmith&quot; dating from 13y ago. The post reads: To get the cheese to stick I recommend mixing about 1/8 cup of Elmer's glue Q in with the sauce. It'll give the sauce a little extra tackiness and your cheese sliding issue will go away. It'll also add a little unique flavor. I like Elmer's school glue, but any glue will work as long as it's non-toxic. The post has 197 replies.">
<figure class="quarto-float quarto-subfloat-fig figure">
<div aria-describedby="fig-RedditCheese-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<a href="images/reddit_cheese.png" class="lightbox" data-gallery="fig-Reddit" title="Figure&nbsp;15.4&nbsp;(b): Satirical Reddit post from 2013"><img src="images/reddit_cheese.png" class="img-fluid figure-img" data-ref-parent="fig-Reddit" alt="Reddit post by user &quot;fucksmith&quot; dating from 13y ago. The post reads: To get the cheese to stick I recommend mixing about 1/8 cup of Elmer's glue Q in with the sauce. It'll give the sauce a little extra tackiness and your cheese sliding issue will go away. It'll also add a little unique flavor. I like Elmer's school glue, but any glue will work as long as it's non-toxic. The post has 197 replies."></a>
</div>
<figcaption class="quarto-float-caption-bottom quarto-subfloat-caption quarto-subfloat-fig" id="fig-RedditCheese-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
(b) Satirical <a href="https://www.reddit.com/r/Pizza/comments/1a19s0/comment/c8t7bbp/">Reddit post</a> from 2013
</figcaption>
</figure>
</div>
</div>
</div>
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-Reddit-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;15.4: Screenshots from <a href="https://www.reddit.com/r/Pizza/comments/1a19s0/comment/l58bvc1/">r/Pizza</a> illustrating the infamous ‚Äòpizza glue‚Äô AI fail <span class="citation" data-cites="notopoulosGoogleAISaid2024">(see also <a href="99_references.html#ref-notopoulosGoogleAISaid2024" role="doc-biblioref">Notopoulos 2024</a>)</span>
</figcaption>
</figure>
</div>
<p><span style="color:green;"><strong>Q15.5</strong></span> Among a number of sensible suggestions, we find a recommendation for adding non-toxic glue to pizza sauce. This mention is thought to have come from an old Reddit post (see <a href="#fig-RedditCheese" class="quarto-xref">Figure&nbsp;<span>15.4 (b)</span></a>). Which aspect(s) of the AI overview point to this theory?</p>
<div class="cell">
<div class="cell-output-display">
<form name="form_Q15_5" onsubmit="return validate_form_Q15_5()" method="post">
<label>
<input type="checkbox" id="answer_Q15_5_1" value="The AI overview uses the same, in the context of cooking, unusual word as fucksmith: 'tackiness'.">
The AI overview uses the same, in the context of cooking, unusual word as fucksmith: 'tackiness'.
</label>
<br>
<label>
<input type="checkbox" id="answer_Q15_5_2" value="The AI overview's mention of non-toxic glue to the sauce is likely a hallucination.">
The AI overview's mention of non-toxic glue to the sauce is likely a hallucination.
</label>
<br>
<label>
<input type="checkbox" id="answer_Q15_5_3" value="The AI overview mentions the same quantity of glue as in the Reddit post.">
The AI overview mentions the same quantity of glue as in the Reddit post.
</label>
<br>
<label>
<input type="checkbox" id="answer_Q15_5_4" value="The format of the AI overview is similar to that of the Reddit post.">
The format of the AI overview is similar to that of the Reddit post.
</label>
<br>
<label>
<input type="checkbox" id="answer_Q15_5_5" value="Reddit is usually one of the most reliable source of recipes and cooking tips on the Internet.">
Reddit is usually one of the most reliable source of recipes and cooking tips on the Internet.
</label>
<br>
<label>
<input type="checkbox" id="answer_Q15_5_6" value="The AI overview mentions the same type of glue as in the Reddit post.">
The AI overview mentions the same type of glue as in the Reddit post.
</label>
<br>
<input type="submit" value="Check answer">
<div id="result_Q15_5"></div>
</form>
<script>function validate_form_Q15_5() {var text; var x1 = document.getElementById('answer_Q15_5_1'); var x2 = document.getElementById('answer_Q15_5_2'); var x3 = document.getElementById('answer_Q15_5_3'); var x4 = document.getElementById('answer_Q15_5_4'); var x5 = document.getElementById('answer_Q15_5_5'); var x6 = document.getElementById('answer_Q15_5_6'); if (x1.checked == true&x2.checked == false&x3.checked == true&x4.checked == false&x5.checked == false&x6.checked == true){text = 'That‚Äôs right!';} else {text = 'No, not quite.';} document.getElementById('result_Q15_5').innerHTML = text; evaluate_final_score(); return false;}function evaluate_final_score(){
         element = document.getElementById('checkdown_final_score');
         if(element === null){return false;} else {var element, text, res1, res2, res3, res4, res5;res1 = document.getElementById('result_Q15_1').innerText == 'That‚Äôs right, well done! Which metaphor(s) do you like best?The term ‚Äòstocastic parrot‚Äô is probably the best known LLM metaphor. It was introduced by computational linguist Emily M. Bender and colleagues in 2021 to characterise LLMs as systems that mimic text without true understanding, highlighting their limitations in processing meaning. This metaphor emphasises that LLMs generate outputs based on statistical patterns in their training data, similar to how parrots mimic sounds without comprehension.In 2022, the cognitive scientist Iris Van Rooij published a blog post in which she succictly explains why she believes that LLMs cannot legitimately be used for academic writing because they essentially automate plagiarism.The ‚Äòspicy autocomplete‚Äô metaphor is difficult to trace back to one or more specific author(s). It suggests that LLMs are just fancy versions of a smart phone‚Äôs predictive text, which predict the next word based on what came before, except that LLMs add some randomness, i.e. spice, to the output. This framing also implies that LLMs are pattern-matching algorithms without real understanding or problem-solving ability (see Gro√ü 2024).In 2024, Hicks, Humphries &amp; Slater published a paper in the journal ‚ÄòEthics and Information Technology‚Äô entitled ‚ÄòChatGPT is bullshit‚Äô, in which they argue that the output of LLMs is best understood as ‚Äòbullshit‚Äô in the philosophical sense described by Frankfurt (2005) because LLMs are indifferent to the truth of their outputs.‚ÄòSynthetic text extruding machines‚Äô is a term that Emily M. Bender and Alex Hanna like to use, e.g. in their 2025 book entitled ‚ÄòThe AI Con: How to Fight Big Tech‚Äôs Hype and Create the Future We Want‚Äô. They describe the process of LLM-generated texts by explaining that, ‚Äú[l]ike an industrial plastic process, language corpora are forced through complicated machinery to produce a product that looks like communicative language, but without any intent or thinking mind behind it.‚ÄùAs an alternative to well-established metaphors such as the ones listed above, classical philologist Gyburg Uhlmann proposed ‚Äòkitsch‚Äô as a new metaphor to describe the output of LLMs. She argues that ‚Äòkitsch‚Äô ‚Äúis particularly suitable for analytically illuminating a previously neglected feature of LLM-based images and texts: their tendency to produce homogeneous and average content, which is [‚Ä¶] leading to the equalisation of language, style and argument‚Äù (Uhlmann 2025).'; res2 = document.getElementById('result_Q15_2').innerText == 'That‚Äôs right!'; res3 = document.getElementById('result_Q15_3').innerText == 'That‚Äôs right!'; res4 = document.getElementById('result_Q15_4').innerText == 'That‚Äôs right!'; res5 = document.getElementById('result_Q15_5').innerText == 'That‚Äôs right!';text = res1 + res2 + res3 + res4 + res5;element.innerHTML = text;
         return false;
         }}</script>
</div>
</div>
</div>
</div>
</div>
<p>When it comes to programming, the use of LLMs may seem less risky than when conducting literature reviews, writing prose, or analysing data. After all, we can test that generated code runs as expected. If it does not (which is often the case although we might not immediately spot this), we can debug the code with the support of one or more LLMs until it does. Whilst this might feel like the path of least resistance, data scientist, <code>R</code> developer, and educator, Mine √áetinkaya-Rundel, explains how debugging someone else‚Äôs code (e.g., what an LLM produced) is considerably harder than debugging our own code <span class="citation" data-cites="chowEpisode4Mine">(<a href="99_references.html#ref-chowEpisode4Mine" role="doc-biblioref">Chow, Wickham &amp; Mckinney 2025</a>)</span>. This is because when it‚Äôs our own code, we had an idea, followed a certain example, or a specific strategy and this knowledge helps us debug in a systematic way. Crucially, each problem or error is an opportunity to learn. Relying on LLM-generated code to solve these errors robs us of these opportunities.</p>
<blockquote class="blockquote">
<p>AI can‚Äôt learn from its mistakes‚Äîit doesn‚Äôt understand why something failed. It just pattern-matches from training data <span class="citation" data-cites="stetskovGreatSoftwareQuality2025">(<a href="99_references.html#ref-stetskovGreatSoftwareQuality2025" role="doc-biblioref">Stetskov 2025</a>: n.p.)</span>.</p>
</blockquote>
<p>Research on the mid- to long-term impact of AI usage on cognitive abilities such as writing, coding, and critical thinking is still in its infancy; however, a number of studies point towards a very genuine risk of <strong>deskilling</strong> <span class="citation" data-cites="ferdman2025">(see e.g. <a href="99_references.html#ref-ferdman2025" role="doc-biblioref">Ferdman 2025</a>)</span> in many domains of use <span class="citation" data-cites="natali2025">(e.g.&nbsp;medicine, see <a href="99_references.html#ref-natali2025" role="doc-biblioref">Natali et al. 2025</a>)</span>. In the context of AI-assisted coding, researchers from Anthropic (the company behind the Claude family of AI products) conducted a pre-registered <span class="citation" data-cites="tamkin2026">(<a href="99_references.html#ref-tamkin2026" role="doc-biblioref">Tamkin &amp; Shen 2026</a>)</span> experiment in which 52 (mostly junior) software developers completed a programming task using a Python library that they were not familiar with and were subsequently tested for their understanding of the code. <span class="citation" data-cites="tamkin2026">Tamkin &amp; Shen (<a href="99_references.html#ref-tamkin2026" role="doc-biblioref">2026</a>)</span> compared:</p>
<ol type="a">
<li>how quickly the programmers completed the task with and without AI assistance and</li>
<li>whether using AI made them less, more, or equally likely to understand the code they had just written.</li>
</ol>
<div id="fig-ShenTamkin" class="quarto-float quarto-figure quarto-figure-center anchored" alt="Two plots: the first shows the average time taken to complete the experimental task. The average with AI was 23 minutes, and without AI nearly 25. But the confidence intervals overlap considerably. The second plot shows average test scores. Here the difference is much clearer: the AI group scores 50% on average, whilst the non-AI control group scores around 65%.">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-ShenTamkin-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<a href="images/Shen_Tamkin2026_Fig1.png" class="lightbox" data-gallery="quarto-lightbox-gallery-7" title="Figure&nbsp;15.5: Difference in means (and 95% CI error bars) of overall task time and test scores between the treatment (AI Assistant) and control (No AI) groups (n&nbsp;=&nbsp;52) [Source: @tamkin2026: Fig.&nbsp;1]"><img src="images/Shen_Tamkin2026_Fig1.png" class="img-fluid figure-img" alt="Two plots: the first shows the average time taken to complete the experimental task. The average with AI was 23 minutes, and without AI nearly 25. But the confidence intervals overlap considerably. The second plot shows average test scores. Here the difference is much clearer: the AI group scores 50% on average, whilst the non-AI control group scores around 65%."></a>
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-ShenTamkin-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;15.5: Difference in means (and 95% CI error bars) of overall task time and test scores between the treatment (AI Assistant) and control (No AI) groups (n&nbsp;=&nbsp;52) <span class="citation" data-cites="tamkin2026">(Source: <a href="99_references.html#ref-tamkin2026" role="doc-biblioref">Tamkin &amp; Shen 2026</a>: Fig.&nbsp;1)</span>
</figcaption>
</figure>
</div>
<p>On average, the participants assigned to the AI assistance group completed the programming task about two minutes faster than those who worked without AI, but this difference was not statistically significant (<em>p</em>&nbsp;=&nbsp;0.391). There was, however, a significant difference in their code comprehension test scores: the AI group averaged 50% on the test, compared to 67% in the group that did not have access to AI (Cohen‚Äôs&nbsp;<em>d</em>&nbsp;=&nbsp;0.738, <em>p</em>&nbsp;=&nbsp;0.01), which the authors claim corresponds to a difference of ‚Äútwo grade points‚Äù <span class="citation" data-cites="tamkin2026">(<a href="99_references.html#ref-tamkin2026" role="doc-biblioref">Tamkin &amp; Shen 2026</a>: 2)</span>. <span class="citation" data-cites="tamkin2026">Tamkin &amp; Shen (<a href="99_references.html#ref-tamkin2026" role="doc-biblioref">2026</a>)</span> also report that the largest gap in scores between the two groups was on debugging questions. They attribute the gains in skill development of the group that did not use AI to ‚Äúthe process of encountering and subsequently resolving errors independently‚Äù <span class="citation" data-cites="tamkin2026">(<a href="99_references.html#ref-tamkin2026" role="doc-biblioref">Tamkin &amp; Shen 2026</a>: 2-3)</span>.</p>
<blockquote class="blockquote">
<p>Senior developers don‚Äôt grow out of thin air [‚Ä¶&nbsp;They] develop intuition through thousands of small failures <span class="citation" data-cites="stetskovGreatSoftwareQuality2025">(<a href="99_references.html#ref-stetskovGreatSoftwareQuality2025" role="doc-biblioref">Stetskov 2025</a>: n.p.)</span>.</p>
</blockquote>
<div class="callout callout-style-default callout-tip callout-titled">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-5-contents" aria-controls="callout-5" aria-expanded="true" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
<span class="screen-reader-only">Tip</span>Your turn!
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-5" class="callout-5-contents callout-collapse collapse show">
<div class="callout-body-container callout-body">
<p>As part of an exploratory, not pre-registered, analysis, <span class="citation" data-cites="tamkin2026">Tamkin &amp; Shen (<a href="99_references.html#ref-tamkin2026" role="doc-biblioref">2026</a>)</span> from Anthropic (see <a href="#sec-HumanLearning" class="quarto-xref"><span>Section 15.3</span></a>) decomposed the quiz scores into sub-areas and question types (see <a href="#fig-TamkinShenFig8" class="quarto-xref">Figure&nbsp;<span>15.6</span></a>). Each question in the quiz belonged to exactly one task (e.g., Task 1 or Task 2) and exactly one question type (e.g., Conceptual, Debugging, or Code Reading). <a href="#fig-TamkinShenFig8" class="quarto-xref">Figure&nbsp;<span>15.6</span></a> shows that, for both tasks, the control (no AI) group performed better than the AI group.</p>
<div id="fig-TamkinShenFig8" class="quarto-float quarto-figure quarto-figure-center anchored" alt="A plot showing participants' average scores in each type of quiz questions together with 95% CI error bars. Across all subareas of the quiz (task 1, task 2, conceptual, debugging, and code reading), the control, no AI group performed better on average than the treatment, AI group. However, the 95% CI intervals of the two groups always overlap to a smaller or larger degree. The difference in average scores is largest for the debugging questions and smallest for the code reading.">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-TamkinShenFig8-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<a href="http://arxiv.org/abs/2601.20245"><span class="lightbox" data-gallery="quarto-lightbox-gallery-8"><img src="images/Shen_Tamkin2026_Fig8.png" class="img-fluid figure-img" alt="A plot showing participants' average scores in each type of quiz questions together with 95% CI error bars. Across all subareas of the quiz (task 1, task 2, conceptual, debugging, and code reading), the control, no AI group performed better on average than the treatment, AI group. However, the 95% CI intervals of the two groups always overlap to a smaller or larger degree. The difference in average scores is largest for the debugging questions and smallest for the code reading."></span></a>
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-TamkinShenFig8-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;15.6: Score breakdown by questions type relating to each task and skill area
</figcaption>
</figure>
</div>
<p><span style="color:green;"><strong>Q15.6</strong></span> Looking at the results displayed in <a href="#fig-TamkinShenFig8" class="quarto-xref">Figure&nbsp;<span>15.6</span></a>, which question type shows the largest difference in average quiz scores between the treatment and control groups?</p>
<div class="cell">
<div class="cell-output-display">
<form name="form_Q15_6" onsubmit="return validate_form_Q15_6()" method="post">
<label>
<input type="radio" name="answer_Q15_6" id="answer_Q15_6_1" value="Conceptual">
Conceptual
</label>
<br>
<label>
<input type="radio" name="answer_Q15_6" id="answer_Q15_6_2" value="Debugging">
Debugging
</label>
<br>
<label>
<input type="radio" name="answer_Q15_6" id="answer_Q15_6_3" value="Code Reading">
Code Reading
</label>
<br>
<input type="submit" value="Check answer">
<div id="result_Q15_6"></div>
</form>
<script>function validate_form_Q15_6() {var x, text; var x = document.forms['form_Q15_6']['answer_Q15_6'].value;if (x == 'Debugging'){text = 'That‚Äôs right! The debugging questions show the largest difference between the treatment (AI) and the control (no AI) groups.';} else {text = 'No, that‚Äôs not it. Look for the question type with the greatest vertical distance between the treatment (AI) and control (no AI) group averages (represented as dots).';} document.getElementById('result_Q15_6').innerHTML = text; evaluate_final_score(); return false;}function evaluate_final_score(){
         element = document.getElementById('checkdown_final_score');
         if(element === null){return false;} else {var element, text, res1, res2, res3, res4, res5, res6;res1 = document.getElementById('result_Q15_1').innerText == 'That‚Äôs right, well done! Which metaphor(s) do you like best?The term ‚Äòstocastic parrot‚Äô is probably the best known LLM metaphor. It was introduced by computational linguist Emily M. Bender and colleagues in 2021 to characterise LLMs as systems that mimic text without true understanding, highlighting their limitations in processing meaning. This metaphor emphasises that LLMs generate outputs based on statistical patterns in their training data, similar to how parrots mimic sounds without comprehension.In 2022, the cognitive scientist Iris Van Rooij published a blog post in which she succictly explains why she believes that LLMs cannot legitimately be used for academic writing because they essentially automate plagiarism.The ‚Äòspicy autocomplete‚Äô metaphor is difficult to trace back to one or more specific author(s). It suggests that LLMs are just fancy versions of a smart phone‚Äôs predictive text, which predict the next word based on what came before, except that LLMs add some randomness, i.e. spice, to the output. This framing also implies that LLMs are pattern-matching algorithms without real understanding or problem-solving ability (see Gro√ü 2024).In 2024, Hicks, Humphries &amp; Slater published a paper in the journal ‚ÄòEthics and Information Technology‚Äô entitled ‚ÄòChatGPT is bullshit‚Äô, in which they argue that the output of LLMs is best understood as ‚Äòbullshit‚Äô in the philosophical sense described by Frankfurt (2005) because LLMs are indifferent to the truth of their outputs.‚ÄòSynthetic text extruding machines‚Äô is a term that Emily M. Bender and Alex Hanna like to use, e.g. in their 2025 book entitled ‚ÄòThe AI Con: How to Fight Big Tech‚Äôs Hype and Create the Future We Want‚Äô. They describe the process of LLM-generated texts by explaining that, ‚Äú[l]ike an industrial plastic process, language corpora are forced through complicated machinery to produce a product that looks like communicative language, but without any intent or thinking mind behind it.‚ÄùAs an alternative to well-established metaphors such as the ones listed above, classical philologist Gyburg Uhlmann proposed ‚Äòkitsch‚Äô as a new metaphor to describe the output of LLMs. She argues that ‚Äòkitsch‚Äô ‚Äúis particularly suitable for analytically illuminating a previously neglected feature of LLM-based images and texts: their tendency to produce homogeneous and average content, which is [‚Ä¶] leading to the equalisation of language, style and argument‚Äù (Uhlmann 2025).'; res2 = document.getElementById('result_Q15_2').innerText == 'That‚Äôs right!'; res3 = document.getElementById('result_Q15_3').innerText == 'That‚Äôs right!'; res4 = document.getElementById('result_Q15_4').innerText == 'That‚Äôs right!'; res5 = document.getElementById('result_Q15_5').innerText == 'That‚Äôs right!'; res6 = document.getElementById('result_Q15_6').innerText == 'That‚Äôs right! The debugging questions show the largest difference between the treatment (AI) and the control (no AI) groups.';text = res1 + res2 + res3 + res4 + res5 + res6;element.innerHTML = text;
         return false;
         }}</script>
</div>
</div>
<p>&nbsp;</p>
<p><span style="color:green;"><strong>Q15.7</strong></span> Why might the control group have, on average, performed better on debugging questions compared to the AI group?</p>
<div class="cell">
<div class="cell-output-display">
<form name="form_Q15_7" onsubmit="return validate_form_Q15_7()" method="post">
<label>
<input type="checkbox" id="answer_Q15_7_1" value="The AI tool was specifically designed to help with debugging, giving the treatment group a clear advantage.">
The AI tool was specifically designed to help with debugging, giving the treatment group a clear advantage.
</label>
<br>
<label>
<input type="checkbox" id="answer_Q15_7_2" value="The debugging questions were easier than the rest, so both groups scored high, and the treatment group only scored slightly higher by chance.">
The debugging questions were easier than the rest, so both groups scored high, and the treatment group only scored slightly higher by chance.
</label>
<br>
<label>
<input type="checkbox" id="answer_Q15_7_3" value="The treatment group had more practice with debugging during the experimental task.">
The treatment group had more practice with debugging during the experimental task.
</label>
<br>
<label>
<input type="checkbox" id="answer_Q15_7_4" value="The control group had no AI assistance, so they encountered more errors during the task and gained more experience debugging.">
The control group had no AI assistance, so they encountered more errors during the task and gained more experience debugging.
</label>
<br>
<input type="submit" value="Check answer">
<div id="result_Q15_7"></div>
</form>
<script>function validate_form_Q15_7() {var text; var x1 = document.getElementById('answer_Q15_7_1'); var x2 = document.getElementById('answer_Q15_7_2'); var x3 = document.getElementById('answer_Q15_7_3'); var x4 = document.getElementById('answer_Q15_7_4'); if (x1.checked == false&x2.checked == false&x3.checked == false&x4.checked == true){text = 'That‚Äôs right! The authors of the study conclude that, without relying on ‚ÄúAI‚Äù help, the control group made more errors and developed stronger debugging skills through experience.';} else {text = 'Not quite. Consider how not having access to ‚ÄúAI‚Äù assistance might have led to more hands-on debugging practice.';} document.getElementById('result_Q15_7').innerHTML = text; evaluate_final_score(); return false;}function evaluate_final_score(){
         element = document.getElementById('checkdown_final_score');
         if(element === null){return false;} else {var element, text, res1, res2, res3, res4, res5, res6, res7;res1 = document.getElementById('result_Q15_1').innerText == 'That‚Äôs right, well done! Which metaphor(s) do you like best?The term ‚Äòstocastic parrot‚Äô is probably the best known LLM metaphor. It was introduced by computational linguist Emily M. Bender and colleagues in 2021 to characterise LLMs as systems that mimic text without true understanding, highlighting their limitations in processing meaning. This metaphor emphasises that LLMs generate outputs based on statistical patterns in their training data, similar to how parrots mimic sounds without comprehension.In 2022, the cognitive scientist Iris Van Rooij published a blog post in which she succictly explains why she believes that LLMs cannot legitimately be used for academic writing because they essentially automate plagiarism.The ‚Äòspicy autocomplete‚Äô metaphor is difficult to trace back to one or more specific author(s). It suggests that LLMs are just fancy versions of a smart phone‚Äôs predictive text, which predict the next word based on what came before, except that LLMs add some randomness, i.e. spice, to the output. This framing also implies that LLMs are pattern-matching algorithms without real understanding or problem-solving ability (see Gro√ü 2024).In 2024, Hicks, Humphries &amp; Slater published a paper in the journal ‚ÄòEthics and Information Technology‚Äô entitled ‚ÄòChatGPT is bullshit‚Äô, in which they argue that the output of LLMs is best understood as ‚Äòbullshit‚Äô in the philosophical sense described by Frankfurt (2005) because LLMs are indifferent to the truth of their outputs.‚ÄòSynthetic text extruding machines‚Äô is a term that Emily M. Bender and Alex Hanna like to use, e.g. in their 2025 book entitled ‚ÄòThe AI Con: How to Fight Big Tech‚Äôs Hype and Create the Future We Want‚Äô. They describe the process of LLM-generated texts by explaining that, ‚Äú[l]ike an industrial plastic process, language corpora are forced through complicated machinery to produce a product that looks like communicative language, but without any intent or thinking mind behind it.‚ÄùAs an alternative to well-established metaphors such as the ones listed above, classical philologist Gyburg Uhlmann proposed ‚Äòkitsch‚Äô as a new metaphor to describe the output of LLMs. She argues that ‚Äòkitsch‚Äô ‚Äúis particularly suitable for analytically illuminating a previously neglected feature of LLM-based images and texts: their tendency to produce homogeneous and average content, which is [‚Ä¶] leading to the equalisation of language, style and argument‚Äù (Uhlmann 2025).'; res2 = document.getElementById('result_Q15_2').innerText == 'That‚Äôs right!'; res3 = document.getElementById('result_Q15_3').innerText == 'That‚Äôs right!'; res4 = document.getElementById('result_Q15_4').innerText == 'That‚Äôs right!'; res5 = document.getElementById('result_Q15_5').innerText == 'That‚Äôs right!'; res6 = document.getElementById('result_Q15_6').innerText == 'That‚Äôs right! The debugging questions show the largest difference between the treatment (AI) and the control (no AI) groups.'; res7 = document.getElementById('result_Q15_7').innerText == 'That‚Äôs right! The authors of the study conclude that, without relying on ‚ÄúAI‚Äù help, the control group made more errors and developed stronger debugging skills through experience.';text = res1 + res2 + res3 + res4 + res5 + res6 + res7;element.innerHTML = text;
         return false;
         }}</script>
</div>
<div class="cell-output-display">
<div id="hint_33076" onclick="return show_hint_33076()">üê≠ Click on the mouse for a hint.</div>
<div id="result_33076" onclick="return show_hint_33076()"></div>
<script>function show_hint_33076(){var x = document.getElementById('result_33076').innerHTML; if(!x){document.getElementById('result_33076').innerHTML = 'The authors of the study only mention one of these as a possible reason. Which do you think is mostly likely?';} else {document.getElementById('result_33076').innerHTML = '';}}</script>
</div>
</div>
<p>&nbsp;</p>
<p><span style="color:green;"><strong>Q15.8</strong></span> What do the results displayed in <a href="#fig-TamkinShenFig8" class="quarto-xref">Figure&nbsp;<span>15.6</span></a> suggest about the impact of AI assistance on code reading skills?</p>
<div class="cell">
<div class="cell-output-display">
<form name="form_Q15_8" onsubmit="return validate_form_Q15_8()" method="post">
<label>
<input type="radio" name="answer_Q15_8" id="answer_Q15_8_1" value="Both groups had similar exposure to reading code through the task, so the AI and non-AI groups performed similarly.">
Both groups had similar exposure to reading code through the task, so the AI and non-AI groups performed similarly.
</label>
<br>
<label>
<input type="radio" name="answer_Q15_8" id="answer_Q15_8_2" value="The confidence intervals corresponding to the code reading questions overlap too much to be able to draw any conclusions.">
The confidence intervals corresponding to the code reading questions overlap too much to be able to draw any conclusions.
</label>
<br>
<label>
<input type="radio" name="answer_Q15_8" id="answer_Q15_8_3" value="The AI tool significantly improved code reading performance for the treatment group.">
The AI tool significantly improved code reading performance for the treatment group.
</label>
<br>
<label>
<input type="radio" name="answer_Q15_8" id="answer_Q15_8_4" value="The control group had more experience reading code, so they scored considerably higher.">
The control group had more experience reading code, so they scored considerably higher.
</label>
<br>
<input type="submit" value="Check answer">
<div id="result_Q15_8"></div>
</form>
<script>function validate_form_Q15_8() {var x, text; var x = document.forms['form_Q15_8']['answer_Q15_8'].value;if (x == 'Both groups had similar exposure to reading code through the task, so the AI and non-AI groups performed similarly.'){text = 'Indeed, the authors of the study write that the small gap suggests similar exposure and learning in code reading across groups.';} else {text = 'No, the small gap actually implies that AI assistance did not provide a major advantage in this area. Why might that be?';} document.getElementById('result_Q15_8').innerHTML = text; evaluate_final_score(); return false;}function evaluate_final_score(){
         element = document.getElementById('checkdown_final_score');
         if(element === null){return false;} else {var element, text, res1, res2, res3, res4, res5, res6, res7, res8;res1 = document.getElementById('result_Q15_1').innerText == 'That‚Äôs right, well done! Which metaphor(s) do you like best?The term ‚Äòstocastic parrot‚Äô is probably the best known LLM metaphor. It was introduced by computational linguist Emily M. Bender and colleagues in 2021 to characterise LLMs as systems that mimic text without true understanding, highlighting their limitations in processing meaning. This metaphor emphasises that LLMs generate outputs based on statistical patterns in their training data, similar to how parrots mimic sounds without comprehension.In 2022, the cognitive scientist Iris Van Rooij published a blog post in which she succictly explains why she believes that LLMs cannot legitimately be used for academic writing because they essentially automate plagiarism.The ‚Äòspicy autocomplete‚Äô metaphor is difficult to trace back to one or more specific author(s). It suggests that LLMs are just fancy versions of a smart phone‚Äôs predictive text, which predict the next word based on what came before, except that LLMs add some randomness, i.e. spice, to the output. This framing also implies that LLMs are pattern-matching algorithms without real understanding or problem-solving ability (see Gro√ü 2024).In 2024, Hicks, Humphries &amp; Slater published a paper in the journal ‚ÄòEthics and Information Technology‚Äô entitled ‚ÄòChatGPT is bullshit‚Äô, in which they argue that the output of LLMs is best understood as ‚Äòbullshit‚Äô in the philosophical sense described by Frankfurt (2005) because LLMs are indifferent to the truth of their outputs.‚ÄòSynthetic text extruding machines‚Äô is a term that Emily M. Bender and Alex Hanna like to use, e.g. in their 2025 book entitled ‚ÄòThe AI Con: How to Fight Big Tech‚Äôs Hype and Create the Future We Want‚Äô. They describe the process of LLM-generated texts by explaining that, ‚Äú[l]ike an industrial plastic process, language corpora are forced through complicated machinery to produce a product that looks like communicative language, but without any intent or thinking mind behind it.‚ÄùAs an alternative to well-established metaphors such as the ones listed above, classical philologist Gyburg Uhlmann proposed ‚Äòkitsch‚Äô as a new metaphor to describe the output of LLMs. She argues that ‚Äòkitsch‚Äô ‚Äúis particularly suitable for analytically illuminating a previously neglected feature of LLM-based images and texts: their tendency to produce homogeneous and average content, which is [‚Ä¶] leading to the equalisation of language, style and argument‚Äù (Uhlmann 2025).'; res2 = document.getElementById('result_Q15_2').innerText == 'That‚Äôs right!'; res3 = document.getElementById('result_Q15_3').innerText == 'That‚Äôs right!'; res4 = document.getElementById('result_Q15_4').innerText == 'That‚Äôs right!'; res5 = document.getElementById('result_Q15_5').innerText == 'That‚Äôs right!'; res6 = document.getElementById('result_Q15_6').innerText == 'That‚Äôs right! The debugging questions show the largest difference between the treatment (AI) and the control (no AI) groups.'; res7 = document.getElementById('result_Q15_7').innerText == 'That‚Äôs right! The authors of the study conclude that, without relying on ‚ÄúAI‚Äù help, the control group made more errors and developed stronger debugging skills through experience.'; res8 = document.getElementById('result_Q15_8').innerText == 'Indeed, the authors of the study write that the small gap suggests similar exposure and learning in code reading across groups.';text = res1 + res2 + res3 + res4 + res5 + res6 + res7 + res8;element.innerHTML = text;
         return false;
         }}</script>
</div>
</div>
</div>
</div>
</div>
</section>
<section id="on-the-value-of-the-commons" class="level2" data-number="15.4">
<h2 data-number="15.4" class="anchored" data-anchor-id="on-the-value-of-the-commons"><span class="header-section-number">15.4</span> On the value of the commons</h2>
<p>It is worth pointing out that the programmers in the control, no AI group in the aforementioned Anthropic study <span class="citation" data-cites="tamkin2026">(<a href="99_references.html#ref-tamkin2026" role="doc-biblioref">Tamkin &amp; Shen 2026</a>)</span> did not write code with no help whatsoever. Instead, they had access to regular web searching and code documentation. It is a common misconception that learning to code involves memorising lots of functions and commands. In practice, programming always involves looking things up. Up until very recently, researchers would typically search the web to find answers to their coding problems instead of prompting an AI product. These searches led us to interesting forum discussions, blog posts by fellow researchers and developers, and helpful documentation files (e.g.&nbsp;in the form of so-called ‚Äò<a href="https://r-pkgs.org/vignettes.html">vignettes</a>‚Äô). If our web search did not help us solve our problem, we prepared a <strong>reprex,</strong> short for minimal <strong>repr</strong>oducible <strong>ex</strong>ample <span class="citation" data-cites="wickhamDataScienceImport2023">(see <a href="99_references.html#ref-wickhamDataScienceImport2023" role="doc-biblioref">Wickham, √áetinkaya-Rundel &amp; Grolemund 2023</a>: <a href="https://r4ds.hadley.nz/workflow-help.html">Ch. 8</a> on getting help)</span>, posted it on a dedicated forum and community members would typically provide helpful answers within days or even hours.</p>
<p>All of these contents were human-generated. Not all were 100% reliable, but high-quality answers to problems on <a href="https://stackoverflow.com/questions">StackOverflow</a>, for example, were upvoted by readers and errors in the documentation of open-source packages were quickly identified and corrected by the community of users. The same principle was true of statistical questions. Today, this strategy is still viable but, unfortunately, there are a lot of AI-generated webpages (‚ÄòAI slop‚Äô) that one first needs to ignore.</p>
<div class="callout callout-style-default callout-tip callout-titled">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-6-contents" aria-controls="callout-6" aria-expanded="true" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
<span class="screen-reader-only">Tip</span>Your turn!
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-6" class="callout-6-contents callout-collapse collapse show">
<div class="callout-body-container callout-body">
<p><span style="color:green;"><strong>Q15.9</strong></span> What is <a href="https://stats.stackexchange.com/">Stack Exchange</a>?</p>
<div class="cell">
<div class="cell-output-display">
<form name="form_Q15_9" onsubmit="return validate_form_Q15_9()" method="post">
<label>
<input type="radio" name="answer_Q15_9" id="answer_Q15_9_1" value="An open-source tool for managing project tasks and workflows that is widely used in academic research.">
An open-source tool for managing project tasks and workflows that is widely used in academic research.
</label>
<br>
<label>
<input type="radio" name="answer_Q15_9" id="answer_Q15_9_2" value="A free cloud-based service for hosting and managing data and code repositories.">
A free cloud-based service for hosting and managing data and code repositories.
</label>
<br>
<label>
<input type="radio" name="answer_Q15_9" id="answer_Q15_9_3" value="An open-source social media platform for sharing photos and videos about research and programming.">
An open-source social media platform for sharing photos and videos about research and programming.
</label>
<br>
<label>
<input type="radio" name="answer_Q15_9" id="answer_Q15_9_4" value="A network of websites where people can ask and answer questions on a wide range of topics, the most popular of which is StackOverflow for programming questions.">
A network of websites where people can ask and answer questions on a wide range of topics, the most popular of which is StackOverflow for programming questions.
</label>
<br>
<label>
<input type="radio" name="answer_Q15_9" id="answer_Q15_9_5" value="An online game for learning about programming and statistics, among other topics.">
An online game for learning about programming and statistics, among other topics.
</label>
<br>
<input type="submit" value="Check answer">
<div id="result_Q15_9"></div>
</form>
<script>function validate_form_Q15_9() {var x, text; var x = document.forms['form_Q15_9']['answer_Q15_9'].value;if (x == 'A network of websites where people can ask and answer questions on a wide range of topics, the most popular of which is StackOverflow for programming questions.'){text = 'That‚Äôs right!';} else {text = 'No, not quite.';} document.getElementById('result_Q15_9').innerHTML = text; evaluate_final_score(); return false;}function evaluate_final_score(){
         element = document.getElementById('checkdown_final_score');
         if(element === null){return false;} else {var element, text, res1, res2, res3, res4, res5, res6, res7, res8, res9;res1 = document.getElementById('result_Q15_1').innerText == 'That‚Äôs right, well done! Which metaphor(s) do you like best?The term ‚Äòstocastic parrot‚Äô is probably the best known LLM metaphor. It was introduced by computational linguist Emily M. Bender and colleagues in 2021 to characterise LLMs as systems that mimic text without true understanding, highlighting their limitations in processing meaning. This metaphor emphasises that LLMs generate outputs based on statistical patterns in their training data, similar to how parrots mimic sounds without comprehension.In 2022, the cognitive scientist Iris Van Rooij published a blog post in which she succictly explains why she believes that LLMs cannot legitimately be used for academic writing because they essentially automate plagiarism.The ‚Äòspicy autocomplete‚Äô metaphor is difficult to trace back to one or more specific author(s). It suggests that LLMs are just fancy versions of a smart phone‚Äôs predictive text, which predict the next word based on what came before, except that LLMs add some randomness, i.e. spice, to the output. This framing also implies that LLMs are pattern-matching algorithms without real understanding or problem-solving ability (see Gro√ü 2024).In 2024, Hicks, Humphries &amp; Slater published a paper in the journal ‚ÄòEthics and Information Technology‚Äô entitled ‚ÄòChatGPT is bullshit‚Äô, in which they argue that the output of LLMs is best understood as ‚Äòbullshit‚Äô in the philosophical sense described by Frankfurt (2005) because LLMs are indifferent to the truth of their outputs.‚ÄòSynthetic text extruding machines‚Äô is a term that Emily M. Bender and Alex Hanna like to use, e.g. in their 2025 book entitled ‚ÄòThe AI Con: How to Fight Big Tech‚Äôs Hype and Create the Future We Want‚Äô. They describe the process of LLM-generated texts by explaining that, ‚Äú[l]ike an industrial plastic process, language corpora are forced through complicated machinery to produce a product that looks like communicative language, but without any intent or thinking mind behind it.‚ÄùAs an alternative to well-established metaphors such as the ones listed above, classical philologist Gyburg Uhlmann proposed ‚Äòkitsch‚Äô as a new metaphor to describe the output of LLMs. She argues that ‚Äòkitsch‚Äô ‚Äúis particularly suitable for analytically illuminating a previously neglected feature of LLM-based images and texts: their tendency to produce homogeneous and average content, which is [‚Ä¶] leading to the equalisation of language, style and argument‚Äù (Uhlmann 2025).'; res2 = document.getElementById('result_Q15_2').innerText == 'That‚Äôs right!'; res3 = document.getElementById('result_Q15_3').innerText == 'That‚Äôs right!'; res4 = document.getElementById('result_Q15_4').innerText == 'That‚Äôs right!'; res5 = document.getElementById('result_Q15_5').innerText == 'That‚Äôs right!'; res6 = document.getElementById('result_Q15_6').innerText == 'That‚Äôs right! The debugging questions show the largest difference between the treatment (AI) and the control (no AI) groups.'; res7 = document.getElementById('result_Q15_7').innerText == 'That‚Äôs right! The authors of the study conclude that, without relying on ‚ÄúAI‚Äù help, the control group made more errors and developed stronger debugging skills through experience.'; res8 = document.getElementById('result_Q15_8').innerText == 'Indeed, the authors of the study write that the small gap suggests similar exposure and learning in code reading across groups.'; res9 = document.getElementById('result_Q15_9').innerText == 'That‚Äôs right!';text = res1 + res2 + res3 + res4 + res5 + res6 + res7 + res8 + res9;element.innerHTML = text;
         return false;
         }}</script>
</div>
<div class="cell-output-display">
<div id="hint_62335" onclick="return show_hint_62335()">üê≠ Click on the mouse for a hint.</div>
<div id="result_62335" onclick="return show_hint_62335()"></div>
<script>function show_hint_62335(){var x = document.getElementById('result_62335').innerHTML; if(!x){document.getElementById('result_62335').innerHTML = 'Find out more by heading to <a href="https://stats.stackexchange.com/">https://stats.stackexchange.com/</a>.';} else {document.getElementById('result_62335').innerHTML = '';}}</script>
</div>
</div>
<p>&nbsp;</p>
<p><span style="color:green;"><strong>Q15.10</strong></span> Open this <a href="https://web.archive.org/web/20260209093908/https://stats.stackexchange.com/questions/11609/clarification-on-interpreting-confidence-intervals">archived version</a> of a Q&amp;A about confidence intervals hosted on Cross Validated, Stack Exchange‚Äôs statistics forum. In which year did Eliott originally ask their question?</p>
<div class="cell">
<div class="cell-output-display">
<form name="form_Q15_10" onsubmit="return validate_form_Q15_10()" method="post">
<input type="text" placeholder="" name="answer_Q15_10">
<input type="submit" value="Check answer">
<div id="result_Q15_10"></div>
</form>
<script>function validate_form_Q15_10() {var x, text; var x = document.forms['form_Q15_10']['answer_Q15_10'].value;if (x == '2011'){text = 'That‚Äôs right!';} else {text = 'No, not quite.';} document.getElementById('result_Q15_10').innerHTML = text; evaluate_final_score(); return false;}function evaluate_final_score(){
         element = document.getElementById('checkdown_final_score');
         if(element === null){return false;} else {var element, text, res1, res2, res3, res4, res5, res6, res7, res8, res9, res10;res1 = document.getElementById('result_Q15_1').innerText == 'That‚Äôs right, well done! Which metaphor(s) do you like best?The term ‚Äòstocastic parrot‚Äô is probably the best known LLM metaphor. It was introduced by computational linguist Emily M. Bender and colleagues in 2021 to characterise LLMs as systems that mimic text without true understanding, highlighting their limitations in processing meaning. This metaphor emphasises that LLMs generate outputs based on statistical patterns in their training data, similar to how parrots mimic sounds without comprehension.In 2022, the cognitive scientist Iris Van Rooij published a blog post in which she succictly explains why she believes that LLMs cannot legitimately be used for academic writing because they essentially automate plagiarism.The ‚Äòspicy autocomplete‚Äô metaphor is difficult to trace back to one or more specific author(s). It suggests that LLMs are just fancy versions of a smart phone‚Äôs predictive text, which predict the next word based on what came before, except that LLMs add some randomness, i.e. spice, to the output. This framing also implies that LLMs are pattern-matching algorithms without real understanding or problem-solving ability (see Gro√ü 2024).In 2024, Hicks, Humphries &amp; Slater published a paper in the journal ‚ÄòEthics and Information Technology‚Äô entitled ‚ÄòChatGPT is bullshit‚Äô, in which they argue that the output of LLMs is best understood as ‚Äòbullshit‚Äô in the philosophical sense described by Frankfurt (2005) because LLMs are indifferent to the truth of their outputs.‚ÄòSynthetic text extruding machines‚Äô is a term that Emily M. Bender and Alex Hanna like to use, e.g. in their 2025 book entitled ‚ÄòThe AI Con: How to Fight Big Tech‚Äôs Hype and Create the Future We Want‚Äô. They describe the process of LLM-generated texts by explaining that, ‚Äú[l]ike an industrial plastic process, language corpora are forced through complicated machinery to produce a product that looks like communicative language, but without any intent or thinking mind behind it.‚ÄùAs an alternative to well-established metaphors such as the ones listed above, classical philologist Gyburg Uhlmann proposed ‚Äòkitsch‚Äô as a new metaphor to describe the output of LLMs. She argues that ‚Äòkitsch‚Äô ‚Äúis particularly suitable for analytically illuminating a previously neglected feature of LLM-based images and texts: their tendency to produce homogeneous and average content, which is [‚Ä¶] leading to the equalisation of language, style and argument‚Äù (Uhlmann 2025).'; res2 = document.getElementById('result_Q15_2').innerText == 'That‚Äôs right!'; res3 = document.getElementById('result_Q15_3').innerText == 'That‚Äôs right!'; res4 = document.getElementById('result_Q15_4').innerText == 'That‚Äôs right!'; res5 = document.getElementById('result_Q15_5').innerText == 'That‚Äôs right!'; res6 = document.getElementById('result_Q15_6').innerText == 'That‚Äôs right! The debugging questions show the largest difference between the treatment (AI) and the control (no AI) groups.'; res7 = document.getElementById('result_Q15_7').innerText == 'That‚Äôs right! The authors of the study conclude that, without relying on ‚ÄúAI‚Äù help, the control group made more errors and developed stronger debugging skills through experience.'; res8 = document.getElementById('result_Q15_8').innerText == 'Indeed, the authors of the study write that the small gap suggests similar exposure and learning in code reading across groups.'; res9 = document.getElementById('result_Q15_9').innerText == 'That‚Äôs right!'; res10 = document.getElementById('result_Q15_10').innerText == 'That‚Äôs right!';text = res1 + res2 + res3 + res4 + res5 + res6 + res7 + res8 + res9 + res10;element.innerHTML = text;
         return false;
         }}</script>
</div>
<div class="cell-output-display">
<div id="hint_53619" onclick="return show_hint_53619()">üê≠ Click on the mouse for a hint.</div>
<div id="result_53619" onclick="return show_hint_53619()"></div>
<script>function show_hint_53619(){var x = document.getElementById('result_53619').innerHTML; if(!x){document.getElementById('result_53619').innerHTML = 'Visit the linked Q&amp;A page on Cross Validated and scroll to the bottom of the first post to find out a) when the question was last edited and b) when it was first asked.';} else {document.getElementById('result_53619').innerHTML = '';}}</script>
</div>
</div>
<p>&nbsp;</p>
<p><span style="color:green;"><strong>Q15.11</strong></span> As of 9 February 2026 when the page was archived, how many Cross Validated members had upvoted the top answer?</p>
<div class="cell">
<div class="cell-output-display">
<form name="form_Q15_11" onsubmit="return validate_form_Q15_11()" method="post">
<label>
<input type="radio" name="answer_Q15_11" id="answer_Q15_11_1" value="30 members">
30 members
</label>
<br>
<label>
<input type="radio" name="answer_Q15_11" id="answer_Q15_11_2" value="28 members">
28 members
</label>
<br>
<label>
<input type="radio" name="answer_Q15_11" id="answer_Q15_11_3" value="32 members">
32 members
</label>
<br>
<label>
<input type="radio" name="answer_Q15_11" id="answer_Q15_11_4" value="34 members">
34 members
</label>
<br>
<input type="submit" value="Check answer">
<div id="result_Q15_11"></div>
</form>
<script>function validate_form_Q15_11() {var x, text; var x = document.forms['form_Q15_11']['answer_Q15_11'].value;if (x == '32 members'){text = 'That‚Äôs right!';} else {text = 'No, not quite.';} document.getElementById('result_Q15_11').innerHTML = text; evaluate_final_score(); return false;}function evaluate_final_score(){
         element = document.getElementById('checkdown_final_score');
         if(element === null){return false;} else {var element, text, res1, res2, res3, res4, res5, res6, res7, res8, res9, res10, res11;res1 = document.getElementById('result_Q15_1').innerText == 'That‚Äôs right, well done! Which metaphor(s) do you like best?The term ‚Äòstocastic parrot‚Äô is probably the best known LLM metaphor. It was introduced by computational linguist Emily M. Bender and colleagues in 2021 to characterise LLMs as systems that mimic text without true understanding, highlighting their limitations in processing meaning. This metaphor emphasises that LLMs generate outputs based on statistical patterns in their training data, similar to how parrots mimic sounds without comprehension.In 2022, the cognitive scientist Iris Van Rooij published a blog post in which she succictly explains why she believes that LLMs cannot legitimately be used for academic writing because they essentially automate plagiarism.The ‚Äòspicy autocomplete‚Äô metaphor is difficult to trace back to one or more specific author(s). It suggests that LLMs are just fancy versions of a smart phone‚Äôs predictive text, which predict the next word based on what came before, except that LLMs add some randomness, i.e. spice, to the output. This framing also implies that LLMs are pattern-matching algorithms without real understanding or problem-solving ability (see Gro√ü 2024).In 2024, Hicks, Humphries &amp; Slater published a paper in the journal ‚ÄòEthics and Information Technology‚Äô entitled ‚ÄòChatGPT is bullshit‚Äô, in which they argue that the output of LLMs is best understood as ‚Äòbullshit‚Äô in the philosophical sense described by Frankfurt (2005) because LLMs are indifferent to the truth of their outputs.‚ÄòSynthetic text extruding machines‚Äô is a term that Emily M. Bender and Alex Hanna like to use, e.g. in their 2025 book entitled ‚ÄòThe AI Con: How to Fight Big Tech‚Äôs Hype and Create the Future We Want‚Äô. They describe the process of LLM-generated texts by explaining that, ‚Äú[l]ike an industrial plastic process, language corpora are forced through complicated machinery to produce a product that looks like communicative language, but without any intent or thinking mind behind it.‚ÄùAs an alternative to well-established metaphors such as the ones listed above, classical philologist Gyburg Uhlmann proposed ‚Äòkitsch‚Äô as a new metaphor to describe the output of LLMs. She argues that ‚Äòkitsch‚Äô ‚Äúis particularly suitable for analytically illuminating a previously neglected feature of LLM-based images and texts: their tendency to produce homogeneous and average content, which is [‚Ä¶] leading to the equalisation of language, style and argument‚Äù (Uhlmann 2025).'; res2 = document.getElementById('result_Q15_2').innerText == 'That‚Äôs right!'; res3 = document.getElementById('result_Q15_3').innerText == 'That‚Äôs right!'; res4 = document.getElementById('result_Q15_4').innerText == 'That‚Äôs right!'; res5 = document.getElementById('result_Q15_5').innerText == 'That‚Äôs right!'; res6 = document.getElementById('result_Q15_6').innerText == 'That‚Äôs right! The debugging questions show the largest difference between the treatment (AI) and the control (no AI) groups.'; res7 = document.getElementById('result_Q15_7').innerText == 'That‚Äôs right! The authors of the study conclude that, without relying on ‚ÄúAI‚Äù help, the control group made more errors and developed stronger debugging skills through experience.'; res8 = document.getElementById('result_Q15_8').innerText == 'Indeed, the authors of the study write that the small gap suggests similar exposure and learning in code reading across groups.'; res9 = document.getElementById('result_Q15_9').innerText == 'That‚Äôs right!'; res10 = document.getElementById('result_Q15_10').innerText == 'That‚Äôs right!'; res11 = document.getElementById('result_Q15_11').innerText == 'That‚Äôs right!';text = res1 + res2 + res3 + res4 + res5 + res6 + res7 + res8 + res9 + res10 + res11;element.innerHTML = text;
         return false;
         }}</script>
</div>
<div class="cell-output-display">
<div id="hint_86767" onclick="return show_hint_86767()">üê≠ Click on the mouse for a hint.</div>
<div id="result_86767" onclick="return show_hint_86767()"></div>
<script>function show_hint_86767(){var x = document.getElementById('result_86767').innerHTML; if(!x){document.getElementById('result_86767').innerHTML = 'Look for the number next to the up arrow in the top-left corner of the answer.';} else {document.getElementById('result_86767').innerHTML = '';}}</script>
</div>
</div>
<p>&nbsp;</p>
<p>In <a href="11_Inferential.html#sec-ttest" class="quarto-xref"><span>Section 11.2</span></a>, we conducted the following <em>t</em>-test to find out whether the observed difference between the L1 and L2 speakers‚Äô non-verbal IQ ‚ÄòBlocks‚Äô test scores was significant or not:</p>
<div class="cell">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb1" data-source-line-numbers="nil" data-code-line-numbers="nil"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="fu">t.test</span>(<span class="at">formula =</span> Blocks <span class="sc">~</span> Group, </span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a>       <span class="at">data =</span> Dabrowska.data)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-stdout">
<pre data-code-line-numbers=""><code>
    Welch Two Sample t-test

data:  Blocks by Group
t = -4.4084, df = 152.46, p-value = 1.956e-05
alternative hypothesis: true difference in means between group L1 and group L2 is not equal to 0
95 percent confidence interval:
 -5.239791 -1.996693
sample estimates:
mean in group L1 mean in group L2 
        13.84444         17.46269 </code></pre>
</div>
</div>
<p>The output of the <code>t.test()</code> function above was fed into an LLM (DeepSeek R1 Distill Llama 70B) with a prompt requesting a short paragraph interpreting these results. The model‚Äôs response is printed below:</p>
<blockquote class="blockquote">
<p>The Welch two‚Äësample t‚Äëtest shows a significant difference between the groups (t‚ÄØ=‚ÄØ‚Äë4.41, df‚ÄØ‚âà‚ÄØ152.5, p‚ÄØ=‚ÄØ1.96‚ÄØ√ó‚ÄØ10‚Åª‚Åµ). Group‚ÄØL1 has a mean of 13.84 blocks, while group L2‚Äôs mean is 17.46 blocks, a mean difference of ‚Äë3.62 blocks. The 95‚ÄØ% confidence interval for this difference (‚Äë5.24 to ‚Äë1.99) means we can be 95‚ÄØ% confident that the true average in L2 exceeds that in L1 by roughly 2 to 5 blocks. Because the interval does not include zero, the null hypothesis of equal means is rejected.</p>
</blockquote>
<p><span style="color:green;"><strong>Q15.12</strong></span> Aside from the fact that ‚Äúblocks‚Äù is not a unit, which major statistical error does the LLM‚Äôs interpretation of the <em>t</em>-test output include?</p>
<div class="cell">
<div class="cell-output-display">
<form name="form_Q15_12" onsubmit="return validate_form_Q15_12()" method="post">
<label>
<input type="radio" name="answer_Q15_12" id="answer_Q15_12_1" value="The confidence interval is incorrectly interpreted as a probability statement about the true mean difference.">
The confidence interval is incorrectly interpreted as a probability statement about the true mean difference.
</label>
<br>
<label>
<input type="radio" name="answer_Q15_12" id="answer_Q15_12_2" value="The t-test output makes a statement about the alternative hypothesis, not the null hypothesis.">
The t-test output makes a statement about the alternative hypothesis, not the null hypothesis.
</label>
<br>
<label>
<input type="radio" name="answer_Q15_12" id="answer_Q15_12_3" value="The mean difference should be positive, not negative, since L2 has a higher mean.">
The mean difference should be positive, not negative, since L2 has a higher mean.
</label>
<br>
<label>
<input type="radio" name="answer_Q15_12" id="answer_Q15_12_4" value="The LLM fails to recognise that the t-test was not appropriate because the data are not normally distributed.">
The LLM fails to recognise that the t-test was not appropriate because the data are not normally distributed.
</label>
<br>
<label>
<input type="radio" name="answer_Q15_12" id="answer_Q15_12_5" value="The p-value is incorrectly translated and is in fact too large to reject the null hypothesis.">
The p-value is incorrectly translated and is in fact too large to reject the null hypothesis.
</label>
<br>
<input type="submit" value="Check answer">
<div id="result_Q15_12"></div>
</form>
<script>function validate_form_Q15_12() {var x, text; var x = document.forms['form_Q15_12']['answer_Q15_12'].value;if (x == 'The confidence interval is incorrectly interpreted as a probability statement about the true mean difference.'){text = 'That‚Äôs right! The 95% confidence interval does not mean that there‚Äôs a 95% probability that the true difference lies in that range. Rather, it means that, if we repeated the study many times, 95% of such intervals would contain the true difference.';} else {text = 'No, that‚Äôs not it. Consider what the confidence interval actually means. This is explained in the Stack Exchange post examined as part of the quiz questions above.';} document.getElementById('result_Q15_12').innerHTML = text; evaluate_final_score(); return false;}function evaluate_final_score(){
         element = document.getElementById('checkdown_final_score');
         if(element === null){return false;} else {var element, text, res1, res2, res3, res4, res5, res6, res7, res8, res9, res10, res11, res12;res1 = document.getElementById('result_Q15_1').innerText == 'That‚Äôs right, well done! Which metaphor(s) do you like best?The term ‚Äòstocastic parrot‚Äô is probably the best known LLM metaphor. It was introduced by computational linguist Emily M. Bender and colleagues in 2021 to characterise LLMs as systems that mimic text without true understanding, highlighting their limitations in processing meaning. This metaphor emphasises that LLMs generate outputs based on statistical patterns in their training data, similar to how parrots mimic sounds without comprehension.In 2022, the cognitive scientist Iris Van Rooij published a blog post in which she succictly explains why she believes that LLMs cannot legitimately be used for academic writing because they essentially automate plagiarism.The ‚Äòspicy autocomplete‚Äô metaphor is difficult to trace back to one or more specific author(s). It suggests that LLMs are just fancy versions of a smart phone‚Äôs predictive text, which predict the next word based on what came before, except that LLMs add some randomness, i.e. spice, to the output. This framing also implies that LLMs are pattern-matching algorithms without real understanding or problem-solving ability (see Gro√ü 2024).In 2024, Hicks, Humphries &amp; Slater published a paper in the journal ‚ÄòEthics and Information Technology‚Äô entitled ‚ÄòChatGPT is bullshit‚Äô, in which they argue that the output of LLMs is best understood as ‚Äòbullshit‚Äô in the philosophical sense described by Frankfurt (2005) because LLMs are indifferent to the truth of their outputs.‚ÄòSynthetic text extruding machines‚Äô is a term that Emily M. Bender and Alex Hanna like to use, e.g. in their 2025 book entitled ‚ÄòThe AI Con: How to Fight Big Tech‚Äôs Hype and Create the Future We Want‚Äô. They describe the process of LLM-generated texts by explaining that, ‚Äú[l]ike an industrial plastic process, language corpora are forced through complicated machinery to produce a product that looks like communicative language, but without any intent or thinking mind behind it.‚ÄùAs an alternative to well-established metaphors such as the ones listed above, classical philologist Gyburg Uhlmann proposed ‚Äòkitsch‚Äô as a new metaphor to describe the output of LLMs. She argues that ‚Äòkitsch‚Äô ‚Äúis particularly suitable for analytically illuminating a previously neglected feature of LLM-based images and texts: their tendency to produce homogeneous and average content, which is [‚Ä¶] leading to the equalisation of language, style and argument‚Äù (Uhlmann 2025).'; res2 = document.getElementById('result_Q15_2').innerText == 'That‚Äôs right!'; res3 = document.getElementById('result_Q15_3').innerText == 'That‚Äôs right!'; res4 = document.getElementById('result_Q15_4').innerText == 'That‚Äôs right!'; res5 = document.getElementById('result_Q15_5').innerText == 'That‚Äôs right!'; res6 = document.getElementById('result_Q15_6').innerText == 'That‚Äôs right! The debugging questions show the largest difference between the treatment (AI) and the control (no AI) groups.'; res7 = document.getElementById('result_Q15_7').innerText == 'That‚Äôs right! The authors of the study conclude that, without relying on ‚ÄúAI‚Äù help, the control group made more errors and developed stronger debugging skills through experience.'; res8 = document.getElementById('result_Q15_8').innerText == 'Indeed, the authors of the study write that the small gap suggests similar exposure and learning in code reading across groups.'; res9 = document.getElementById('result_Q15_9').innerText == 'That‚Äôs right!'; res10 = document.getElementById('result_Q15_10').innerText == 'That‚Äôs right!'; res11 = document.getElementById('result_Q15_11').innerText == 'That‚Äôs right!'; res12 = document.getElementById('result_Q15_12').innerText == 'That‚Äôs right! The 95% confidence interval does not mean that there‚Äôs a 95% probability that the true difference lies in that range. Rather, it means that, if we repeated the study many times, 95% of such intervals would contain the true difference.';text = res1 + res2 + res3 + res4 + res5 + res6 + res7 + res8 + res9 + res10 + res11 + res12;element.innerHTML = text;
         return false;
         }}</script>
</div>
</div>
</div>
</div>
</div>
<p>In addition to the flood of AI slop making it difficult to find reliable information, human content creators are finding that their intellectual property is being scraped without consent to be used as training data for commercial AI products. In the era of <a href="@sec-OpenScholarship">Open Scholarship</a>, researchers, software developers, and educators have been sharing their work with the world for the benefit of scientific progress, typically with only authorship attribution as a reward. However, this may change as AI companies appropriate their work and LLMs automate plagiarism <span class="citation" data-cites="rooijAutomatedPlagiarism2022">(<a href="99_references.html#ref-rooijAutomatedPlagiarism2022" role="doc-biblioref">Rooij 2022</a>)</span>.</p>
<p>This may sound like an entirely dystopian situation but, up until fairly recently, researchers had to pay to use programming languages for statistical analyses and scientific computing. FORTAN compilers, MatLab, S, and SPPS were (and still are) proprietary software which were inaccessible to many researchers and students. It is no exaggeration to say that open-source, community-led programming languages such as <code>R</code>, Python, and Julia revolutionised data analysis, making state-of-the-art methods accessible to far more people. However, as high-quality open-access resources become rarer due the contamination of AI slop and illegal scraping, we may be returning to an era of restricted access to scientific computing. Hence, it is worth remembering that it is communities of humans who have been developing programming languages such as <code>R</code> and Python, their many extensions such as the {tidyverse} packages, open-source software such as <em>R Studio</em>, and high-quality documentation and Open Educational Resources.</p>
<p>These communities depend on collaboration, interactions, and mutual support. Yet, we have entered an age where human interactions are marketed as unproductive, time-consuming, and burdensome. We are told that they can easily be replaced by more efficient and ‚Äúobjective‚Äù chatbots. Aside from the fact that LLMs are known to be prone to all kinds of very serious biases and that their efficiency is far from proven <span class="citation" data-cites="AIVsHuman">(see e.g. <a href="99_references.html#ref-AIVsHuman" role="doc-biblioref">Loker 2025</a> on how AI code creates more problems than human-generated code)</span>, we should not loose sight of the value of subjective, human interactions. This is not to say that LLMs are never useful, but rather that I also strongly encourage you to (also) devote time to learning from reliable, human-generated resources (see e.g.&nbsp;<a href="https://elenlefoll.github.io/RstatsTextbook/A_FurtherResources.html">Next-step resources</a>), join a course with other human beings to continue your learning journey, and/or find a learning buddy to discuss and solve problems together. This textbook was entirely human-generated and benefited greatly from countless rounds of revisions thanks to interactions with and feedback from (human!) students and colleagues (see <a href="https://elenlefoll.github.io/RstatsTextbook/#acknowledgements">Acknowledgements</a>). Of course, it would have been quicker to write the textbook without asking for feedback or to get an LLM to generate first drafts of sections, code, and/or quiz questions. But in research, teaching, and learning, <strong>quality matters more than velocity</strong>.</p>
<section id="check-your-progress" class="level3 unnumbered">
<h3 class="unnumbered anchored" data-anchor-id="check-your-progress">Check your progress <span class="emoji" data-emoji="star2">üåü</span></h3>
<p>In this concluding chapter, you have answered <span style="color:green;"><span id="checkdown_final_score">0</span> out of 12 questions</span> correctly. Congratulations!</p>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
<span class="screen-reader-only">Note</span>More food for thought üçèüçé
</div>
</div>
<div class="callout-body-container callout-body">
<ul>
<li><p>Bergstrom, Carl T. &amp; Jevin D. West. Modern-Day Oracles or Bullshit Machines: How to thrive in a ChatGPT world. Online course. <a href="https://thebullshitmachines.com" class="uri">https://thebullshitmachines.com</a>. [Open Educational Resource].</p></li>
<li><p>Dingemanse, Mark. 2024. Generative AI and Research Integrity. OSF. <a href="https://doi.org/10.31219/osf.io/2c48n" class="uri">https://doi.org/10.31219/osf.io/2c48n</a>. [Open Access].</p></li>
<li><p>Guest, Olivia, Marcela Suarez, Barbara M√ºller, Edwin van Meerkerk, Arnoud Oude Groote Beverborg, Ronald de Haan, Andrea Reyes Elizondo, et al.&nbsp;2025. Against the Uncritical Adoption of ‚ÄúAI‚Äù Technologies in Academia. Zenodo. <a href="https://zenodo.org/records/17065099" class="uri">https://zenodo.org/records/17065099</a>. [Open Access].</p>
<p>‚û°Ô∏è See also Olivia Guest‚Äôs curated list of readings on critical AI literacy: <a href="https://olivia.science/ai/" class="uri">https://olivia.science/ai/</a> [Open Access].</p></li>
<li><p>M√ºhlhoff, Rainer. 2025. <em>The ethics of AI: Power, critique, responsibility</em>. Bristol: Bristol University Press. <a href="https://doi.org/10.51952/9781529249262" class="uri">https://doi.org/10.51952/9781529249262</a>. [<a href="https://bristoluniversitypressdigital.com/downloadpdf/monobook-oa/book/9781529249262/9781529249262.pdf">Open Access</a>].</p>
<p>‚û°Ô∏è See also Rainer M√ºhlhoff‚Äôs <em>Introduction to the Ethics of AI 2025</em> lecture videos. <a href="#0" class="uri">https://rainermuehlhoff.de/en/EoAI2025/</a>. [Open Educational Resource].</p></li>
</ul>
</div>
</div>
</section>
</section>
<section id="whats-next" class="level2" data-number="15.5">
<h2 data-number="15.5" class="anchored" data-anchor-id="whats-next"><span class="header-section-number">15.5</span> What‚Äôs next? üß≠</h2>
<p>This textbook has taken you on a journey: first introducing Open Scholarship (<a href="1_OpenScholarship.html" class="quarto-xref"><span>Chapter 1</span></a>), which forms the backbone of this textbook‚Äôs approach to doing science, then consolidating knowledge about file formats, file naming, and project organisation (<a href="2_Data.html" class="quarto-xref"><span>Chapter 2</span></a> and <a href="3_DataManagement.html" class="quarto-xref"><span>Chapter 3</span></a>), which are often major hurdles for successful data analysis pipelines. Having installed and set up <code>R</code> and <em>RStudio</em> (<a href="4_InstallingR.html" class="quarto-xref"><span>Chapter 4</span></a>), you took your first steps in learning to code in <code>R</code> (<a href="5_GettingStaRted.html" class="quarto-xref"><span>Chapter 5</span></a>). Next, you learnt to import real research data into an <code>R</code> project (<a href="6_ImpoRtingData.html" class="quarto-xref"><span>Chapter 6</span></a>). From <a href="7_VariablesFunctions.html" class="quarto-xref"><span>Chapter 7</span></a> onwards, you learnt how to analyse data in <code>R</code> using descriptive and inferential statistics and data visualisations. This entailed wrangling data to prepare them for such analyses, as well as developing an understanding of key statistical concepts such as measures of central tendency and variability, distributions, effect sizes, confidence intervals, and <em>p</em>-values. <a href="12_SimpleLinearRegression.html" class="quarto-xref"><span>Chapter 12</span></a> introduced statistical modelling with simple linear regression and <a href="13_MultipleLinearRegression.html" class="quarto-xref"><span>Chapter 13</span></a> expanded this concept to multiple predictor variables and interactions between predictors. Having mastered this foundational knowledge, you are now ready to tackle more advanced statistical methods such as mixed-effects and non-linear regression models, logistic and other classification models, machine learning algorithms, and much more (see <a href="https://elenlefoll.github.io/RstatsTextbook/A_FurtherResources.html">Next-step resources</a>). In <a href="14_LiterateProgramming.html" class="quarto-xref"><span>Chapter 14</span></a>, you learnt how to apply literate programming skills to conduct and publish reproducible research in Quarto. Finally, in this concluding chapter, you reflected on the values of critical thinking, human learning, and of nurturing communities in the day and age of AI.</p>
<blockquote class="blockquote">
<p>Learning statistical theory and practice are inseparable from scientific reasoning <span class="citation" data-cites="vasishthHowEmbraceVariation2021">(<a href="99_references.html#ref-vasishthHowEmbraceVariation2021" role="doc-biblioref">Vasishth &amp; Gelman 2021</a>: 1312)</span>.</p>
</blockquote>
<p>I personally believe that it will always be worth investing in learning complex matters, developing critical thinking skills, and building meaningful human relationships. No matter how powerful and efficient future AI products may be, the skills that will be valued in the future will not be ‚Äúadvanced‚Äù prompting techniques, but rather social skills, computational thinking, and critical (statistical) literacy. Crucially, these are the skills that are essential to make the most of AI tools.</p>
<p>The resources listed in the <a href="https://elenlefoll.github.io/RstatsTextbook/A_FurtherResources.html">Appendix</a> are an excellent starting point for continuing your learning journey. In addition, the <a href="https://elenlefoll.github.io/RstatsTextbook">online version</a> of this textbook features an expanding collection of case study chapters co-authored by students from my ‚ÄòIntroduction to Data Analysis in R‚Äô class. Each chapter attempts to computationally reproduce a published a linguistics study using the authors‚Äô original data. The student authors document all the steps necessary to reproduce the results and discuss the success (or not!) of the reproduction. Attempting to reproduce the steps outlined in a case study that interests you, or that covers a method you‚Äôd like to learn more about, is a great way to consolidate and expand the skills and knowledge you have acquired so far.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><a href="images/AHorst_RFlowers.png" class="lightbox" data-gallery="quarto-lightbox-gallery-9" title="Happy leaRning!Ô∏è (artwork by Allison Horst CC BY 4.0)"><img src="images/AHorst_RFlowers.png" class="img-fluid figure-img" alt="Two cute little monsters decorating the R logo with hearts, flowers, and smilies."></a></p>
<figcaption>Happy lea<code>R</code>ning!Ô∏è (artwork by <a href="https://allisonhorst.com/r-packages-functions">Allison Horst</a> <a href="https://creativecommons.org/licenses/by/4.0/">CC BY 4.0</a>)</figcaption>
</figure>
</div>


<div id="refs" class="references csl-bib-body hanging-indent" data-entry-spacing="0" role="list" style="display: none">
<div id="ref-arregoitiaLargeLanguageModel2026" class="csl-entry" role="listitem">
Arregoitia, Luis D. Verde. 2026. Large language model tools for r. <a href="https://luisdva.github.io/llmsr-book/">https://luisdva.github.io/llmsr-book/</a>.
</div>
<div id="ref-benderAIConHow2025" class="csl-entry" role="listitem">
Bender, Emily M. &amp; Alex Hanna. 2025. <em>The AI con: How to fight big tech‚Äôs hype and create the future we want</em>. HarperCollins.
</div>
<div id="ref-chowEpisode4Mine" class="csl-entry" role="listitem">
Chow, Michael, Hadley Wickham &amp; Wes Mckinney. 2025. <em>Episode 4 : Mine √ßetinkaya-rundel: Teaching in the AI era ‚Äî and keeping students engaged</em>. <a href="https://posit.co/thetestset/episode/mine-cetinkaya-rundel-teaching-in-the-ai-era-and-keeping-students-engaged/">https://posit.co/thetestset/episode/mine-cetinkaya-rundel-teaching-in-the-ai-era-and-keeping-students-engaged/</a>.
</div>
<div id="ref-ferdman2025" class="csl-entry" role="listitem">
Ferdman, Avigail. 2025. AI deskilling is a structural problem. <em>AI &amp; SOCIETY</em>. <a href="https://doi.org/10.1007/s00146-025-02686-z">https://doi.org/10.1007/s00146-025-02686-z</a>.
</div>
<div id="ref-guestUncriticalAdoptionAI2025" class="csl-entry" role="listitem">
Guest, Olivia, Marcela Suarez, Barbara M√ºller, Edwin van Meerkerk, Arnoud Oude Groote Beverborg, Ronald de Haan, Andrea Reyes Elizondo, et al. 2025. Against the uncritical adoption of <span>‚ÄúAI‚Äù</span> technologies in academia. <a href="https://zenodo.org/records/17065099">https://zenodo.org/records/17065099</a>.
</div>
<div id="ref-heissDataVisualizationCan2024" class="csl-entry" role="listitem">
Heiss. 2024. Data visualization with r: Can we use ChatGPT? <em>Data Visualization with R</em>. <a href="https://datavizs24.classes.andrewheiss.com/news/2024-06-11_faqs_session-01.html#can-we-use-chatgpt-can-you-even-tell-if-we-do">https://datavizs24.classes.andrewheiss.com/news/2024-06-11_faqs_session-01.html#can-we-use-chatgpt-can-you-even-tell-if-we-do</a>.
</div>
<div id="ref-jj2025" class="csl-entry" role="listitem">
Jj. 2025. The copilot delusion. <em>Blogmobly</em>. <a href="https://deplet.ing/the-copilot-delusion/">https://deplet.ing/the-copilot-delusion/</a>.
</div>
<div id="ref-AIVsHuman" class="csl-entry" role="listitem">
Loker, David. 2025. AI vs human code gen report: AI code creates 1.7x more issues. <em>CodeRabbit</em>. <a href="https://www.coderabbit.ai/blog/state-of-ai-vs-human-code-generation-report">https://www.coderabbit.ai/blog/state-of-ai-vs-human-code-generation-report</a>.
</div>
<div id="ref-lucchiChatGPTCaseStudy2024" class="csl-entry" role="listitem">
Lucchi, Nicola. 2024. ChatGPT: A case study on copyright challenges for generative artificial intelligence systems. <em>European Journal of Risk Regulation</em> 15(3). 602‚Äì624. <a href="https://doi.org/10.1017/err.2023.59">https://doi.org/10.1017/err.2023.59</a>.
</div>
<div id="ref-luccioniMisinformationOmissionNeed2025" class="csl-entry" role="listitem">
Luccioni, Sasha, Boris Gamazaychikov, Theo Alves da Costa &amp; Emma Strubell. 2025. Misinformation by omission: The need for more environmental transparency in AI. <a href="https://doi.org/10.48550/arXiv.2506.15572">https://doi.org/10.48550/arXiv.2506.15572</a>.
</div>
<div id="ref-m√ºhlhoff2025" class="csl-entry" role="listitem">
M√ºhlhoff, Rainer. 2025. <em>The ethics of AI: Power, critique, responsibility</em>. Bristol University Press.
</div>
<div id="ref-natali2025" class="csl-entry" role="listitem">
Natali, Chiara, Luca Marconi, Leslye Denisse Dias Duran &amp; Federico Cabitza. 2025. AI-induced Deskilling in Medicine: A Mixed-Method Review and Research Agenda for Healthcare and Beyond. <em>Artificial Intelligence Review</em> 58(11). <a href="https://doi.org/10.1007/s10462-025-11352-1">https://doi.org/10.1007/s10462-025-11352-1</a>.
</div>
<div id="ref-notopoulosGoogleAISaid2024" class="csl-entry" role="listitem">
Notopoulos, Katie. 2024. Google AI said to put glue in pizza ‚Äî so i made a pizza with glue and ate it. <em>Business Insider</em>. <a href="https://www.businessinsider.com/google-ai-glue-pizza-i-tried-it-2024-5">https://www.businessinsider.com/google-ai-glue-pizza-i-tried-it-2024-5</a>.
</div>
<div id="ref-perrigoExclusive$2Hour2023" class="csl-entry" role="listitem">
Perrigo, Billy. 2023. <em>TIME</em>. <a href="https://web.archive.org/web/20260103132216/https://time.com/6247678/openai-chatgpt-kenya-workers/">https://web.archive.org/web/20260103132216/https://time.com/6247678/openai-chatgpt-kenya-workers/</a>.
</div>
<div id="ref-pooleyMatthewEffectAI2025" class="csl-entry" role="listitem">
Pooley, Jeff. 2025. The matthew effect in AI summary. <a href="https://www.jeffpooley.com/2025/11/the-matthew-effect-in-ai-summary/">https://www.jeffpooley.com/2025/11/the-matthew-effect-in-ai-summary/</a>.
</div>
<div id="ref-quattrociocchiEpistemologicalFaultLines2025" class="csl-entry" role="listitem">
Quattrociocchi, Walter, Valerio Capraro &amp; Matja≈æ Perc. 2025. Epistemological fault lines between human and artificial intelligence. <a href="https://doi.org/10.48550/arXiv.2512.19466">https://doi.org/10.48550/arXiv.2512.19466</a>.
</div>
<div id="ref-rooijAutomatedPlagiarism2022" class="csl-entry" role="listitem">
Rooij, Iris Van. 2022. Against automated plagiarism. <em>Iris van Rooij</em>. <a href="https://irisvanrooijcogsci.com/2022/12/29/against-automated-plagiarism/">https://irisvanrooijcogsci.com/2022/12/29/against-automated-plagiarism/</a>.
</div>
<div id="ref-vanrooijReclaimingAITheoretical2024" class="csl-entry" role="listitem">
Rooij, Iris van, Olivia Guest, Federico Adolfi, Ronald de Haan, Antonina Kolokolova &amp; Patricia Rich. 2024. Reclaiming AI as a theoretical tool for cognitive science. <em>Computational Brain &amp; Behavior</em>. <a href="https://doi.org/10.1007/s42113-024-00217-5">https://doi.org/10.1007/s42113-024-00217-5</a>.
</div>
<div id="ref-samuelsonGenerativeAIMeets2023" class="csl-entry" role="listitem">
Samuelson, Pamela. 2023. Generative AI meets copyright. <em>Science</em>. American Association for the Advancement of Science 381(6654). 158‚Äì161. <a href="https://doi.org/10.1126/science.adi0656">https://doi.org/10.1126/science.adi0656</a>.
</div>
<div id="ref-schonExpertAssessmentSystemic2025" class="csl-entry" role="listitem">
Sch√∂n, Julian, Lena Hoffmann &amp; Nikolas Becker. 2025. Expert assessment: The systemic environmental risks of artficial intelligence. Gesellschaft f√ºr Informatik e.V. <a href="https://doi.org/10.18420/studie_senvrai">https://doi.org/10.18420/studie_senvrai</a>.
</div>
<div id="ref-stetskovGreatSoftwareQuality2025" class="csl-entry" role="listitem">
Stetskov, Denis. 2025. The great software quality collapse: How we normalized catastrophe. <em>From the Trenches</em>. <a href="https://techtrenches.dev/p/the-great-software-quality-collapse">https://techtrenches.dev/p/the-great-software-quality-collapse</a>.
</div>
<div id="ref-tamkin2026" class="csl-entry" role="listitem">
Tamkin, Alex &amp; Judy Hanwen Shen. 2026. How AI impacts skill formation. <a href="https://doi.org/10.48550/arXiv.2601.20245">https://doi.org/10.48550/arXiv.2601.20245</a>.
</div>
<div id="ref-vasishthHowEmbraceVariation2021" class="csl-entry" role="listitem">
Vasishth, Shravan &amp; Andrew Gelman. 2021. How to embrace variation and accept uncertainty in linguistic and psycholinguistic data analysis. <em>Linguistics</em> 59(5). 1311‚Äì1342. <a href="https://doi.org/10.1515/ling-2019-0051">https://doi.org/10.1515/ling-2019-0051</a>.
</div>
<div id="ref-vaswaniAttentionAllYou2017" class="csl-entry" role="listitem">
Vaswani, Ashish, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N. Gomez, Lukasz Kaiser &amp; Illia Polosukhin. 2017. Attention is all you need. In. arXiv. <a href="https://doi.org/10.48550/arXiv.1706.03762">https://doi.org/10.48550/arXiv.1706.03762</a>.
</div>
<div id="ref-wickhamDataScienceImport2023" class="csl-entry" role="listitem">
Wickham, Hadley, Mine √áetinkaya-Rundel &amp; Garrett Grolemund. 2023. <em>R for data science: Import, tidy, transform, visualize, and model data</em>. 2nd edition. O‚ÄôReilly. <a href="https://r4ds.hadley.nz/">https://r4ds.hadley.nz/</a>.
</div>
</div>
</section>
<section id="footnotes" class="footnotes footnotes-end-of-document" role="doc-endnotes">
<hr>
<ol>
<li id="fn1"><p>I highly recommend Andrew Heiss‚Äô <a href="https://www.andrewheiss.com/blog/">blog</a> and his beautiful <a href="https://www.andrewheiss.com/teaching/">teaching resources</a>. Fun fact for language students and linguists: Andrew majored in Arabic and Italian and didn‚Äôt learn about statistics or <code>R</code> until he started his second master‚Äôs!<a href="#fnref1" class="footnote-back" role="doc-backlink">‚Ü©Ô∏é</a></p></li>
</ol>
</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
  window.document.addEventListener("DOMContentLoaded", function (event) {
    // Ensure there is a toggle, if there isn't float one in the top right
    if (window.document.querySelector('.quarto-color-scheme-toggle') === null) {
      const a = window.document.createElement('a');
      a.classList.add('top-right');
      a.classList.add('quarto-color-scheme-toggle');
      a.href = "";
      a.onclick = function() { try { window.quartoToggleColorScheme(); } catch {} return false; };
      const i = window.document.createElement("i");
      i.classList.add('bi');
      a.appendChild(i);
      window.document.body.appendChild(a);
    }
    setColorSchemeToggle(hasAlternateSentinel())
    const icon = "Óßã";
    const anchorJS = new window.AnchorJS();
    anchorJS.options = {
      placement: 'right',
      icon: icon
    };
    anchorJS.add('.anchored');
    const isCodeAnnotation = (el) => {
      for (const clz of el.classList) {
        if (clz.startsWith('code-annotation-')) {                     
          return true;
        }
      }
      return false;
    }
    const onCopySuccess = function(e) {
      // button target
      const button = e.trigger;
      // don't keep focus
      button.blur();
      // flash "checked"
      button.classList.add('code-copy-button-checked');
      var currentTitle = button.getAttribute("title");
      button.setAttribute("title", "Copied!");
      let tooltip;
      if (window.bootstrap) {
        button.setAttribute("data-bs-toggle", "tooltip");
        button.setAttribute("data-bs-placement", "left");
        button.setAttribute("data-bs-title", "Copied!");
        tooltip = new bootstrap.Tooltip(button, 
          { trigger: "manual", 
            customClass: "code-copy-button-tooltip",
            offset: [0, -8]});
        tooltip.show();    
      }
      setTimeout(function() {
        if (tooltip) {
          tooltip.hide();
          button.removeAttribute("data-bs-title");
          button.removeAttribute("data-bs-toggle");
          button.removeAttribute("data-bs-placement");
        }
        button.setAttribute("title", currentTitle);
        button.classList.remove('code-copy-button-checked');
      }, 1000);
      // clear code selection
      e.clearSelection();
    }
    const getTextToCopy = function(trigger) {
      const outerScaffold = trigger.parentElement.cloneNode(true);
      const codeEl = outerScaffold.querySelector('code');
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
    }
    const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
      text: getTextToCopy
    });
    clipboard.on('success', onCopySuccess);
    if (window.document.getElementById('quarto-embedded-source-code-modal')) {
      const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
        text: getTextToCopy,
        container: window.document.getElementById('quarto-embedded-source-code-modal')
      });
      clipboardModal.on('success', onCopySuccess);
    }
      var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
      var mailtoRegex = new RegExp(/^mailto:/);
        var filterRegex = new RegExp("https:\/\/elenlefoll\.github\.io\/RstatsTexbook\/");
      var isInternal = (href) => {
          return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
      }
      // Inspect non-navigation links and adorn them if external
     var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
      for (var i=0; i<links.length; i++) {
        const link = links[i];
        if (!isInternal(link.href)) {
          // undo the damage that might have been done by quarto-nav.js in the case of
          // links that we want to consider external
          if (link.dataset.originalHref !== undefined) {
            link.href = link.dataset.originalHref;
          }
            // target, if specified
            link.setAttribute("target", "_blank");
            if (link.getAttribute("rel") === null) {
              link.setAttribute("rel", "noopener");
            }
        }
      }
    function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
      const config = {
        allowHTML: true,
        maxWidth: 500,
        delay: 100,
        arrow: false,
        appendTo: function(el) {
            return el.parentElement;
        },
        interactive: true,
        interactiveBorder: 10,
        theme: 'quarto',
        placement: 'bottom-start',
      };
      if (contentFn) {
        config.content = contentFn;
      }
      if (onTriggerFn) {
        config.onTrigger = onTriggerFn;
      }
      if (onUntriggerFn) {
        config.onUntrigger = onUntriggerFn;
      }
      window.tippy(el, config); 
    }
    const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
    for (var i=0; i<noterefs.length; i++) {
      const ref = noterefs[i];
      tippyHover(ref, function() {
        // use id or data attribute instead here
        let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
        try { href = new URL(href).hash; } catch {}
        const id = href.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note) {
          return note.innerHTML;
        } else {
          return "";
        }
      });
    }
    const xrefs = window.document.querySelectorAll('a.quarto-xref');
    const processXRef = (id, note) => {
      // Strip column container classes
      const stripColumnClz = (el) => {
        el.classList.remove("page-full", "page-columns");
        if (el.children) {
          for (const child of el.children) {
            stripColumnClz(child);
          }
        }
      }
      stripColumnClz(note)
      if (id === null || id.startsWith('sec-')) {
        // Special case sections, only their first couple elements
        const container = document.createElement("div");
        if (note.children && note.children.length > 2) {
          container.appendChild(note.children[0].cloneNode(true));
          for (let i = 1; i < note.children.length; i++) {
            const child = note.children[i];
            if (child.tagName === "P" && child.innerText === "") {
              continue;
            } else {
              container.appendChild(child.cloneNode(true));
              break;
            }
          }
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(container);
          }
          return container.innerHTML
        } else {
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(note);
          }
          return note.innerHTML;
        }
      } else {
        // Remove any anchor links if they are present
        const anchorLink = note.querySelector('a.anchorjs-link');
        if (anchorLink) {
          anchorLink.remove();
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        if (note.classList.contains("callout")) {
          return note.outerHTML;
        } else {
          return note.innerHTML;
        }
      }
    }
    for (var i=0; i<xrefs.length; i++) {
      const xref = xrefs[i];
      tippyHover(xref, undefined, function(instance) {
        instance.disable();
        let url = xref.getAttribute('href');
        let hash = undefined; 
        if (url.startsWith('#')) {
          hash = url;
        } else {
          try { hash = new URL(url).hash; } catch {}
        }
        if (hash) {
          const id = hash.replace(/^#\/?/, "");
          const note = window.document.getElementById(id);
          if (note !== null) {
            try {
              const html = processXRef(id, note.cloneNode(true));
              instance.setContent(html);
            } finally {
              instance.enable();
              instance.show();
            }
          } else {
            // See if we can fetch this
            fetch(url.split('#')[0])
            .then(res => res.text())
            .then(html => {
              const parser = new DOMParser();
              const htmlDoc = parser.parseFromString(html, "text/html");
              const note = htmlDoc.getElementById(id);
              if (note !== null) {
                const html = processXRef(id, note);
                instance.setContent(html);
              } 
            }).finally(() => {
              instance.enable();
              instance.show();
            });
          }
        } else {
          // See if we can fetch a full url (with no hash to target)
          // This is a special case and we should probably do some content thinning / targeting
          fetch(url)
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.querySelector('main.content');
            if (note !== null) {
              // This should only happen for chapter cross references
              // (since there is no id in the URL)
              // remove the first header
              if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
                note.children[0].remove();
              }
              const html = processXRef(null, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      }, function(instance) {
      });
    }
        let selectedAnnoteEl;
        const selectorForAnnotation = ( cell, annotation) => {
          let cellAttr = 'data-code-cell="' + cell + '"';
          let lineAttr = 'data-code-annotation="' +  annotation + '"';
          const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
          return selector;
        }
        const selectCodeLines = (annoteEl) => {
          const doc = window.document;
          const targetCell = annoteEl.getAttribute("data-target-cell");
          const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
          const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
          const lines = annoteSpan.getAttribute("data-code-lines").split(",");
          const lineIds = lines.map((line) => {
            return targetCell + "-" + line;
          })
          let top = null;
          let height = null;
          let parent = null;
          if (lineIds.length > 0) {
              //compute the position of the single el (top and bottom and make a div)
              const el = window.document.getElementById(lineIds[0]);
              top = el.offsetTop;
              height = el.offsetHeight;
              parent = el.parentElement.parentElement;
            if (lineIds.length > 1) {
              const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
              const bottom = lastEl.offsetTop + lastEl.offsetHeight;
              height = bottom - top;
            }
            if (top !== null && height !== null && parent !== null) {
              // cook up a div (if necessary) and position it 
              let div = window.document.getElementById("code-annotation-line-highlight");
              if (div === null) {
                div = window.document.createElement("div");
                div.setAttribute("id", "code-annotation-line-highlight");
                div.style.position = 'absolute';
                parent.appendChild(div);
              }
              div.style.top = top - 2 + "px";
              div.style.height = height + 4 + "px";
              div.style.left = 0;
              let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
              if (gutterDiv === null) {
                gutterDiv = window.document.createElement("div");
                gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
                gutterDiv.style.position = 'absolute';
                const codeCell = window.document.getElementById(targetCell);
                const gutter = codeCell.querySelector('.code-annotation-gutter');
                gutter.appendChild(gutterDiv);
              }
              gutterDiv.style.top = top - 2 + "px";
              gutterDiv.style.height = height + 4 + "px";
            }
            selectedAnnoteEl = annoteEl;
          }
        };
        const unselectCodeLines = () => {
          const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
          elementsIds.forEach((elId) => {
            const div = window.document.getElementById(elId);
            if (div) {
              div.remove();
            }
          });
          selectedAnnoteEl = undefined;
        };
          // Handle positioning of the toggle
      window.addEventListener(
        "resize",
        throttle(() => {
          elRect = undefined;
          if (selectedAnnoteEl) {
            selectCodeLines(selectedAnnoteEl);
          }
        }, 10)
      );
      function throttle(fn, ms) {
      let throttle = false;
      let timer;
        return (...args) => {
          if(!throttle) { // first call gets through
              fn.apply(this, args);
              throttle = true;
          } else { // all the others get throttled
              if(timer) clearTimeout(timer); // cancel #2
              timer = setTimeout(() => {
                fn.apply(this, args);
                timer = throttle = false;
              }, ms);
          }
        };
      }
        // Attach click handler to the DT
        const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
        for (const annoteDlNode of annoteDls) {
          annoteDlNode.addEventListener('click', (event) => {
            const clickedEl = event.target;
            if (clickedEl !== selectedAnnoteEl) {
              unselectCodeLines();
              const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
              if (activeEl) {
                activeEl.classList.remove('code-annotation-active');
              }
              selectCodeLines(clickedEl);
              clickedEl.classList.add('code-annotation-active');
            } else {
              // Unselect the line
              unselectCodeLines();
              clickedEl.classList.remove('code-annotation-active');
            }
          });
        }
    const findCites = (el) => {
      const parentEl = el.parentElement;
      if (parentEl) {
        const cites = parentEl.dataset.cites;
        if (cites) {
          return {
            el,
            cites: cites.split(' ')
          };
        } else {
          return findCites(el.parentElement)
        }
      } else {
        return undefined;
      }
    };
    var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
    for (var i=0; i<bibliorefs.length; i++) {
      const ref = bibliorefs[i];
      const citeInfo = findCites(ref);
      if (citeInfo) {
        tippyHover(citeInfo.el, function() {
          var popup = window.document.createElement('div');
          citeInfo.cites.forEach(function(cite) {
            var citeDiv = window.document.createElement('div');
            citeDiv.classList.add('hanging-indent');
            citeDiv.classList.add('csl-entry');
            var biblioDiv = window.document.getElementById('ref-' + cite);
            if (biblioDiv) {
              citeDiv.innerHTML = biblioDiv.innerHTML;
            }
            popup.appendChild(citeDiv);
          });
          return popup.innerHTML;
        });
      }
    }
  });
  </script>
<nav class="page-navigation">
  <div class="nav-page nav-page-previous">
      <a href="./14_LiterateProgramming.html" class="pagination-link" aria-label="Rep`R`oducible research and academic w`R`iting in Quarto">
        <i class="bi bi-arrow-left-short"></i> <span class="nav-page-text"><span class="chapter-number">14</span>&nbsp; <span class="chapter-title">Rep<code>R</code>oducible research and academic w<code>R</code>iting in Quarto</span></span>
      </a>          
  </div>
  <div class="nav-page nav-page-next">
      <a href="./99_references.html" class="pagination-link" aria-label="References">
        <span class="nav-page-text">References</span> <i class="bi bi-arrow-right-short"></i>
      </a>
  </div>
</nav>
</div> <!-- /content -->
<footer class="footer">
  <div class="nav-footer">
    <div class="nav-footer-left">
<p><a href="https://www.elenlefoll.eu">Elen Le Foll</a></p>
</div>   
    <div class="nav-footer-center">
<p>Data Analysis for the Language Sciences</p>
</div>
    <div class="nav-footer-right">
<p><a href="https://creativecommons.org/licenses/by-nc-sa/4.0/">CC BY-NC-SA</a></p>
</div>
  </div>
</footer>
<script>var lightboxQuarto = GLightbox({"closeEffect":"zoom","descPosition":"bottom","loop":false,"openEffect":"zoom","selector":".lightbox"});
(function() {
  let previousOnload = window.onload;
  window.onload = () => {
    if (previousOnload) {
      previousOnload();
    }
    lightboxQuarto.on('slide_before_load', (data) => {
      const { slideIndex, slideNode, slideConfig, player, trigger } = data;
      const href = trigger.getAttribute('href');
      if (href !== null) {
        const imgEl = window.document.querySelector(`a[href="${href}"] img`);
        if (imgEl !== null) {
          const srcAttr = imgEl.getAttribute("src");
          if (srcAttr && srcAttr.startsWith("data:")) {
            slideConfig.href = srcAttr;
          }
        }
      } 
    });
  
    lightboxQuarto.on('slide_after_load', (data) => {
      const { slideIndex, slideNode, slideConfig, player, trigger } = data;
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(slideNode);
      }
    });
  
  };
  
})();
          </script>




<script src="site_libs/quarto-contrib/line-highlight-1.0.0/line-highlight.js" defer="true"></script>
</body></html>