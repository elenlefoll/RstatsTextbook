---
engine: knitr
bibliography: references.bib
---

# Data w`R`angling {#sec-DataWrangling}

### Chapter overview {.unnumbered}

This chapter focuses on the tidyverse framework. You will learn how to:

-   Recognise whether a dataset is in a tidy data format
-   Check the sanity of a dataset
-   Pre-process data in a reproducible way using tidyverse functions
-   Convert character vectors representing categorical data to factors
-   Add and replace columns in a table
-   Transform several columns of a table at once
-   Use {stringr} functions to manipulate text values
-   Reshape and combine tables
-   Save and export `R` objects in different formats

## Welcome to the tidyverse! ü™ê {#sec-tidyverse}

This chapter explains how to examine, clean, and manipulate data using functions from the [{tidyverse}](https://www.tidyverse.org): a collection of useful `R` packages increasingly used for all kinds of data analysis projects. Tidyverse functions are designed to work with **tidy data** (see @fig-tidydata) and, as a result, they are often easier to combine.

![Tidy data illustration from the [Openscapes](https://www.openscapes.org/) blog [Tidy Data for reproducibility, efficiency, and collaboration](https://www.openscapes.org/blog/2020/10/12/tidy-data/) by @horstOpenscapesTidyData2020.](images/AHorst_tidydata.jpg){#fig-tidydata fig-alt="Stylized text providing an overview of Tidy Data. The top reads ‚ÄúTidy data is a standard way of mapping the meaning of a dataset to its structure. - Hadley Wickham.‚Äù On the left reads ‚ÄúIn tidy data: each variable forms a column; each observation forms a row; each cell is a single measurement.‚Äù There is an example table on the lower right with columns ‚Äòid‚Äô, ‚Äòname‚Äô and ‚Äòcolor‚Äô with observations for different cats, illustrating tidy data structure."}

Learning to manipulate data and conduct data analysis in `R` "the tidyverse-way" can help make your workflows more efficient.

> If you ensure that your data is tidy, you‚Äôll spend less time fighting with the tools and more time working on your analysis. [@TidyMessyData]

## Base `R` vs. tidyverse functions

Novice `R` users may find it confusing that many operations can be performed using either a base `R` function or a tidyverse one. For example, in @sec-ImportingData, we saw that both the base `R` function `read.csv()` and the tidyverse function `read_csv()` can be used to import CSV files. The functions have slightly different arguments and default values, which can lead to confusion, even though they are fundamentally designed to perform the same task. But don't fret over this too much: it's fine for you to use whichever function you find most convenient and intuitive and it's also absolutely fine to combine base `R` and tidyverse functions.

You will no doubt have noticed that the functions `read.csv()` and `read_csv()` have very similar but not exactly identical names. This is helpful to differentiate between the two functions. Unfortunately, some function names are found in several packages, which can lead to confusion and errors! For example, you may have noticed that when you load the tidyverse library the first time in a project, a message similar to @fig-tidyverseConflicts is printed in the Console.

![Screenshot of the `R` Console after having loaded the {tidyverse} library](images/TidyverseConflicts.png){#fig-tidyverseConflicts fig-alt="Screenshot of R Console showing the output of the command library(tidyverse). The output lists all attached core tidyverse packages and their versions and then it lists \"Conflicts: tidyverse_conflicts() ‚îÄ‚îÄ ‚úñ dplyr::filter() masks stats::filter() ‚úñ dplyr::lag()    masks stats::lag() ‚Ñπ Use the conflicted package to force all conflicts to become errors\"" width="516"}

First, the error message reproduced in @fig-tidyverseConflicts confirms that loading the {tidyverse} package has led to the successful loading of a total of nine packages and that these are now ready to use. Crucially, the message also warns us about **conflicts** between some {tidyverse} packages and base `R` packages. These conflicts are due to the fact that two functions from the {dplyr} package have exactly the same name as functions from the base `R` {stats} package. The warning informs us that, by default, the {dplyr} functions will be applied.

To force `R` to use a function from a specific package, we can use the `package::function()` syntax. Hence, to force `R` to use the base `R` {stats} `filter()` function rather than the tidyverse one, we would use `stats::filter()`. On the contrary, if we want to be absolutely certain that the tidyverse one is used, we can use `dplyr::filter()`.

![A galaxy of tidyverse-related hex stickers (artwork by [\@allison_horst](https://allisonhorst.com/allison-horst)).](images/AHorst_tidyverse.png){#fig-tidyverse fig-alt="Hex stickers flying in space. The stickers all represent tidyverse packages including stringr, tidyr, readr, tibble, and dyplr." width="300"}

In this chapter, we will explore functions from {[dplyr](https://dplyr.tidyverse.org/)}, {[stringr](https://stringr.tidyverse.org/)}, and {[tidyr](https://tidyr.tidyverse.org/)}. The popular {[ggplot2](https://ggplot2.tidyverse.org/)} tidyverse library for data visualisation following the "Grammar of Graphics" approach will be introduced in Chapter 10. Make sure that you have loaded the tidyverse packages before proceeding with the rest of this chapter.

```{r}
#| eval: false

library(tidyverse)
```

## Checking data sanity

```{r include=FALSE}
library(here)
library(checkdown)
library(tidyverse)

L1.data <- read.csv(file = here("data", "L1_data.csv"))
L2.data <- read.csv(file = here("data", "L2_data.csv"))
```

Before beginning any data analysis, it is important to always check the sanity of our data. In the following, we will use tables and descriptive statistics to do this. In Chapter 10, we will learn how to use data visualisation to check for outliers and other issues that may affect our analyses.

::: callout-warning
### Prerequisites

In this chapter and the following chapters, all examples, tasks, and quiz questions are based on data from:

> DƒÖbrowska, Ewa. 2019. Experience, Aptitude, and Individual Differences in Linguistic Attainment: A Comparison of Native and Nonnative Speakers. Language Learning 69(S1). 72‚Äì100. <https://doi.org/10.1111/lang.12323>.

You will only be able to reproduce the analyses and answer the quiz questions from this chapter if you have successfully imported the two datasets from @DabrowskaExperienceAptitudeIndividual2019. To import the datasets, follow the instructions from @sec-RProject to @sec-ImportingDataCSV and complete Task 1.
:::

### Numeric variables {#sec-CheckNumeric}

In @sec-IQR, we used the `summary()` function to obtain some useful descriptive statistics on a single numeric variable, namely the range, mean, median, and interquartile range (IQR).

```{r}
summary(L1.data$GrammarR)
```

To check the sanity of a dataset, we can use this same function on an entire data table (provided that the data is in the tidy format, see @sec-tidyverse). Thus, the command `summary(L1.data)`[^9_datawrangling-1] outputs summary statistics on all the variables of the L1 dataset - in other words, on all the columns of the data frame `L1.data`.

[^9_datawrangling-1]: Note that, throughout this chapter, long code output is shortened to save space. When you run this command on your own computer, however, you will see that the output is much longer that what is reprinted in this chapter. You will likely need to scroll up in your Console window to view it all.

```{r}
#| eval: false
summary(L1.data)
```

```{r}
#| echo: false
summary(L1.data[,c(1:12)])
```

For the numeric variables in the dataset, the `summary()` function provides us with many useful descriptive statistics to check the sanity of the data. For example, we can check whether the minimum values include improbably low values (e.g., a five-year-old participant in a written language exam) or outright impossible ones (e.g., a minus 18-year old participant!). Equally, if we know that the maximum number of points that could be obtained in the English grammar test is 100, a maximum value of more than 100 would be highly suspicious and warrant further investigation.

As far as we can see from the output of `summary(L1.data)` above, the numeric variables in @DabrowskaExperienceAptitudeIndividual2019's L1 dataset do not appear to feature any obvious problematic values.

### Categorical variables as factors {#sec-Factors}

Having examined the numeric variables, we now turn to the non-numeric, categorical ones (see @sec-Variables). For these variables, the descriptive statistics returned by `summary(L1.data)` are not as insightful. They only tell us that they each include 90 values, which corresponds to the 90 participants in the L1 dataset. As we can see from the output of the `str()` function, these categorical variables are stored in `R` as character string vectors (abbreviated in the `str()` output to "chr").

```{r}
str(L1.data$Gender)
```

Character string vectors are a useful `R` object type for text but, in `R`, categorical variables are best stored as factors. Factors are a more efficient way to store character values because each unique character value is stored only once. The data itself is stored as a vector of integers. Let's look at an example.

First, we convert the categorical variable `Gender` from `L1.data` that is currently stored as a character string vector to a factor vector called `L1.Gender.fct`.

```{r}
L1.Gender.fct <- factor(L1.data$Gender)
```

When we now inspect its structure using `str()`, we can see that `L1.Gender.fct` is a factor with two levels "F" and "M". The values themselves, however, are no longer listed as "M" "M" "M" "F" "F"..., but rather as integers: 2 2 2 1 1 1....

```{r}
str(L1.Gender.fct)
```

By default, the levels of a factor are ordered alphabetically, hence in `L1.Gender.fct`, 1 corresponds to "F" and 2 to "M".

The summary output of factor vectors are far more insightful than of character variables (and look rather like the output of the `table()` function that we used in @sec-Mode).

```{r}
summary(L1.Gender.fct)
```

The tidyverse package [{forcats}](https://forcats.tidyverse.org/) has a lot of very useful functions to manipulate factors. They all start with `fct_`.

::: column-margin
![Hex sticker of the [{forcats}](https://forcats.tidyverse.org/) package](images/hex_forcats.png){#fig-hexdplyr width="100" alt-text="The forcats hex sticker logo"}
:::

::: callout-tip
#### Quiz time! {.unnumbered}

[**Q1.**]{style="color:green;"} Type `?fct_` in an `R` script or directly in the Console and then press the tab key (‚Üπ or ‚á• on your keyboard). A list of all loaded functions that start with `fct_` should pop up. Which of these is *not* listed?

```{r echo=FALSE}
check_question("fct_mutate",
               options = c("fct_count",
                           "fct_mutate",
                           "fct_na_level_to_value",
                           "fct_rev",
                           "fct_reorder"),
               type = "radio",
               button_label = "Check answer",
               right = "That's right!",
               wrong = "No, if you call the help file of this function using `?` or `help()`, you will see that this function is part of the {forcats} package. You should have loaded it when you loaded the {tidyverse} collection of packages using `library(tidyverse)` at the beginning of the chapter.")

```

¬†

[**Q2.**]{style="color:green;"} In the factor object `L1.Gender.fct` (which we created above), the first level is "F" because it comes first in the alphabet. Which of these commands will make "M" the first level instead? Check out the help files of the following [{forcats}](https://forcats.tidyverse.org/) functions to understand what they do and try them out.

```{r echo=FALSE}
check_question(c("fct_relevel(L1.Gender.fct, \"M\")",
                           "fct_rev(L1.Gender.fct)",
                           "fct_recode(L1.Gender.fct, first = \"M\", second = \"F\")"),
               options = c("fct_relevel(L1.Gender.fct, \"M\")",
                           "fct_rev(L1.Gender.fct)",
                           "fct_recode(L1.Gender.fct, first = \"M\", second = \"F\")",
                           "fct_reorder(L1.Gender.fct, c(\"M\", \"F\")))",
                           "fct_lump(L1.Gender.fct)"),
               random_answer_order = TRUE,
               type = "check",
               button_label = "Check answer",
               right = "Correct, well done!",
               wrong = "Not quite. Note that three of these commands will yield the desired outcome!")
check_hint("Try these commands out! When you print an entire factor variable in the Console, the order of the levels is displayed the bottom of the output. So if the output reads \"Levels: M F\", then the operation has been successful.", 
           hint_title = "üòá Hover for a hint", 
           type = "onmouseover")

```
:::

## Pre-processing data

### Using `mutate()` to add and replace columns {#sec-mutate}

In the previous section, we stored the factor representing L1 participants' gender as a separate `R` object called `L1.Gender.fct`. If, instead, we want to add this factor as an additional column to our dataset, we can use the `mutate()` function from [{dplyr}](https://dplyr.tidyverse.org/).

::: column-margin
![Hex sticker of the [{dplyr}](https://dplyr.tidyverse.org/) package](images/hex_dplyr.png){width="100"}
:::

```{r}
L1.data <- L1.data |> 
  mutate(Gender.fct = factor(L1.data$Gender))
```

The `mutate()` function allows us to add new columns to a dataset. By default, it also keeps all the existing ones (to control which columns are retained, check the help file and read about the ".keep =" argument).

![Artwork explaining the `dplyr::mutate()` function by [\@allison_horst](https://allisonhorst.com/allison-horst).](images/AHorst_mutate.png){#fig-mutate fig-alt="Cartoon of cute fuzzy monsters dressed up as different X-men characters, working together to add a new column to an existing data frame. Stylized title text reads ‚Äúdplyr::mutate - add columns, keep existing.‚Äù" width="465"}

We can use the `colnames()` function to check that the new column has been correctly appended to the table. Alternatively, you can use the `View()` function to display the table in full in a new RStudio tab. In both cases, you should see that the new column is now the last column in the table (column number 32).

```{r}
colnames(L1.data)
```

Watch out: if you add a new column to a table using an existing column name, `mutate()` will overwrite the entire content of the existing column with the new values! In the following code chunk, we are therefore overwriting the character vector `Gender` with a factor vector also called `Gender`. We should only do this if we are certain that we won't need to compare the original values with the new ones!

```{r}
L1.data <- L1.data |> 
  mutate(Gender = factor(L1.data$Gender))
```

### Using `across()` to transform multiple columns {#sec-across}

In addition to `Gender`, there are quite a few more character vectors in `L1.data` that represent categorical variables and that would therefore be better stored as factors. We could use `mutate()` and `factor()` to convert them one by one like we did for `Gender` above, but that would require several lines of code in which we could easily make a silly error or two. Instead, we can use a series of neat tidyverse functions to convert all character vectors to factor vectors in one go.

```{r}
L1.data.fct <- L1.data |> 
  mutate(across(where(is.character), factor))
```

Above, we use `mutate()` to convert `across()` the entire dataset all columns `where()` there are character vectors to `factor()` vectors (using the `is.character()` function to determine which columns contain character vectors).

![Artwork explaining the `across()` function by [\@allison_horst](https://allisonhorst.com/allison-horst).](images/AHorst_across.png){#fig-across fig-alt="A cute round fuzzy monster with fairy wings and a wand, with a party hat on reading ‚Äúmean‚Äù, bouncing across the top of a data table applying the function to each column. Stylized text reads: ‚Äúdplyr::across() - use within mutate() or summarize() to apply function(s) to a selection of columns!‚Äù An example shows the use within summarize: summarize(across(where(is.numeric), mean))."}

We can check that the correct variables have been converted by comparing the output of `summary(L1.data)` (partially printed in @sec-CheckNumeric) with the output of `summary(L1.data.fct)` (partially printed below).

```{r}
#| eval: false
summary(L1.data.fct)
```

```{r}
#| echo: false
summary(L1.data.fct[,c(1:12)])
```

::: callout-caution
#### Task 1 {.unnumbered}

In this task, you will do some data wrangling on the L2 dataset from @DabrowskaExperienceAptitudeIndividual2019.

[**a.**]{style="color:green;"} Which of these columns from `L2.data` represent categorical variables and therefore ought to be converted to factors?

```{r echo=FALSE}
check_question(c("OccupGroup", "NativeLg", "EdNative"),
               options = c("OccupGroup", "NativeLg", "EdNative", "Arrival", "FirstExp", "UseEngC"),
button_label = "Check answer",
random_answer_order = TRUE,
type = "check",
right = "That's right!",
wrong = "Not quite. Three of the above are categorical variables.")
check_hint("Run the `str(L2.data)` command to examine the structure of the L2 dataset.", hint_title = "üê≠ Click on the mouse for a hint.")

```

[**b.**]{style="color:green;"} Convert all character vectors of `L2.data` to factors and save the new table as `L2.data.fct`. Use the `str()` function to check that your conversion has worked as planned. How many different factor levels are there in the categorical variable `Occupation`?

```{r echo=FALSE}
check_question("48",
               options = c("48", "44", "27", "4", "45", "67"),
button_label = "Check answer",
random_answer_order = TRUE,
type = "radio",
right = "That's right.",
wrong = "No")
```

```{r}
#| code-fold: true
#| code-summary: "üê≠ Click on the mouse to view `R` code to help you answer question **c.**"
#| echo: true
#| results: "hide"

L2.data.fct <- L2.data |> 
  mutate(across(where(is.character), factor))

str(L2.data.fct)
```

[**c.**]{style="color:green;"} Use the `summary()` and `str()` functions to inspect the sanity of L2 dataset now that you have converted all the character vectors to factors. Have you noticed that there three factor levels in the `Gender` variable of the L2 dataset whereas there are only two in the L1 dataset? What is the most likely reason for this?

```{r echo=FALSE}
check_question("Because sometimes \"female\" was recorded as lower-case \"f\" rather than upper-case \"F\".",
               options = c("Because the gender of six female participants was recorded as lower-case \"f\" rather than upper-case \"F\".",
                           "Because these six participants were under 18 at the time of data collection.",
                           "Because these six participants identify as non-binary.",
                           "Because these six participants declined to answer the question about their gender."),
button_label = "Check answer",
random_answer_order = TRUE,
type = "radio",
right = "Your intuition is correct (and this is confirmed by the author in the description of the L2 participants in the published paper).",
wrong = "No, it turns out that this is not the reason.")
check_hint("Once you have converted all the character vectors to factors in both `L1.data` and `L2.data`, compare the outputs of `summary(L1.data$Gender)` and `summary(L2.data$Gender)`.", hint_title = "üê≠ Click on the mouse for a hint.")
```

¬†
:::

## Data cleaning üßº

By closely examining the data, we noticed that the values of the categorical variables were not always entered in a consistent way, which may lead to incorrect analyses. For example, in the L2 dataset, most female participants' gender is recorded as `F` except for six participants, where it is `f`. As `R` is a case-sensitive language, these two factor levels are treated as two different levels of the `Gender` variable. This means that any future analyses on the effect of `Gender` on language learning will compare participants across these three groups.

```{r}
summary(L2.data.fct$Gender)
```

::: callout-important
To ensure that our analyses are reproducible from the beginning to the end, it is crucial that we document *all* of our corrections in a script. This ensures that if we need to go back on any data pre-processing decision that we made or if we need to make any additional corrections, we can do so without having to re-do our entire analyses. In addition, it means that our corrections and other data pre-processing steps are transparent and can be inspected and challenged by our peers.
:::

### Using {stringr} functions

To convert all of the lower-case "f" in the `Gender` variable to upper-case "F", we can combine the `mutate()` with the `str_to_upper()` function. This ensures that all values in the new `Gender.corrected` column are in capital letters.

```{r}
L2.data.cleaned <- L2.data.fct |> 
  mutate(Gender.corrected = str_to_upper(Gender))
```

We should check that our correction has gone to plan by comparing the original `Gender` variable with the new `Gender.corrected`. To this end, we display them side by side using the `select()` function from {dplyr}.

```{r eval = FALSE}
L2.data.cleaned |> 
  select(Gender, Gender.corrected)
```

```{r echo = FALSE}
# Printing all rows takes up too much space, therefore I only print the first six rows with this chunk, but show the code in the chunk above that displays all values so that the reader can examine all rows.
L2.data.cleaned |> 
  select(Gender, Gender.corrected) |> 
  head()
```

Like `mutate()` and `select()`, `str_to_upper()` also comes from a tidyverse package[^9_datawrangling-2]. All functions that begin with `str_` come from the {stringr} package, which features lots of useful functions to manipulate character string vectors. These include:

[^9_datawrangling-2]: The equivalent base `R` function is `toupper()`.

::: column-margin
![Hex sticker of the [{stringr}](https://stringr.tidyverse.org/) package](images/hex_stringr.png){#fig-hexstringr width="100"}
:::

-   `str_to_upper()` converts to string upper case.
-   `str_to_lower()` converts to string lower case.
-   `str_to_title()` converts to string title case (i.e. only the first letter of each word is capitalised).
-   `str_to_sentence()` converts string to sentence case (i.e. only the first letter of each sentence is capitalised).

For more useful functions to manipulate character strings, check out the {stringr} cheatsheet: <https://github.com/rstudio/cheatsheets/blob/main/strings.pdf>.

Note that in the code chunk above, we did not save the output to a new `R` object. We merely printed the output in the Console. Once we have checked that our data wrangling operation went well, we can overwrite the original `Gender` variable with the cleaned version by using the original variable name as the name of the new column.

```{r}
L2.data.cleaned <- L2.data.fct |> 
  mutate(Gender = str_to_upper(Gender))
```

Using `summary()` or `class()`, we can see that manipulating the `Gender` variable with a function from {stringr} has resulted in the factor variable being converted back to a character variable.

```{r}
summary(L2.data.cleaned$Gender)
class(L2.data.cleaned$Gender)
```

We therefore need to add a line of code to reconvert it to a factor. We can do this within a single `mutate()` command.

```{r}
L2.data.cleaned <- L2.data.fct |> 
  mutate(Gender = str_to_upper(Gender),
         Gender = factor(Gender))

class(L2.data.cleaned$Gender)
```

Now the `summary()` function provides a tally of male and female participants that corresponds to the values reported in @DabrowskaExperienceAptitudeIndividual2019 [p.5].

```{r}
summary(L2.data.cleaned$Gender)
```

::: callout-tip
#### Task 2 {.unnumbered}

This task focuses on the `OccupGroup` variable, which is found in both the L1 and L2 datasets.

`OccupGroup` is a categorical variable that groups participants' professional occupations into different categories. In the L2 dataset, there are four occupational categories.

```{r}
L2.data.fct |> 
  count(OccupGroup)
```

@DabrowskaExperienceAptitudeIndividual2019 [p. 6] explains that these abbreviations correspond to:

> **C**: Clerical positions\
> **I**: Occupationally inactive (i.e., unemployed, retired, or homemakers)\
> **M**: Manual jobs\
> **PS**: Professional-level jobs or studying for a degree

[**a.**]{style="color:green;"} Examine the `OccupGroup` variable in the L1 dataset (`L1.data`). What do you notice? Why are L1 participants grouped into five rather than four occupational categories?

```{r echo=FALSE}
check_question("Because an extra space character was accidentally added after one \"PS\" value.",
               options = c("Because this study has more L1 participants than L2 participants.",
                           "Because one L1 participant had an occupation that did not fit any of the other four categories.",
                           "Because an extra space character was accidentally added after one \"PS\" value.",
                           "Because the original data file was saved in a format incompatible with R."),
               type = "radio",
button_label = "Check answer",
right = "That's right, well done! This **trailing space** needs to be removed otherwise `R` (and most other data analysis programmes) will consider this value to represent a fifth occupational category.",
wrong = "No, that's not the reason. Have you noticed that, in the output of the `summary(L1.data.fct$OccupGroup)` command, the last category does not appear to be right-aligned like the others? Why might that be?")

```

```{r collapse=TRUE}
#| code-fold: true
#| code-summary: "üê≠ Click on the mouse to view `R` code to help you answer question **a.**"
#| echo: true

summary(L1.data.fct$OccupGroup)

L1.data.fct |> 
  count(OccupGroup)
```

¬†

[**b.**]{style="color:green;"} Which {stringr} function removes trailing spaces from character strings? Find the appropriate function on the [{stringr} cheatsheet](https://github.com/rstudio/cheatsheets/blob/main/strings.pdf).

```{r echo=FALSE}
check_question("str_trim()",
               options = c("str_trim()",
                           "str_ends()",
                           "str_flatten()",
                           "str_glue()",
                           "str_squish()",
                           "str_extract()"
                          ),
               button_label = "Check answer",
               random_answer_order = TRUE,
               type = "radio",
               right = "That's right! Now, use `str_trim()` to remove all trailing spaces in the `OccupGroup` variable. Check that you then have an L1 dataset with only four occupational categories.",
               wrong = "No, this function won't help us for this task. You can use the `?` command to find out more about each of these functions if you're struggling to interpret the [{stringr} cheatsheet](https://github.com/rstudio/cheatsheets/blob/main/strings.pdf).")
check_hint("The function can be found in the \"Manage Lengths\" section of the [{stringr} cheatsheet](https://github.com/rstudio/cheatsheets/blob/main/strings.pdf).", hint_title = "üê≠ Click on the mouse for a hint.")
```

```{r}
#| code-fold: true
#| code-summary: "Show `R` code to use the function and check that it worked as expected."
#| echo: true
#| results: "hide"

L1.data.cleaned <- L1.data.fct |> 
  mutate(OccupGroup = str_trim(OccupGroup)) # Apply the str_trim() function to the OccupGroup variable

L1.data.cleaned |> 
  count(OccupGroup)
```

¬†

[**c.**]{style="color:green;"} Following the removal of trailing whitespaces, what percentage of L1 participants have a professional-level jobs/are studying for a degree?

```{r echo=FALSE}
check_question("28%",
               options = c("20%",
                           "22.22%",
                           "24.44%",
                           "25%",
                           "26%",
                           "28%"
                          ),
               button_label = "Check answer",
               type = "radio",
               right = "That's right, well done!",
               wrong = "No, check the hint or look at the `R` code below if you're stuck.")
check_hint("We are looking for the proportion of L1 participants assigned the occupational group \"PS\". You will need to use the `count()` and the `mutate()` functions to be able to answer this question.", hint_title = "üê≠ Click on the mouse for a hint.")
```

```{r}
#| code-fold: true
#| code-summary: "Show `R` code to answer question **c.**"
#| echo: true
#| results: "hide"

L1.data.cleaned |> 
  count(OccupGroup) |> 
  mutate(percent = n / sum(n),
         percent = percent*100, 
         percent = round(percent, digits = 2)
         )

```
:::

So far, we have looked at rather simple data cleaning cases. Let's now turn to a slightly more complex one: In the L2 dataset, the variable `NativeLg` contains character string values that correspond to the L2 participants' native language. Using the base `R` function `unique()`, we can see that are a total of 22 unique values in this variable. However using `sort()` to order these 22 values alphabetically, we can easily see that there are, in fact, fewer unique native languages in this dataset due to different spellings and the inconsistent use of upper-case letters.

```{r}
L2.data$NativeLg |> 
  unique() |> 
  sort()
```

If we convert all `NativeLg` values to title case, we can reduce the number of unique languages to 19.

```{r}
L2.data$NativeLg |>
  str_to_title() |> 
  unique() |> 
  sort()
```

Second, to facilitate further analyses, we may decide to only retain the first word/language from each entry as this will further reduce the number of different levels in this categorical variable. To abbreviate "Mandarin Chinese" to "Mandarin", we can use the `word()` function from the {stringr} package.

Below is an extract of the help page for the `word()` function (accessed with the command `?word`). Can you work out how to extract the first word of a character string?

> |                |                 |
> |----------------|----------------:|
> | word {stringr} | R Documentation |
>
> ## Extract words from a sentence {#sec-WordHelp}
>
> ### Description
>
> Extract words from a sentence
>
> ### Usage
>
> ```         
> word(string, start = 1L, end = start, sep = fixed(" "))
> ```
>
> ### Arguments
>
> +----------------+-------------------------------------------------------------------------------------------------------------------------+
> | `string`       | Input vector. Either a character vector, or something coercible to one.                                                 |
> +----------------+-------------------------------------------------------------------------------------------------------------------------+
> | `start`, `end` | Pair of integer vectors giving range of words (inclusive) to extract. If negative, counts backwards from the last word. |
> |                |                                                                                                                         |
> |                | The default value select the first word.                                                                                |
> +----------------+-------------------------------------------------------------------------------------------------------------------------+
> | `sep`          | Separator between words. Defaults to single space.                                                                      |
> +----------------+-------------------------------------------------------------------------------------------------------------------------+

The help file tells us that "The default value select the first word". In our case, this means that we can simply use the `word()` function with no specified argument as this will automatically retain only the first word of every entry.

```{r}
L2.data$NativeLg |>
  str_to_title() |> 
  word() |> 
  unique() |> 
  sort()
```

Alternatively, we can choose to specify the "start" argument as a reminder of what we did and to better document our code. The output is exactly the same.

```{r}

L2.data$NativeLg |>
  str_to_title() |> 
  word(start = 1) |> 
  unique() |> 
  sort()
```

As you can tell from the output above, the `word()` function uses white space to identify word boundaries. In this dataset, however, some of the participants' native languages are separated by forward slashes (`/`) rather than or in addition to spaces. The "Usage" section of the help file for the `word()` function (see `?word` and @sec-WordHelp) also confirms that the default word separator symbol is a space and shows us the syntax for changing the default separator. Below we change it to a forward slash.

```{r}
L2.data$NativeLg |>
  str_to_title() |> 
  word(start = 1, sep = fixed("/")) |> 
  unique() |> 
  sort()
```

Now we can combine these two word extraction methods using the pipe operator (`|>`) so that "Cantonese/Hokkein" is abbreviated to "Cantonese" and "Mandarin/ Cantonese" to "Mandarin".

```{r}
L2.data$NativeLg |>
  str_to_title() |> 
  word(start = 1) |> # Extracts the first word before the first space
  word(start = 1, sep = fixed("/")) |> # Extracts the first word before the first forward slash
  unique() |> 
  sort()
```

::: {.callout-note collapse="true"}
#### Going further: Using regular expressions (regex) ü§ì

Many functions of the {stringr} package involve **regular expressions** (short: **regex**). The second page of the [{stringr} cheatsheet](https://github.com/rstudio/cheatsheets/blob/main/strings.pdf) provides a nice overview of how regular expressions can be used to manipulate character strings in `R`.

Using the `str_extract()` function together with the regex `\\w+`, it is possible to extract the first word of each `NativeLg` value with just one line of code:

```{r}
L2.data$NativeLg |>
  str_to_title() |> 
  str_extract("\\w+") |> 
  unique() |> 
  sort()
```

Regular expressions provide incredibly powerful and versatile ways to work with text in all kinds of programming languages. When conducting **corpus linguistics** research, they also allow us to conduct complex corpus queries.

Each programming language/software has a slightly different flavour of regex but the basic principles are the same across all languages/software and are well worth learning. To get started, I highly recommend this beautifully designed interactive regex tutorial for beginners: <https://regexlearn.com/learn/regex101>. Have fun! ü§ì
:::

### Using `case_when()`

We have now reduced the number of levels in the `NativeLg` variable to just 14 unique languages. But we still have some typos to correct, e.g., "Lithunanina" and "Lituanian".

We can correct these on a case-by-case basis using `case_when()`. This is a very useful tidyverse function from the {dplyr} package that is easy to use once you have gotten used to its syntax. @fig-case_when illustrates the syntax with a toy example dataset about the dangerousness of dragons (`df`). In this annotated line of code in @fig-case_when, `mutate()` is used to add a new column called `danger` whose values depend on the type of dragon that we are dealing with. The first argument of `case_when()` determines that, when the dragon `type` is equal to "kraken", then the `danger` value is set to "extreme", otherwise the danger value is set to "high". You can see the outcome in the appended `danger` column.

![Artwork explaining the `case_when()` function by [\@allison_horst](https://allisonhorst.com/allison-horst)).](images/AHorst_case_when.png){#fig-case_when fig-alt="Cartoon showing a table with creature type (kraken, dragon, or cyclops) and age (baby, teen, or adult). The three creatures listed are adding a new column named ‚Äúdanger‚Äù, which contains the word ‚Äúextreme!‚Äù if the type is ‚Äúkraken‚Äù, or ‚Äúhigh‚Äù for any other type. Stylized text reads ‚Äúdplyr::case_when() - IF ELSE...but you love it? An example of code is shown: mutate(danger = case_when(type == ‚Äúkraken‚Äù ~ ‚Äúextreme!‚Äù, TRUE ~ ‚Äúhigh‚Äù)."}

Applying `case_when()` to fix the typos in the `NativeLg` variable in `L2.data`, we determine that:

a.  if the shortened `NativeLg` value is "Mandarine", we replace it with "Mandarin", and
b.  if the shortened `NativeLg` value corresponds to either "Lithunanina" or "Lituanian", we replace it with "Lithuanian".

Using `mutate()`, we save this cleaned-up version of the `NativeLg` variable as a new column in our `L2.data` table, which we call `NativeLg.cleaned`.

```{r}
L2.data <- L2.data |>
  mutate(
    NativeLg.cleaned = str_to_title(NativeLg) |> 
      word(start = 1) |> 
      word(start = 1, sep = fixed("/")),
    NativeLg.cleaned = case_when(
      NativeLg.cleaned == "Mandarine" ~ "Mandarin",
      NativeLg.cleaned %in% c("Lithunanina", "Lituanian") ~ "Lithuanian",
      TRUE ~ NativeLg.cleaned)
    )
```

Whenever we do any data wrangling, it is crucial that we take the time to carefully check that we have not made any mistakes in the process. To this end, we display the original `NativeLg` and the new `NativeLg.cleaned` variables side by side using the `select()` function.

```{r eval = FALSE}
L2.data |> 
  select(NativeLg, NativeLg.cleaned)
```

```{r echo = FALSE}
# Printing all rows takes up too much space, therefore I only print the first six rows with this chunk, but show the code in the chunk above that displays all values so that the reader can examine all rows.
L2.data |> 
  select(NativeLg, NativeLg.cleaned) |> 
  head()
```

As you can see, only the first six rows of the table are printed above. Run the code yourself to check all the other rows.

::: {.callout-note collapse="true"}
#### Using base `R` functions instead

This chapter focuses on {tidyverse} functions, however all of the above data wrangling and cleaning operations can equally be achieved using base `R` functions. For example, the `mutate()` code chunk above could be replaced by the following lines of base `R` code.

```{r}
#| code-line-numbers: true

L2.data$NativeLg.cleaned.base <- gsub("([a-zA-Z]+).*", "\\1", L2.data$NativeLg)
L2.data$NativeLg.cleaned.base <- tools::toTitleCase(L2.data$NativeLg.cleaned.base)
L2.data$NativeLg.cleaned.base[L2.data$NativeLg.cleaned.base == "Mandarine"] <- "Mandarin"
L2.data$NativeLg.cleaned.base[L2.data$NativeLg.cleaned.base %in% c("Lithunanina", "Lituanian")] <- "Lithuanian"

```

-   With the first line, we extract the first string of letters before any space or slash in `NativeLg` and save this to a new variable called `NativeLg.cleaned.base`.

-   The second line converts all the values of the new variable to title case using a base `R` function from the {tools} package. The {tools} package comes with `R` so you don't need to install it separately but, if you haven't loaded it earlier in your `R` session, you need to call the function with the prefix `tools::` so that `R` knows where to find the `toTitleCase()` function.

-   The third line corrects a typo with a direct replacement, whilst the fourth replaces two typos with a single correction.

If we now compare the variable created with the tidyverse code (`NativeLg.cleaned`) vs. the one created using base R functions only (`NativeLg.cleaned.base`), we can see that they are exactly the same.

```{r}
#| eval: false

L2.data |> 
  select(NativeLg.cleaned, NativeLg.cleaned.base) 

```

```{r}
#| echo: false

L2.data |> 
  select(NativeLg.cleaned, NativeLg.cleaned.base) |> 
  head()

```

An undeniable advantage of sticking to base `R` functions is that your code is more portable as it does not require the installation of any additional packages, keeping dependencies on external packages to the minimum. However, base `R` lacks the consistency of the tidyverse framework, which can make certain data transformation tasks considerably more tricky and code less readable (and therefore transparent) to yourself and others.
:::

::: callout-caution
#### Task 3

For some analyses, it may be useful to group together participants whose native languages come from the same family of languages. For example, French, Spanish and Italian L1 speakers, may be considered as a one group of participants whose native language is a Romance language.

Use `mutate()` and `case_when()` to add a new variable to `L2.data` that corresponds to the L2 participant's native language family. Give this new variable an appropriate name. Use the following language family categories:

-   Baltic
-   Chinese
-   Germanic
-   Hellenic
-   Romance
-   Slavic

If you're not sure which language family a language belongs to, look it up on Wikipedia (e.g. the Wikipedia page on the [German language](https://en.wikipedia.org/wiki/German_language) informs us in a text box at the top of the article that German is a Germanic language).

[**a.**]{style="color:green;"} Which language family is the *second* most represented among L2 participants' native languages in @DabrowskaExperienceAptitudeIndividual2019?

```{r echo=FALSE}
check_question("Chinese",
               options = c("Baltic", "Chinese", "Germanic", "Hellenic", "Romance", "Slavic"),
               type = "radio",
button_label = "Check answer",
right = "‚úÖ That's right, well done!",
wrong = "No, have you checked that you have correctly classified all participants' native languages?")
check_hint("Once you have created your new variable, use the `table()` or `count()` function to see the distribution of language families omong L2 participants.", hint_title = "üê≠ Click on the mouse for a hint.")

```

¬†

[**b.**]{style="color:green;"} How many L2 participants are native speakers of a language that belongs to the family of Romance languages?

```{r echo=FALSE}
check_question(c("6", "six"),
               button_label = "Check answer",
               right = "‚úÖ Tr√®s bien! ¬°Muy bien hecho! Ottimo!",
               wrong = "No, that's incorrect. Check out the hint or, if you're really stuck, the solution below.")
check_hint("Use the `count()` function as explained above to obtain a tally of the number of participants in each language family.", hint_title = "üê≠ Click on the mouse for a hint.")
```

¬†

[**c.**]{style="color:green;"} What percentage of L2 participants have a Slavic native language? Round your answer to the nearest percent.

```{r echo=FALSE}
check_question(c("58", "fifty-eight", "fifty eight", "58%", "58 %", "58 percent", "fifty-eight percent", "fifty eight percent"),
               button_label = "Check answer",
               right = "‚úÖ Yes, nice data wrangling job!",
               wrong = "No, that's incorrect. First check the hint and, if you're still stuck, take a look at the solution below.")
check_hint("You can copy the code from the previous section to add a \"percent\" column. Ensure that you adjust the correct argument in the `round()` function to obtain percentages rounded off the nearest percent.", hint_title = "üê≠ Click on the mouse for a hint.")
```

¬†
:::

::: {.callout-note collapse="true"}
#### Click here for the solution to Task 3

As always, there are several solutions to solving this task. Here is one solution based on what we have covered so far in this chapter.

[**a.**]{style="color:green;"} Note that the following code will only work if you followed the instructions in the section above to create the `NativeLg.cleaned` variable as it relies on this variable to create the new `NativeLgFamily` variable. I chose `NativeLgFamily` as the new column name. You may well have chosen a different name (see naming guidelines in @sec-NamingObjects).

```{r}
L2.data <- L2.data |> 
  mutate(NativeLgFamily = case_when(
    NativeLg.cleaned == "Lithuanian" ~ "Baltic",
    NativeLg.cleaned %in% c("Cantonese", "Mandarin", "Chinese") ~ "Chinese",
    NativeLg.cleaned == "German" ~ "Germanic",
    NativeLg.cleaned == "Greek" ~ "Hellenic",
    NativeLg.cleaned %in% c("French", "Italian", "Spanish") ~ "Romance",
    NativeLg.cleaned %in% c("Polish", "Russian") ~ "Slavic"))
```

As always, it is important to check that things have gone to plan.

```{r eval=FALSE}
L2.data |> 
  select(NativeLg.cleaned, NativeLgFamily)
```

```{r echo=FALSE}
# Printing all rows takes up too much space, therefore I only print the first six rows with this chunk, but show the code in the chunk above that displays all values so that the reader can examine all rows.
L2.data |> 
  select(NativeLg.cleaned, NativeLgFamily) |> 
  head()
```

[**b.**]{style="color:green;"} We can display the distribution of language families using either the base `R` `table()` function or the {tidyverse} `count()` function.

```{r}
table(L2.data$NativeLgFamily)

L2.data |> 
  count(NativeLgFamily)
```

[**c.**]{style="color:green;"} We can add a column to show the distribution in percentages by adding a new "percent" column to the `count()` table using `mutate()`.[^9_datawrangling-3] The steps are the following:

1.  We start with the dataset that contains the new `NativeLgFamily` variable.
2.  We pipe it into the `count()` function. As shown above, this function produces a frequency table with counts stored in the variable `n`.
3.  We divide the number of participant with each native language (`n`) by the total number of participants (`sum(n)`). We obtain proportions ranging from 0 to 1.
4.  We multiply these by 100 to get percentages.
5.  We round the percentages to two decimal places.
6.  We reorder the table so that the most represented group is at the top. To do so, we pipe our table into the `dplyr::arrange()`. By default, `arrange()` orders values in ascending order (from smallest to largest); hence, we add the `desc()` function to sort the table in descending order of frequency.

```{r}
#| code-line-numbers: true

L2.data |> 
  count(NativeLgFamily) |> 
  mutate(percent = n / sum(n),
         percent = percent*100, 
         percent = round(percent, digits = 0)
         ) |> 
  arrange(desc(n))
```
:::

[^9_datawrangling-3]: Note that this a {tidyverse} approach to working out percentages, see @sec-Mode for a base `R` approach.

## Combining datasets

So far, we have analysed the L1 and L2 datasets individually. In the following chapters, however, we will conduct comparative analyses, comparing the performance of the L1 and L2 participants in the various language-related tests conduced as part of @DabrowskaExperienceAptitudeIndividual2019. To this end, we need to create a combined table that includes the data of all participants from @DabrowskaExperienceAptitudeIndividual2019.

Remember that both tables, `L1.data` and `L2.data`, are in a tidy data format. This means that:

-   each row represents an observation (i.e., here, a participant),
-   each cell represents a measurement, and
-   each variable forms a column.

To combine the two datasets, therefore, we need to combine the rows of the two tables. However, we cannot simply add the rows of the `L2.data` table to the bottom of `L1.data` table because, as shown below, the two tables do not have the same number of columns and the shared columns are not in the same position! We therefore need to ensure that, when the two datasets are combined, the shared columns are aligned.

```{r}
colnames(L1.data)
```

```{r}
colnames(L2.data)
```

The {dplyr} package boasts an array of useful functions to combine tables (see @fig-dplyrcheatsheet). For our purposes, `bind_rows()` appears to be the perfect function.[^9_datawrangling-4]

[^9_datawrangling-4]: We could also use the `full_join()` function since we want to retain all rows and all columns from both datasets.

![Extract of the [data transformation with {dplyr} cheatsheet](https://rstudio.github.io/cheatsheets/data-transformation.pdf) (CC BY SA Posit Software, PBC)](images/dplyr_cheatsheet_extract.png){#fig-dplyrcheatsheet fig-alt="Extract from dplyr cheatsheet showing all the \"join\" functions. Screenreader friendly version can be found here: https://rstudio.github.io/cheatsheets/html/data-transformation.html" out-width="80%"}

However, when we try to combine `L1.data` and `L2.data` using `bind_rows()`, we get an error message... üò¢ Does this error remind you of Q10 from @sec-DataTypes by any chance?

```{r}
#| eval: false

combined.data <- bind_rows(L1.data, L2.data)
```

```         
Error in `bind_rows()`:
! Can't combine `..1$Participant` <character> and `..2$Participant` <integer>.
```

What this error message tells us is that the `bind_rows()` function cannot combine the two `Participant` columns because in `L1.data` it is a string character vector, whereas in `L2.data` it is an integer vector. However, to avoid data loss, `bind_rows()` can only match columns of the same data type!

We must therefore first convert the `Participant` variable in `L2.data` to a character vector.

```{r}
L2.data <- L2.data |> 
  mutate(Participant = as.character(Participant))
```

Now, we can combine the two data frames using `bind_rows()`.

```{r}
combined.data <- bind_rows(L1.data, L2.data)
```

The problem is that now that we have merged our two datasets into one, it's not obvious which rows correspond to L1 participants and which to L2 participants! There are various ways to solve this, but here's a simple **three-step solution** that relies exclusively on functions that you are already familiar with.

**Step 1:** We add a new column to `L1.data` called `Group` and fill this column with the value "L1" for all rows.

```{r}
L1.data <- L1.data |> 
  mutate(Group = "L1")
```

**Step 2:** We add a new column to `L2.data` also called `Group` and fill this column with the value "L2" for all rows.

```{r}

L2.data <- L2.data |> 
  mutate(Group = "L2")
```

**Step 3:** We use `bind_rows()` as above to combine the two datasets that now both include the extra `Group` column.[^9_datawrangling-5].

[^9_datawrangling-5]: Alternatively, you may have gathered from the cheatsheet (@fig-dplyrcheatsheet) that the `bind_rows()` function has an optional ".id" argument that can be used to create an additional column to disambiguate between the two combined datasets. In this case, we do not need to add a `Group` column to both datasets prior to combining them.

    ```{r}
    combined.data <- bind_rows(L1 = L1.data, 
                               L2 = L2.data, 
                               .id = "Group")
    ```

```{r}
combined.data <- bind_rows(L1.data, L2.data)

```

**Verification step:** The `combined.data` table now includes the column `Group`, which we can use to easily identify the observations that belong to L1 and L2 participants. As expected, our combined dataset includes 90 participants from the L1 group and 67 from the L2 group:

```{r}
combined.data |> 
  count(Group)
```

Our combined dataset contains all the columns that appear in either `L1.data` or `L2.data`. Check that this is the case by examining the structure of the new dataset with `str(combined.data)`.

You will have noticed that, in some columns, there are lots of `NA` ("Not Available") values. These represent **missing data**. `R` has inserted these `NA` values in the columns that only appear in one of the two datasets. For example, the L1 dataset does not include an `Arrival` variable (indicating the age when participants first arrived in an English-speaking country), presumably because they were all *born* in an English-speaking country! We only have this information for the L2 participants and this explains the 90 `NA` values in the `Arrival` column of the combined dataset.

```{r}
combined.data$Arrival
```

We can also check this by cross-tabulating the `Group` and the `Arrival` variables.

```{r}
#| eval: false

combined.data |> 
  count(Group, Arrival)
```

```{r}
#| echo: false

combined.data |> 
  count(Group, Arrival) |> 
  head()
```

Run `View(combined.data)` to inspect the combined dataset and check in which other columns there are `NA` values.

:::: callout-note
#### What if my data is not yet in tidy format? ü§®

Combining the two datasets from @DabrowskaExperienceAptitudeIndividual2019 was relatively easy because the data was already in tidy format. But, fear not: if you need to first convert your data to tidy format, the [{tidyr}](https://tidyr.tidyverse.org/) package has got you covered! üòé

The `pivot_longer()` and `pivot_wider()` functions allow you to easily convert tables from "long" to "wide" format and vice versa (see @fig-tidyrcheatsheet).

![Extract of the [data tidying with tidyr cheatsheet](https://github.com/rstudio/cheatsheets/blob/main/tidyr.pdf) (CC BY SA Posit Software, PBC)](images/tidyr_cheatsheet_extract.png){#fig-tidyrcheatsheet fig-alt="pivot_longer(data, cols, names_to = \"name\", values_to = \"value\", values_drop_na = FALSE) \"Lengthen\" data by collapsing several columns into two. Column names move to a new names_to column and values to a new values_to column. pivot_longer(table4a, cols = 2:3, names_to =\"year\", values_to = \"cases\") pivot_wider(data, names_from = \"name\", values_from = \"value\") The inverse of pivot_longer(). \"Widen\" data by expanding two columns into several. One column provides the new column names, the other the values. pivot_wider(table2, names_from = type, values_from = count)" out-width="60%"}

::: column-margin
![Hex sticker of the [{tidyr}](https://tidyr.tidyverse.org/) package](images/hex_tidyr.png){#fig-tidyr width="100"}
:::

Remember to carefully check the output of any data manipulation that you do *before* moving on to doing any analyses! To this end, the `View()` function is particularly helpful.
::::

::: callout-warning
### Using AI tools for coding ‚ö†Ô∏è

Note that older textbooks/tutorials, and especially AI tools such as ChatGPT that have been trained on older web data, will frequently suggest **superseded** (i.e. outdated) functions for data manipulation such as `spread()`, `gather()`, `select_all()`, and `mutate_if()`. If you use superseded functions, your code will still work, but `R` will print a warning in the Console and usually suggest a modern alternative.

AI tools may also suggest using functions that are **deprecated**. As with superseded functions, you will get a warning message with a recommended alternative. In this case, however, you must follow the advice of the warning, as writing new code with deprecated functions is really asking for trouble! Deprecated functions are scheduled for removal, which means that your code will eventually no longer run on up-to-date `R` versions.

![The four main stages of the lifecycle of `R` packages, functions, function arguments: **experimental** developments can become **stable** and stable can eventually become **deprecated** or **superseded** (image by Henry and Wickham 2023 for Posit Software, PBC, <https://lifecycle.r-lib.org/articles/stages.html>).](images/lifecycle.svg){#fig-lifecycle}

In sum, to ensure the future compatibility of your code, do not ignore warnings about deprecated functions and, in general, *never ever* blindly trust the output of AI tools!
:::

## A pre-processing pipeline

So far in this chapter, we have learnt how to pre-process data for future statistical analyses and data visualisation. In the process, we have learnt about lots of different functions, mostly from the tidyverse environment (see @sec-tidyverse ü™ê). Now it's time to put everything together and save our pre-processed combined dataset for future use.

But, first, let's recap all of the data wrangling operations that we performed in this chapter and combine them into one code chunk. Before running this code, we first reload the original data from @DabrowskaExperienceAptitudeIndividual2019 to overwrite any changes that were made during this chapter. This will ensure that we all have exactly the same version of the dataset for the following chapters.

```{r}
library(here)

L1.data <- read.csv(file = here("data", "L1_data.csv"))
L2.data <- read.csv(file = here("data", "L2_data.csv"))
```

Then, run the following lines of code to create a new `R` object called `combined.data` that contains the wrangled data.

```{r}

L2.data <- L2.data |> 
  mutate(Participant = as.character(Participant)) |> 
  mutate(Group = "L2")  

L1.data <- L1.data |> 
  mutate(Group = "L1")

combined.data <- bind_rows(L1.data, L2.data) |>
  mutate(across(where(is.character), str_to_title)) |>
  mutate(across(where(is.character), str_trim)) |>
  mutate(OccupGroup = str_to_upper(OccupGroup)) |> 
  mutate(
    NativeLg = word(NativeLg, start = 1),
    NativeLg = word(NativeLg, start = 1, sep = fixed("/")),
    NativeLg = case_when(
      NativeLg == "Mandarine" ~ "Mandarin",
      NativeLg %in% c("Lithunanina", "Lithunanina", "Lituanian") ~ "Lithuanian",
      TRUE ~ NativeLg)) |> 
  mutate(NativeLgFamily = case_when(
    NativeLg == "Lithuanian" ~ "Baltic",
    NativeLg %in% c("Cantonese", "Mandarin", "Chinese") ~ "Chinese",
    NativeLg == "German" ~ "Germanic",
    NativeLg == "Greek" ~ "Hellenic",
    NativeLg %in% c("French", "Italian", "Spanish") ~ "Romance",
    NativeLg %in% c("Polish", "Russian") ~ "Slavic")) |> 
  mutate(across(where(is.character), factor))
```

Don't forgot to check the result by examining the output of `View(combined.data)` and `str(combined.data)`.

```{r}
#| eval: false

summary(combined.data)
```

```{r}
#| echo: false

summary(combined.data[,c(1:12)])

```

::: callout-tip
#### Quiz time! {.unnumbered}

[**Q3.**]{style="color:green;"} The following operations describe the steps performed by the data wrangling code chunk above. In which order are the operations performed?

```{r echo=FALSE}
check_question(c("Convert one variable to a character variable.",
                 "Add two new variables that each have all the same values.",
                 "Merge data from the two datasets into one.", 
                 "Convert the values of all character variables to title case.",
                 "Remove whitespace at the start and end of all values in all character variables.",
                 "Convert all the values of one variable to upper case.",
                 "Shorten and correct typos in the values of one variable.",
                 "Add a new variable based on another variable.",
                 "Convert all character string vectors to factors."), 
               type = "in_order", 
               alignment = "vertical",
               button_label = "Check answer",
               right = "Perfect! üéâ",
               wrong = "No, not quite.")
check_hint("The first three operations are 1) \"Convert one variable to a character variable.\", 2) \"Add two new variables that each have all the same values.\" and 3) \"Merge data from the two datasets into one\".", hint_title = "üê≠ Click on the mouse for a hint.")
```

¬†

[**Q4.**]{style="color:green;"} In the combined dataset, how many participants have a clerical occupation?

```{r echo=FALSE}
check_question(c("32", "thirty-two", "thirty two"),
               button_label = "Check answer",
               right = "‚úÖ",
               wrong = "‚ùå")
check_hint("Have you tried using the `summary()` function to look into the `OccupGroup` variable of `combined.data`?", hint_title = "üê≠ Click on the mouse for a hint.")
  
```

¬†

[**Q5.**]{style="color:green;"} Of the participants who have a clerical occupation, how many were over 50 years old at the time of the data collection?

```{r echo=FALSE}
check_question(c("6"),
               options = c("none", "1", "2", "6", "all of them"),
               button_label = "Check answer",
               right = "That's right! Check the solution below to see different ways to find the answer to this question. üòé",
               wrong = "That's not the correct answer. Check the hint below.",
type = "radio")
check_hint("One way to answer find the answer to this question is to cross-tabulate the `Age` and `OccupGroup` variables of `combined.data` using the count() function and then add up the numbers in your head. Check the solution below if you're stuck.", hint_title = "üê≠ Click on the mouse for a hint.")
```
:::

::: {.callout-note collapse="true"}
#### Click here for the solution to Q5

There are various ways to find the answer to Q5. Sticking to a function that we have looked at so far, you could cross-tabulate `Age` and `OccupGroup` using the `count()` function.

```{r}
#| eval: false

combined.data |> 
  count(OccupGroup, Age)
```

```{r}
#| echo: false

combined.data |> 
  count(OccupGroup, Age) |> 
  head(16)
  
```

And then add up the frequencies listed in the rows that correspond to participants with clerical jobs who are 50.

```{r}
2 + 1 + 1 + 1 +1 
```

But, of course, this is method is rather error-prone! Instead, we can use `dplyr::filter()` (see @fig-filter) to filter the combined dataset according to our two criteria of interest and then count the number of rows (i.e., participants) remaining in the dataset once the filter has been applied.

```{r}
combined.data |>
  filter(OccupGroup == "C" & Age > 50) |> 
  nrow()
```

![Artwork explaining the `dplyr::filter()` function by [\@allison_horst](https://allisonhorst.com/allison-horst).](images/AHorst_filter.png){#fig-filter fig-alt="Cartoon showing three fuzzy monsters either selecting or crossing out rows of a data table. If the type of animal in the table is ‚Äúotter‚Äù and the site is ‚Äúbay‚Äù, a monster is drawing a purple rectangle around the row. If those conditions are not met, another monster is putting a line through the column indicating it will be excluded. Stylized text reads ‚Äúdplyr::filter() - keep rows that satisfy your conditions.‚Äù"}
:::

## Saving and exporting `R` objects

As a final step, we want to save the `R` object `combined.data` to a local file on our computer so that, when we continue our analyses in a new `R` session, we can immediately start working with the wrangled dataset. We can either save the wrangled dataset as an `R` object (`.rds`) or export it as a DSV file (e.g. `.csv`, see @sec-DSV). The pros and cons of the two solutions are summarised in @tbl-saving.

| DSV files (e.g., `.csv`, `.tsv`, `.tab`) | `R` data files (`.rds`) |
|:---|:---|
| ‚úÖ Highly portable (i.e., can be opened in all standard spreadsheet software and text editors). | ‚ùå Specific to `R` and cannot be opened in standard spreadsheet software or text editors. |
| ‚ùå Inefficient for very large datasets. | ‚úÖ Efficient memory usage for more compact data storage and faster loading times in `R`. |
| ‚úÖ Universal, language-independent format and therefore suitable for long-term archiving. | ‚ùå No guarantee that older `.rds` files will be compatible with newer versions of `R` and therefore unsuitable for long-term archiving. |
| ‚ùå Loss of metadata. | ‚úÖ Preserve `R` data structures (e.g., factor variables remain stored as factors). |

: Pros and cons of saving DSV and `R` data files. {#tbl-saving}

We will save both a `.csv` and an `.rds` version of the wrangled data but in the following chapters, we will use the `.rds` file.

We will save both files to a subfolder of our project "data" folder called "processed". If we try to save the file to this subfolder before it has been created at this location we get an error message.

```{r eval = FALSE}

saveRDS(combined.data, file = here("data", "processed", "combined_L1_L2_data.rds"))

```

```         
Error in gzfile(file, mode) : cannot open the connection
```

We first need to create the "processed" subfolder before we can save to this location! There are two ways of doing this:

1.  Either in the Files pane of RStudio or in a File Navigator/Explorer window, navigate to the "data" folder and, from there, click on the "Create a new folder" icon to create a new subfolder called "processed".

2.  Alternatively, we can use the `dir.create()` function to create the subfolder from `R` itself. If the folder already exists at this location, we will get a warning.

```{r eval = FALSE}
dir.create(file.path(here("data", "processed")))
```

Now that the subfolder exists, we can save `combined.data` as an `.rds` file. We will work with this file in the following chapters.

```{r}

saveRDS(combined.data, file = here("data", "processed", "combined_L1_L2_data.rds"))

```

If you want to share your wrangled dataset with a colleague who does not (yet? üòâ) use `R`, you can use the tidyverse function `write_csv()`.[^9_datawrangling-6] Your colleague will be able to open this file in any standard spreadsheet programme or text editor (but do warn them about the dangers of opening `.csv` file in spreadsheets, see @sec-ExcelWarning!).

[^9_datawrangling-6]: As usual, there is a base `R` alternative: `write.csv()` will work just as well but, for larger datasets, it is considerably slower than `write_csv()`. For finer differences, check out the functions' respective help files.

```{r}

write_csv(combined.data, file = here("data", "processed", "combined_L1_L2_data.csv"))

```

## Check your progress üåü {.unnumbered}

Are you confident that you can...?

-   [ ] Define tidy data
-   [ ] Check the sanity of a dataset
-   [ ] Convert character vectors representing categorical data to factors
-   [ ] Add and replace columns in a table
-   [ ] Transform several columns at once
-   [ ] Use {stringr} functions to manipulate text values
-   [ ] Interpret `R` package cheatsheets
-   [ ] Gain insights from the help file of `R` functions
-   [ ] Use tidyverse functions to pre-process data in an readable and reproducible way
-   [ ] Save `R` objects as `.rds` and `.csv` files on your computer.

The following chapter stays in the tidyverse as we will learn how to use the popular tidyverse package {ggplot2} to visualise the pre-processed data from @DabrowskaExperienceAptitudeIndividual2019.
