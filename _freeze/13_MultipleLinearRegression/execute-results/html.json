{
  "hash": "06851019674a9281561b132d4a54791c",
  "result": {
    "engine": "knitr",
    "markdown": "---\nbibliography: references.bib\ncode-annotations: hover\n---\n\n# Multiple linear reg`R`ession modelling {#sec-MLR}\n\n::: callout-warning\n## Warning\n\nAs with the rest of this textbook (see [Preface](https://elenlefoll.github.io/RstatsTextbook/)), this chapter is very much **work in progress**. Feedback is very welcome.\n:::\n\n\n\n### Chapter overview {.unnumbered}\n\nIn this chapter, you will learn how to:\n\n-   Fit a linear regression model with multiple predictors\n-   Center numeric predictor variables when meaningful\n-   Interpret the coefficient estimates of a multiple linear regression model\n-   Interpret a model's coefficients of determination (multiple R^2^ and adjusted R^2^)\n-   Compute and plot the relative importance of predictors\n-   Fit interaction effects and interpret their coefficient estimates\n-   Visualise the predictions of a multiple linear regression model and its (partial) residuals\n-   Report the results of a multiple linear regression model in tabular and graphical formats\n-   Check that the assumptions of multiple linear regression models are met.\n\n## From simple to multiple linear regression models\n\nIn @sec-SLR, we used the `lm()` function to fit simple linear regression models. We saw that, like the `t.test()` and the `cor.test()` functions, the `lm()` function takes a formula as its first argument. Schematically, the formula syntax for a simple linear regression model takes the form of:\n\n```         \noutcome.variable ~ predictor\n```\n\nIn the second half of this chapter, we will continue to try to predict (i.e., try to better understand) `Vocab` scores among L1 and L2 English speakers, but this time, we will do so with *multiple* predictors. To this end, we will use the `+` operator to add predictors to our model formula like this:\n\n```         \noutcome.variable ~ predictor1 + predictor2 + predictor3\n```\n\nA linear regression model can include as many predictors as we like -- or rather, as is meaningful and we have data for! The predictors can be a mixture of numeric and categorical predictors. Multiple linear regression modelling is much more powerful than conducting individual statistical tests (as in @sec-Inferential) or several simple linear regression models (as in @sec-SLR) because it enables us to quantify the strength of the association between an outcome variable and a predictor, while **controlling for the other predictors** -- in other words, while holding all the other predictors constant. Moreover, it also reduces the risk of reporting false positive results (i.e. Type 1 error, see @sec-pHacking). In this chapter, we will see that we can learn much more about our data from a single multiple linear regression model than from a series of individual statistical tests or simple regression models.\n\n::: {.callout-warning collapse=\"false\"}\n### Prerequisites\n\nAs with previous chapters, all the examples, tasks, and quiz questions from this chapter are based on data from:\n\n> Dąbrowska, Ewa. 2019. Experience, Aptitude, and Individual Differences in Linguistic Attainment: A Comparison of Native and Nonnative Speakers. Language Learning 69(S1). 72–100. <https://doi.org/10.1111/lang.12323>.\n\nOur starting point for this chapter is the wrangled combined dataset that we created and saved in @sec-DataWrangling. Follow the instructions in @sec-filter to create this `R` object.\n\nAlternatively, you can download `Dabrowska2019.zip` from [the textbook's GitHub repository](https://github.com/elenlefoll/RstatsTextbook/blob/main/Dabrowska2019.zip){.uri}. To launch the project correctly, unzip the file and then double-click on the `Dabrowska2019.Rproj` file.\n\nTo begin, load the `combined_L1_L2_data.rds` file that we created in @sec-DataWrangling. This file contains the full data of all the L1 and L2 participants from @DabrowskaExperienceAptitudeIndividual2019. The categorical variables are stored as factors, and obvious data entry inconsistencies and typos have been corrected.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(here)\n\nDabrowska.data <- readRDS(file = here(\"data\", \"processed\", \"combined_L1_L2_data.rds\"))\n```\n:::\n\n\nBefore you get started, check that you have correctly imported the data by examining the output of `View(Dabrowska.data)` and `str(Dabrowska.data)`. In addition, run the following lines of code to load the {tidyverse} and create \"clean\" versions of both the L1 and L2 datasets as separate `R` objects.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(tidyverse)\n\nL1.data <- Dabrowska.data |> \n  filter(Group == \"L1\")\n\nL2.data <- Dabrowska.data |> \n  filter(Group == \"L2\")\n```\n:::\n\n\nOnce you are satisfied that the data have been correctly imported and that you are familiar with the dataset, you are ready to tap into the potential of multiple linear regression modelling! 🚀\n:::\n\n## Combining multiple predictors {#sec-MultipleLM}\n\nIn the following, we will attempt to model the variability in the receptive English vocabulary test scores of L1 and L2 English participants from @DabrowskaExperienceAptitudeIndividual2019. To this end, we will use multiple numeric and categorical predictors:\n\na.  participants' native-speaker status (`Group`)\nb.  their `Age`,\nc.  their occupational group (`OccupGroup`),\nd.  their `Gender`\ne.  their non-verbal IQ test score (`Blocks`), and\nf.  the number of years they were in formal education (`EduTotal`).\n\nWe use the `+` operator to construct the model formula. It doesn't matter in which order we list the predictors, as the model will consider them all simultaneously.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmodel4 <- lm(Vocab ~ Group + Age + OccupGroup + Gender + Blocks + EduTotal, \n             data = Dabrowska.data)\n```\n:::\n\n\nWe can then examine the model summary just like we did in @sec-SLR using the `summary()` function:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsummary(model4)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nCall:\nlm(formula = Vocab ~ Group + Age + OccupGroup + Gender + Blocks + \n    EduTotal, data = Dabrowska.data)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-62.825 -10.838   1.831  12.185  38.345 \n\nCoefficients:\n             Estimate Std. Error t value Pr(>|t|)    \n(Intercept)    4.2113    10.7831   0.391 0.696691    \nGroupL2      -22.2896     3.4854  -6.395 1.98e-09 ***\nAge            0.3718     0.1401   2.654 0.008812 ** \nOccupGroupI    9.9519     5.5999   1.777 0.077600 .  \nOccupGroupM   -3.9993     4.5139  -0.886 0.377050    \nOccupGroupPS  -1.0629     4.3876  -0.242 0.808919    \nGenderM       -3.7177     3.1387  -1.184 0.238131    \nBlocks         1.3011     0.3218   4.043 8.44e-05 ***\nEduTotal       2.4308     0.6293   3.863 0.000167 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 18.65 on 148 degrees of freedom\nMultiple R-squared:  0.3621,\tAdjusted R-squared:  0.3276 \nF-statistic:  10.5 on 8 and 148 DF,  p-value: 1.327e-11\n```\n\n\n:::\n:::\n\n\nAs with the simple linear regression models, we begin our interpretation of the model summary with the coefficient estimate for the **intercept** (see @sec-Ttestsregression). The first question we ask ourselves is:\n\n-   In this model, what does the intercept correspond to?\n\nRemember that the reference levels of **categorical predictors** correspond to the **first level** of these variables. This is why, here, the coefficient estimate for the intercept corresponds to a female English native speaker with a clerical occupation:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlevels(Dabrowska.data$Gender) # 'Female' is the first level.\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] \"F\" \"M\"\n```\n\n\n:::\n\n```{.r .cell-code}\nlevels(Dabrowska.data$Group) # 'L1' is the first level.\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] \"L1\" \"L2\"\n```\n\n\n:::\n\n```{.r .cell-code}\nlevels(Dabrowska.data$OccupGroup) # 'C' corresponding to a clerical professional occupation is the first level.\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] \"C\"  \"I\"  \"M\"  \"PS\"\n```\n\n\n:::\n:::\n\n\nThe reference level of the **numeric predictors**, by contrast, corresponds to the value of **zero**. In `model4`, therefore, the estimated coefficient for the intercept corresponds to the predicted `Vocab` score of an adult English native speaker who belongs to the occupational group \"C\", is female, who is aged 0 (!), scored 0 on the Blocks test, and spent 0 years (!) in formal education. Needless to say that trying to interpret this value is utterly meaningless! This is why, in this case, it makes sense to **center** our numeric predictor variables before entering them into our model. Another way to go about this would be to standardise the predictors using a *z*-transformation [see e.g. @WinterStatisticsLinguistsIntroduction2019: Section 5.2].\n\n## Centering numeric predictors\n\nCentering involves subtracting a variable's average from each value in the variable. Typically, we subtract the mean from each value but, given that we know that many of the numeric variables in our dataset are not normally distributed (see @sec-DistributionsNumeric), here, we will subtract the median instead.\n\nTo this end, we use the `mutate()` function to add three columns to the `R` data object `Dabrowska.data`. These new columns contain **transformed** versions of the predictor variables that we previously entered into our model:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nDabrowska.data <- Dabrowska.data |> \n  mutate(Age_c = Age - median(Age),\n         Blocks_c = Blocks - median(Blocks),\n         EduTotal_c = EduTotal - median(EduTotal))\n```\n:::\n\n\nWe have centred the values of the three numeric predictor variables so that a value of zero in the transformed version corresponds to the variable's original median value (see @tbl-Untransformed).\n\n\n::: {#tbl-Untransformed .cell tbl-cap='Comparison of the original, untransformed variables with the new, centered ones in a random sample of observations from the data'}\n::: {.cell-output-display}\n`````{=html}\n<table>\n <thead>\n  <tr>\n   <th style=\"text-align:center;\"> Age </th>\n   <th style=\"text-align:center;\"> Age_c </th>\n   <th style=\"text-align:center;\"> Blocks </th>\n   <th style=\"text-align:center;\"> Blocks_c </th>\n   <th style=\"text-align:center;\"> EduTotal </th>\n   <th style=\"text-align:center;\"> EduTotal_c </th>\n  </tr>\n </thead>\n<tbody>\n  <tr>\n   <td style=\"text-align:center;background-color: rgba(248, 248, 248, 255) !important;width: 16%; \"> 21 </td>\n   <td style=\"text-align:center;background-color: rgba(248, 248, 248, 255) !important;width: 16%; \"> -10 </td>\n   <td style=\"text-align:center;width: 16%; \"> <span style=\" font-weight: bold;    border-radius: 4px; padding-right: 4px; padding-left: 4px; background-color: pink !important;\">16</span> </td>\n   <td style=\"text-align:center;width: 16%; \"> <span style=\" font-weight: bold;    border-radius: 4px; padding-right: 4px; padding-left: 4px; background-color: pink !important;\">0</span> </td>\n   <td style=\"text-align:center;background-color: rgba(248, 248, 248, 255) !important;width: 16%; \"> 17 </td>\n   <td style=\"text-align:center;background-color: rgba(248, 248, 248, 255) !important;width: 16%; \"> 3 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:center;background-color: rgba(248, 248, 248, 255) !important;width: 16%; \"> 27 </td>\n   <td style=\"text-align:center;background-color: rgba(248, 248, 248, 255) !important;width: 16%; \"> -4 </td>\n   <td style=\"text-align:center;width: 16%; \"> 21 </td>\n   <td style=\"text-align:center;width: 16%; \"> 5 </td>\n   <td style=\"text-align:center;background-color: rgba(248, 248, 248, 255) !important;width: 16%; \"> 18 </td>\n   <td style=\"text-align:center;background-color: rgba(248, 248, 248, 255) !important;width: 16%; \"> 4 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:center;background-color: rgba(248, 248, 248, 255) !important;width: 16%; \"> 25 </td>\n   <td style=\"text-align:center;background-color: rgba(248, 248, 248, 255) !important;width: 16%; \"> -6 </td>\n   <td style=\"text-align:center;width: 16%; \"> 21 </td>\n   <td style=\"text-align:center;width: 16%; \"> 5 </td>\n   <td style=\"text-align:center;background-color: rgba(248, 248, 248, 255) !important;width: 16%; \"> 18 </td>\n   <td style=\"text-align:center;background-color: rgba(248, 248, 248, 255) !important;width: 16%; \"> 4 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:center;background-color: rgba(248, 248, 248, 255) !important;width: 16%; \"> <span style=\" font-weight: bold;    border-radius: 4px; padding-right: 4px; padding-left: 4px; background-color: pink !important;\">31</span> </td>\n   <td style=\"text-align:center;background-color: rgba(248, 248, 248, 255) !important;width: 16%; \"> <span style=\" font-weight: bold;    border-radius: 4px; padding-right: 4px; padding-left: 4px; background-color: pink !important;\">0</span> </td>\n   <td style=\"text-align:center;width: 16%; \"> 8 </td>\n   <td style=\"text-align:center;width: 16%; \"> -8 </td>\n   <td style=\"text-align:center;background-color: rgba(248, 248, 248, 255) !important;width: 16%; \"> 13 </td>\n   <td style=\"text-align:center;background-color: rgba(248, 248, 248, 255) !important;width: 16%; \"> -1 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:center;background-color: rgba(248, 248, 248, 255) !important;width: 16%; \"> 37 </td>\n   <td style=\"text-align:center;background-color: rgba(248, 248, 248, 255) !important;width: 16%; \"> 6 </td>\n   <td style=\"text-align:center;width: 16%; \"> 9 </td>\n   <td style=\"text-align:center;width: 16%; \"> -7 </td>\n   <td style=\"text-align:center;background-color: rgba(248, 248, 248, 255) !important;width: 16%; \"> 12 </td>\n   <td style=\"text-align:center;background-color: rgba(248, 248, 248, 255) !important;width: 16%; \"> -2 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:center;background-color: rgba(248, 248, 248, 255) !important;width: 16%; \"> 60 </td>\n   <td style=\"text-align:center;background-color: rgba(248, 248, 248, 255) !important;width: 16%; \"> 29 </td>\n   <td style=\"text-align:center;width: 16%; \"> 1 </td>\n   <td style=\"text-align:center;width: 16%; \"> -15 </td>\n   <td style=\"text-align:center;background-color: rgba(248, 248, 248, 255) !important;width: 16%; \"> 10 </td>\n   <td style=\"text-align:center;background-color: rgba(248, 248, 248, 255) !important;width: 16%; \"> -4 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:center;background-color: rgba(248, 248, 248, 255) !important;width: 16%; \"> 20 </td>\n   <td style=\"text-align:center;background-color: rgba(248, 248, 248, 255) !important;width: 16%; \"> -11 </td>\n   <td style=\"text-align:center;width: 16%; \"> 17 </td>\n   <td style=\"text-align:center;width: 16%; \"> 1 </td>\n   <td style=\"text-align:center;background-color: rgba(248, 248, 248, 255) !important;width: 16%; \"> 12 </td>\n   <td style=\"text-align:center;background-color: rgba(248, 248, 248, 255) !important;width: 16%; \"> -2 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:center;background-color: rgba(248, 248, 248, 255) !important;width: 16%; \"> 25 </td>\n   <td style=\"text-align:center;background-color: rgba(248, 248, 248, 255) !important;width: 16%; \"> -6 </td>\n   <td style=\"text-align:center;width: 16%; \"> 20 </td>\n   <td style=\"text-align:center;width: 16%; \"> 4 </td>\n   <td style=\"text-align:center;background-color: rgba(248, 248, 248, 255) !important;width: 16%; \"> 12 </td>\n   <td style=\"text-align:center;background-color: rgba(248, 248, 248, 255) !important;width: 16%; \"> -2 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:center;background-color: rgba(248, 248, 248, 255) !important;width: 16%; \"> 62 </td>\n   <td style=\"text-align:center;background-color: rgba(248, 248, 248, 255) !important;width: 16%; \"> 31 </td>\n   <td style=\"text-align:center;width: 16%; \"> 8 </td>\n   <td style=\"text-align:center;width: 16%; \"> -8 </td>\n   <td style=\"text-align:center;background-color: rgba(248, 248, 248, 255) !important;width: 16%; \"> <span style=\" font-weight: bold;    border-radius: 4px; padding-right: 4px; padding-left: 4px; background-color: pink !important;\">14</span> </td>\n   <td style=\"text-align:center;background-color: rgba(248, 248, 248, 255) !important;width: 16%; \"> <span style=\" font-weight: bold;    border-radius: 4px; padding-right: 4px; padding-left: 4px; background-color: pink !important;\">0</span> </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:center;background-color: rgba(248, 248, 248, 255) !important;width: 16%; \"> 42 </td>\n   <td style=\"text-align:center;background-color: rgba(248, 248, 248, 255) !important;width: 16%; \"> 11 </td>\n   <td style=\"text-align:center;width: 16%; \"> 21 </td>\n   <td style=\"text-align:center;width: 16%; \"> 5 </td>\n   <td style=\"text-align:center;background-color: rgba(248, 248, 248, 255) !important;width: 16%; \"> 15 </td>\n   <td style=\"text-align:center;background-color: rgba(248, 248, 248, 255) !important;width: 16%; \"> 1 </td>\n  </tr>\n</tbody>\n</table>\n\n`````\n:::\n:::\n\n\nFor each pair of variables, the value of 0 in the centered variable corresponds to the median value of the untransformed variable. As a result, in the centered variables, each data point is expressed in terms of how much it is either above the median (positive score) or below the median (negative score).\n\n## Interpreting a model summary\n\nWe can now fit a new multiple linear regression model that attempts to predict `Vocab` scores with the same predictors as `model4` above, except that we are now entering the centered numeric predictor variables instead of the original untransformed ones. The categorical predictor variables remain the same.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmodel4_c <- lm(Vocab ~ Group + Age_c + OccupGroup + Gender + Blocks_c + EduTotal_c, \n             data = Dabrowska.data)\n\nsummary(model4_c)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nCall:\nlm(formula = Vocab ~ Group + Age_c + OccupGroup + Gender + Blocks_c + \n    EduTotal_c, data = Dabrowska.data)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-62.825 -10.838   1.831  12.185  38.345 \n\nCoefficients:\n             Estimate Std. Error t value Pr(>|t|)    \n(Intercept)   70.5852     3.7045  19.054  < 2e-16 ***\nGroupL2      -22.2896     3.4854  -6.395 1.98e-09 ***\nAge_c          0.3718     0.1401   2.654 0.008812 ** \nOccupGroupI    9.9519     5.5999   1.777 0.077600 .  \nOccupGroupM   -3.9993     4.5139  -0.886 0.377050    \nOccupGroupPS  -1.0629     4.3876  -0.242 0.808919    \nGenderM       -3.7177     3.1387  -1.184 0.238131    \nBlocks_c       1.3011     0.3218   4.043 8.44e-05 ***\nEduTotal_c     2.4308     0.6293   3.863 0.000167 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 18.65 on 148 degrees of freedom\nMultiple R-squared:  0.3621,\tAdjusted R-squared:  0.3276 \nF-statistic:  10.5 on 8 and 148 DF,  p-value: 1.327e-11\n```\n\n\n:::\n:::\n\n\nIf you compare the summary of `model4` with that of `model4_c`, you will notice that, whilst the intercept coefficient estimate has changed, all the other coefficient estimates have stayed the same.\n\nLet's decipher the summary of `model4_c` step-by-step:\n\n-   In this model, the estimated coefficient for the **intercept** corresponds to the predicted `Vocab` score of an English native speaker (`Group` = L1) who is aged 31 (the median `Age`), belongs to the occupational group `C`, is female, scored 16 on the Blocks test (the median `Blocks` score), and was in formal education for 14 years (the median number of years).\n\n-   As with the simple linear regression models that we computed in @sec-SLR, the **coefficient estimates of the numeric predictors** (`Age_c`, `Blocks_c`, and `EduTotal_c`) correspond to increases or decreases in `Vocab` scores for each additional unit of that predictor variable, whilst keeping all other predictors at their reference level. Remember that, for numeric predictors, the reference level is 0, which, given that we have centered them, corresponds to the variable's median value. Looking at the coefficient estimate for `Blocks_c` (`1.3011`), this means that someone who scored one point more than the median score in the Blocks test is predicted to have a `Vocab` test result that is `1.3011` points higher than the intercept, namely:\n\n\n    ::: {.cell}\n    \n    ```{.r .cell-code}\n    70.5852 + 1.3011\n    ```\n    \n    ::: {.cell-output .cell-output-stdout}\n    \n    ```\n    [1] 71.8863\n    ```\n    \n    \n    :::\n    :::\n\n\n-   To calculate the predicted `Vocab` score of an L1 female speaker in a clerical occupation, of median age, who spent the median number of years in formal education, but scored an impressive 26 points on the Blocks test, we multiply the estimated `Blocks_c` coefficient (`1.3011`) by 26 minus the median Blocks score (16) and add this to the intercept coefficient:\n\n\n    ::: {.cell}\n    \n    ```{.r .cell-code}\n    70.5852 + 1.3011*(26 - median(Dabrowska.data$Blocks))\n    ```\n    \n    ::: {.cell-output .cell-output-stdout}\n    \n    ```\n    [1] 83.5962\n    ```\n    \n    \n    :::\n    :::\n\n\n-   You'll be pleased to read that the interpretation of **coefficient estimates of categorical predictors** is less involved. Recall that, for categorical variables, the reference level is always the variable's first level (see @sec-MultipleLM). If we want to make a prediction for an L2 instead of an L1 female speaker, but keep all other predictors at the reference level (i.e. clerical occupation, median age, median number of years in formal education, and median Blocks score), all we need to do is add the coefficient estimate for `GroupL2` (`-22.2896`) to the intercept coefficient. Given that this coefficient is negative, this addition will result in a predicted `Vocab` score that is lower than the model's reference level:\n\n\n    ::: {.cell}\n    \n    ```{.r .cell-code}\n    70.5852 + -22.2896\n    ```\n    \n    ::: {.cell-output .cell-output-stdout}\n    \n    ```\n    [1] 48.2956\n    ```\n    \n    \n    :::\n    :::\n\n\n-   Since very few people are perfectly average, let us now calculate the predicted `Vocab` score of an actual person: the 154^th^ participant in our dataset. As shown below using the {tidyverse} function `slice()`, the 154^th^ participant is a 46-year-old Polish male driver who scored 23 points on the Blocks test and attended formal education for 10 years.\n\n\n    ::: {.cell}\n    \n    ```{.r .cell-code}\n    Dabrowska.data |> \n      slice(154) |> \n      select(Group, Age, NativeLg, Occupation, OccupGroup, Gender, Blocks, EduTotal)\n    ```\n    \n    ::: {.cell-output .cell-output-stdout}\n    \n    ```\n      Group Age NativeLg Occupation OccupGroup Gender Blocks EduTotal\n    1    L2  46   Polish     Driver          M      M     23       10\n    ```\n    \n    \n    :::\n    :::\n\n\n    To obtain the model's predicted `Vocab` score for a 46-year-old male L2 speaker with a manual occupation (`M`) who scored 23 points on the `Blocks` test and was in formal education for 10 years (`EduTotal`), we combine the coefficient estimates as follows:\n\n\n    ::: {.cell}\n    \n    ```{.r .cell-code}\n    70.5852 +                                       # <1>     \n    -22.2896 +                                      # <2>\n    0.3718 * (46 - median(Dabrowska.data$Age)) +    # <3>\n    -3.9993 +                                       # <4>\n    -3.7177 +                                       # <5>\n    1.3011 * (23 - median(Dabrowska.data$Blocks)) + # <6>\n    2.4308 * (10 - median(Dabrowska.data$EduTotal)) # <7>\n    ```\n    \n    ::: {.cell-output .cell-output-stdout}\n    \n    ```\n    [1] 45.5401\n    ```\n    \n    \n    :::\n    :::\n\n\n    1.  Intercept coefficient\n    2.  L2 speaker\n    3.  46 years old\n    4.  Manual occupation (OccupGroupM)\n    5.  Male\n    6.  23 points on Blocks test\n    7.  10 years in formal education\n\n    ::: {.callout-tip .content-visible when-format=\"html\"}\n    You can hover your mouse over the circled numbers to find out how this predicted score was calculated. All the coefficient estimates were copied from the model summary output by `summary(model4_c)`.\n    :::\n\n-   We can check that we did the maths correctly by outputting the model's prediction for the 154^th^ observation directly. To this end, we apply the `predict()` function to the model object `model4_c` and extract the model's predicted score for the 154^th^ data point:\n\n\n    ::: {.cell}\n    \n    ```{.r .cell-code}\n    predict(model4_c)[154]\n    ```\n    \n    ::: {.cell-output .cell-output-stdout}\n    \n    ```\n         154 \n    45.53989 \n    ```\n    \n    \n    :::\n    :::\n\n\n    As you can see, we obtain the same predicted `Vocab` score. The minor difference after the decimal point is due to us using coefficient estimates rounded-off to four decimal places (as displayed in the model's summary output) rather than the exact values to which the `predict()` function has access.\n\n-   This is all very well, but how accurate is this model prediction? To find out, we can compare this *predicted* score (that our model predicts for any male 46-year old with a manual occupation, a Blocks score of 23, and 10 years in formal education) to the 46-year-old Polish driver's *actual* `Vocab` score:\n\n\n    ::: {.cell}\n    \n    ```{.r .cell-code}\n    Dabrowska.data |> \n      slice(154) |> \n      select(Group, Age, NativeLg, Occupation, OccupGroup, Gender, Blocks, EduTotal, Vocab)\n    ```\n    \n    ::: {.cell-output .cell-output-stdout}\n    \n    ```\n      Group Age NativeLg Occupation OccupGroup Gender Blocks EduTotal    Vocab\n    1    L2  46   Polish     Driver          M      M     23       10 48.88889\n    ```\n    \n    \n    :::\n    :::\n\n\n-   Our model prediction (`45.53989`) is close to our Polish driver's real `Vocab` test score (`48.88889`), but our model has slightly underestimated his performance. This underestimation results in a positive **residual**. The residual is positive because there are points \"left over\" by the model. Model residuals are calculated by subtracting a model's prediction from the real, observed value of the outcome variable for any specific data point. In our case, we substract our model's predicted `Vocab` score for a male 46-year old with a manual occupation, a Blocks score of 23, and 10 years in formal education from the Polish 46-year-old driver's actual `Vocab` score:\n\n\n    ::: {.cell}\n    \n    ```{.r .cell-code}\n    48.88889 - 45.53989\n    ```\n    \n    ::: {.cell-output .cell-output-stdout}\n    \n    ```\n    [1] 3.349\n    ```\n    \n    \n    :::\n    :::\n\n\n    Residuals are also stored in the model object and be accesssed like this:\n\n\n    ::: {.cell}\n    \n    ```{.r .cell-code}\n    model4_c$residuals[154]\n    ```\n    \n    ::: {.cell-output .cell-output-stdout}\n    \n    ```\n         154 \n    3.348998 \n    ```\n    \n    \n    :::\n    :::\n\n\n-   We can compare this particular residual (corresponding to the 154^th^ participant in the dataset) to all model residuals (corresponding to all participants) by examining the **summary statistics of all residuals**, which are displayed at the top of the model summary output (`summary(model4_c)`). These descriptive statistics inform us that the residual for the 154^th^ participant is slightly higher than the average (median) residual, but well within the IQR (see @sec-IQR) of model residuals:\n\n    ```         \n    Residuals:\n        Min      1Q  Median      3Q     Max \n    -62.825 -10.838   1.831  12.185  38.345 \n    ```\n\n    Looking at the minimum and maximum residuals, we can see that our model overestimates at least one person's `Vocab` score by 63 points (this is the most negative residual: `Min`), whilst in another case it underestimates it by 38 points (this is the largest positive residual: `Max`).\n\n\n    ::: {.cell}\n    \n    ```{.r .cell-code  code-fold=\"true\" code-summary=\"Click here to find out whose score was most underestimated!\"}\n    # Run the following code to find out more about the participant whose Vocab score was most dramatically underestimated by our model:\n    \n    Dabrowska.data |> \n      slice(which.max(model4_c$residuals)) |> \n      select(Group, NativeLg, Age, Occupation, Gender, Blocks, EduTotal, Vocab)\n    ```\n    :::\n\n\n-   The ***p*****-values** associated with each coefficient estimate in the model summary indicate which predictor variables (or predictor variable *levels*, in the case of categorical variables) make a statistically significant contribution to the model. You may recall that, in @sec-Categoricalpredictor, we fitted a simple linear regression model (`model3`) which included only `OccupGroup` as a single predictor. In this simple model, the coefficient estimate for `OccupGroupI` made a statistically significant contribution to the model at an α-level of 0.05 (*p* = 0.0335). By contrast, in the present multiple linear regression model, the predictor level `OccupGroupI` does *not* make a statistically significant contribution (*p* = 0.077600 which is greater than 0.05). This is because our multiple regression model `model4_c` includes predictors that account for some of the same variance in `Vocab` scores in the data that occupational groups accounted for in our earlier model. This leaves less unique variance attributable to occupational group, thereby rendering it statistically non-significant.\n\n-   From the **adjusted R-squared** value (`0.3276`) displayed at the bottom of the model summary output, we can see that our multiple linear regression model accounts for around 33% of the total variance in `Vocab` scores found in the @DabrowskaExperienceAptitudeIndividual2019 data. This is considerably more than we achieved with any of the simple linear models that we fitted in @sec-SLR.\n\n### Interpreting model predictions {#sec-ModelPredictions}\n\nWhilst it is important to understand how to interpret the coefficients of a multiple linear regression model from the model summary, in practice, it is also always a very good idea to visualise model predictions. On the one hand, this reduces the risk of making any obvious interpretation errors and, on the other, it is much easier to interpret the residuals of a model when they are visualised alongside model predictions.\n\nTo fully visualise the predictions of a multiple linear model, we would need to be able to plot as many dimensions as there are predictors in the model. The trouble is that, as humans, we find it difficult to interpret data visualisations with more than two dimensions. Indeed, although 3D plots can sometimes be useful (and can easily be generated in `R`), we are much better at interpreting two-dimensional plots. To bypass this inherent human weakness, we will plot the values predicted by our model on several plots: one for each predictor variable (see @fig-VisregVocab). Run the following command and then follow the instructions displayed in the Console pane to view the plots one by one. You may need to resize your Plot pane for the plots to be displayed. If you have a small screen, you may find the \"🔎 Zoom\" option in RStudio's Plots pane useful as it allows you to view the plots in a separate window.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(visreg)\n\nvisreg(model4_c)\n```\n:::\n\n\n\n::: {.cell}\n::: {.cell-output-display}\n![`Vocab` scores as predicted by `model4_c` (blue lines) as a function of various predictor variables and partial model residuals (grey points)](13_MultipleLinearRegression_files/figure-html/fig-VisregVocab-1.png){#fig-VisregVocab fig-alt='Six-panel scatter plot showing vocabulary scores predicted by various factors, with partial residual points and blue regression lines in each panel. Categorical predictors show relatively flat trends and continuous predictors show positive linear relationships.' width=768}\n:::\n:::\n\n\nOn plots produced by the `visreg()` function, as in @fig-PredictedVocabByOccupation, the model's predicted values are displayed as blue lines. By default, these predictions are surrounded by 95% confidence bands, which are visualised as grey areas. Now that we have several predictors in our model, the points in `visreg()` plots represent the model's **partial residuals**. Partial residuals are the left-over variance (i.e., the residual) relative to the predictor that we are examining after having subtracted off the contribution of all the other predictors in the model.\n\nWhen interpreting the numeric predictors plotted in @fig-VisregVocab above, it is important to remember that we entered centered numeric predictors in `model4_c`. This means that an `Age_c` value of 0 corresponds to the median age in the dataset: 31 years. This is why @fig-VisregVocab features negative ages: the negative values correspond to participants who are younger than 31. By contrast, positive scores correspond to participants who are older than 31 years. This is hardly intuitive so, for the purposes of visualising and interpreting our model, it is best to transform these variables back to their original scale (see @fig-PredictedVocabAge). This is achieved by adding the following `xtrans` argument within the `visreg()` function.\n\n::: callout-warning\nDue to a bug that was introduced in the latest version of the {visreg} package, it is currently necessary to install version 2.7 of the {visreg} package for the `xtrans` argument to work as expected. You can find out which package version you currently have installed, if any, using this function:\n\n\n::: {.cell}\n\n```{.r .cell-code}\npackageVersion(\"visreg\")\n```\n:::\n\n\nIf you have version 2.8.0, begin by deleting your current installation:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nremove.packages(\"visreg\")\n```\n:::\n\n\nThen, install the {remotes} package, which allows you to install older versions of packages (if they are compatible with your `R` version). You will likely get a message notifying you that it is necessary to restart your `R` session. Click \"yes\".\n\n\n::: {.cell}\n\n```{.r .cell-code}\ninstall.packages(\"remotes\")\nlibrary(remotes)\n```\n:::\n\n\nFinally, load the {remotes} library and then install version 2.7.0 of the {visreg} package:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(remotes)\ninstall_version(\"visreg\", \"2.7.0\")\n```\n:::\n\n:::\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(visreg)\n\nvisreg(model4_c, \n       xvar = \"Age_c\", \n       xtrans = function(x) x + median(Dabrowska.data$Age), \n       gg = TRUE) + \n  labs(x = \"Age (in years)\",\n       y = \"Predicted Vocab scores\") +\n  theme_bw()\n```\n:::\n\n\n\n::: {.cell}\n::: {.cell-output-display}\n![`Vocab` scores as predicted by `model4_c` for speakers of various ages (blue line) and partial model residuals represented as points. In the version printed in the textbook, two data points are highlighted: one representing a very large positive residual and one representing a very small residual.](13_MultipleLinearRegression_files/figure-html/fig-PredictedVocabAge-1.png){#fig-PredictedVocabAge fig-alt='Scatter plot showing predicted vocabulary scores versus age in years, with partial residual points and a blue regression line with gray confidence band showing a slight positive trend. Two data points are highlighted: a pink point labeled Lithuanian bar staff showing a large positive residual around age 25, and a purple point labeled Polish driver showing a small residual around age 50.' width=576}\n:::\n:::\n\n\nIn @fig-PredictedVocabAge, we focus on one predictor from our model: `Age`. We know from our model summary that the coefficient estimate for age is positive (`0.3718`), hence the upward blue line. The grey 95% confidence band visualises the uncertainty around the estimated mean predicted `Vocab` scores.\n\nThe points on @fig-PredictedVocabAge represent the partial residuals. This means that there are as many points as there are participants in the dataset used to fit the model. The further away a point is from the predicted value (the blue line), the poorer the prediction is for that particular participant.\n\nSome of the partial residuals are particularly large: the `Vocab` score of the 23-year-old Lithuanian bar staff, for instance, is vastly underestimated. By contrast, the 46-year-old Polish driver's predicted score is well within the confidence band of the predicted `Vocab` score for his age, indicating that our model makes a pretty accurate prediction for this L2 speaker.\n\n\n::: {.cell}\n\n:::\n\n\n::: {.callout-tip collapse=\"false\"}\n#### Your turn! {.unnumbered}\n\nThe dataset from @DabrowskaExperienceAptitudeIndividual2019 includes a variable that we have not explored yet: `ART`. It stands for Author Recognition Test [@acheson2008] and is a measure of print exposure to (almost exclusively Western, English-language) literature. Dąbrowska [-@DabrowskaExperienceAptitudeIndividual2019: 9] explains the testing instrument and her motivation for including it in her battery of tests as follows:\n\n> The test consists of a list of 130 names, half of which are names of real authors. The participants’ task is to mark the names that they know to be those of published authors. To penalize guessing, the score is computed by subtracting the number of foils \\[wrong guesses\\] from the number of real authors selected. Thus, the maximum possible score is 65, and the minimum score could be negative if a participant selects more foils than real authors. When this happened, the negative number was replaced with 0.\n>\n> The ART has been shown to be a valid and reliable measure of print exposure, which, unlike questionnaire-based measures, is not contaminated by socially desirable responses and assesses lifetime reading experience as opposed to current reading (see Acheson et al., 2008; Stanovich & Cunningham, 1992).\n\n[**Q13.1**]{style=\"color:green;\"} For this task, you will fit a new multiple linear regression model that predicts `Vocab` scores among L1 and L2 speakers using all of the predictors that we used in `model4_c` plus `ART` scores. Which formula do you need to specify inside the `lm()`function to fit this model?\n\n\n::: {.cell}\n::: {.cell-output-display}\n\n```{=html}\n<form name=\"form_Q13_1\" onsubmit=\"return validate_form_Q13_1()\" method=\"post\">\n<label>\n<input type=\"radio\" name=\"answer_Q13_1\" id=\"answer_Q13_1_1\" value=\"Vocab ~ Group + Age_c + OccupGroup + Gender + Blocks_c + EduTotal_c + ART\"/>\nVocab ~ Group + Age_c + OccupGroup + Gender + Blocks_c + EduTotal_c + ART\n</label>\n<br/>\n<label>\n<input type=\"radio\" name=\"answer_Q13_1\" id=\"answer_Q13_1_2\" value=\"Vocab ~ Group + Age_c + OccupGroup + Gender + Blocks_c + EduTotal_c * ART\"/>\nVocab ~ Group + Age_c + OccupGroup + Gender + Blocks_c + EduTotal_c * ART\n</label>\n<br/>\n<label>\n<input type=\"radio\" name=\"answer_Q13_1\" id=\"answer_Q13_1_3\" value=\"ART ~ Group + Age_c + OccupGroup + Gender + Blocks_c + EduTotal_c\"/>\nART ~ Group + Age_c + OccupGroup + Gender + Blocks_c + EduTotal_c\n</label>\n<br/>\n<label>\n<input type=\"radio\" name=\"answer_Q13_1\" id=\"answer_Q13_1_4\" value=\"Vocab ~ model4_c + ART\"/>\nVocab ~ model4_c + ART\n</label>\n<br/>\n<input type=\"submit\" value=\"Check answer\"/>\n<div id=\"result_Q13_1\"></div>\n</form>\n<script>function validate_form_Q13_1() {var x, text; var x = document.forms['form_Q13_1']['answer_Q13_1'].value;if (x == 'Vocab ~ Group + Age_c + OccupGroup + Gender + Blocks_c + EduTotal_c + ART'){text = 'That’s right, well done!';} else {text = 'No, try it out for yourself and see which formula generates the right model.';} document.getElementById('result_Q13_1').innerHTML = text; evaluate_final_score(); return false;}function evaluate_final_score(){\n         element = document.getElementById('checkdown_final_score');\n         if(element === null){return false;} else {var element, text, res1;res1 = document.getElementById('result_Q13_1').innerText == 'That’s right, well done!';text = res1;element.innerHTML = text;\n         return false;\n         }}</script>\n```\n\n:::\n:::\n\n\n[**Q13.2**]{style=\"color:green;\"} Fit a model using the correct formula from above. Examine the summary of your new model. Which of these statements is/are true?\n\n\n::: {.cell}\n::: {.cell-output-display}\n\n```{=html}\n<form name=\"form_Q13_2\" onsubmit=\"return validate_form_Q13_2()\" method=\"post\">\n<label>\n<input type=\"checkbox\" id=\"answer_Q13_2_1\" value=\"The model that does not include ART (model4_c) accounts for more of the variance in Vocab scores than the model that does.\"/>\nThe model that does not include ART (model4_c) accounts for more of the variance in Vocab scores than the model that does.\n</label>\n<br/>\n<label>\n<input type=\"checkbox\" id=\"answer_Q13_2_2\" value=\"Recognising more real authors on the ART is associated with higher Vocab scores.\"/>\nRecognising more real authors on the ART is associated with higher Vocab scores.\n</label>\n<br/>\n<label>\n<input type=\"checkbox\" id=\"answer_Q13_2_3\" value=\"The model that includes ART accounts for more of the variance in Vocab scores than the model that does not (model4_c).\"/>\nThe model that includes ART accounts for more of the variance in Vocab scores than the model that does not (model4_c).\n</label>\n<br/>\n<label>\n<input type=\"checkbox\" id=\"answer_Q13_2_4\" value=\"ART makes a statistically significant contribution to the model at the α-level of 0.05.\"/>\nART makes a statistically significant contribution to the model at the α-level of 0.05.\n</label>\n<br/>\n<label>\n<input type=\"checkbox\" id=\"answer_Q13_2_5\" value=\"Recognising more real authors on the ART is associated with lower Vocab scores.\"/>\nRecognising more real authors on the ART is associated with lower Vocab scores.\n</label>\n<br/>\n<label>\n<input type=\"checkbox\" id=\"answer_Q13_2_6\" value=\"ART does not make a statistically significant contribution to the model at the α-level of 0.05.\"/>\nART does not make a statistically significant contribution to the model at the α-level of 0.05.\n</label>\n<br/>\n<input type=\"submit\" value=\"Check answer\"/>\n<div id=\"result_Q13_2\"></div>\n</form>\n<script>function validate_form_Q13_2() {var text; var x1 = document.getElementById('answer_Q13_2_1'); var x2 = document.getElementById('answer_Q13_2_2'); var x3 = document.getElementById('answer_Q13_2_3'); var x4 = document.getElementById('answer_Q13_2_4'); var x5 = document.getElementById('answer_Q13_2_5'); var x6 = document.getElementById('answer_Q13_2_6'); if (x1.checked == false&x2.checked == true&x3.checked == true&x4.checked == true&x5.checked == false&x6.checked == false){text = 'Excellent!';} else {text = 'No, not quite. Check the code below if you need some help.';} document.getElementById('result_Q13_2').innerHTML = text; evaluate_final_score(); return false;}function evaluate_final_score(){\n         element = document.getElementById('checkdown_final_score');\n         if(element === null){return false;} else {var element, text, res1, res2;res1 = document.getElementById('result_Q13_1').innerText == 'That’s right, well done!'; res2 = document.getElementById('result_Q13_2').innerText == 'Excellent!';text = res1 + res2;element.innerHTML = text;\n         return false;\n         }}</script>\n```\n\n:::\n\n::: {.cell-output-display}\n\n```{=html}\n<div id=\"hint_82123\" onclick=\"return show_hint_82123()\">🐭 Click on the mouse for a hint.</div>\n<div id=\"result_82123\" onclick=\"return show_hint_82123()\"></div>\n<script>function show_hint_82123(){var x = document.getElementById('result_82123').innerHTML; if(!x){document.getElementById('result_82123').innerHTML = 'Three of these statements are correct.';} else {document.getElementById('result_82123').innerHTML = '';}}</script>\n```\n\n:::\n:::\n\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\" code-summary=\"Show sample code to answer Q13.2.\"}\n# First, it is always a good idea to visualise the data before fitting a model to have an idea of what to expect:\nDabrowska.data |> \n  ggplot(mapping = aes(y = Vocab,\n                       x = ART)) +\n  geom_point() +\n  geom_smooth(method = \"lm\") +\n  theme_bw()\n\n# We fit the new model with ART as an additional predictor using the formula from Q13.1:\nmodel.ART <- lm(Vocab ~ Group + Age_c + OccupGroup + Gender + Blocks_c + EduTotal_c + ART, \n             data = Dabrowska.data)\n\n# We examine the coefficients of this new model:\nsummary(model.ART)\n\n# To find out how much variance the model accounts for compared to our prior model, compare the adjusted R-squared values of the two models:\nsummary(model4_c)\nsummary(model.ART)\n```\n:::\n\n\nHave you noticed how, having added `ART` as a predictor to your model, `Age` no longer makes a statistically significant contribution to the model (*p* = 0.070994)? How come? Well, it turns out that `ART` and `Age` are correlated (*r* = 0.32, see @fig-AgeArtPlot). This moderate positive correlation makes intuitive sense: the older you are, the more likely you are to have come across more authors and therefore be able to correctly identify them in the Author Recognition Test. Of the two predictors, our model suggests that ART scores are a more useful predictor of `Vocab` scores than age. In other words, if we know the ART score of a participant from the @DabrowskaExperienceAptitudeIndividual2019 dataset, their age does not provide additional information that can help us to better predict their `Vocab` score.\n\n\n::: {.cell}\n::: {.cell-output-display}\n![Observed relationship between participants' age and their Author Recognition Test (ART) scores. The blue line shows that there is a moderate positive correlation between these two variables.](13_MultipleLinearRegression_files/figure-html/fig-AgeArtPlot-1.png){#fig-AgeArtPlot fig-alt='Scatter plot showing the relationship between age on the x-axis and Author Recognition Test (ART) scores on the y-axis, with data points scattered throughout. A blue regression line with gray confidence band shows a moderate positive correlation.' width=576}\n:::\n:::\n\n\n[**Q13.3**]{style=\"color:green;\"} What is the predicted `Vocab` score of a female L1 speaker aged 31 (the median age) with a manual occupation, who scored 16 on the Blocks test (the median score), spent 14 years in formal education (median time period), and scored 20 on the Author Recognition Test?\n\n\n::: {.cell}\n::: {.cell-output-display}\n\n```{=html}\n<form name=\"form_Q13_3\" onsubmit=\"return validate_form_Q13_3()\" method=\"post\">\n<label>\n<input type=\"radio\" name=\"answer_Q13_3\" id=\"answer_Q13_3_1\" value=\"71.1133\"/>\n71.1133\n</label>\n<br/>\n<label>\n<input type=\"radio\" name=\"answer_Q13_3\" id=\"answer_Q13_3_2\" value=\"8.5405\"/>\n8.5405\n</label>\n<br/>\n<label>\n<input type=\"radio\" name=\"answer_Q13_3\" id=\"answer_Q13_3_3\" value=\"74.1007\"/>\n74.1007\n</label>\n<br/>\n<label>\n<input type=\"radio\" name=\"answer_Q13_3\" id=\"answer_Q13_3_4\" value=\"73.6248\"/>\n73.6248\n</label>\n<br/>\n<label>\n<input type=\"radio\" name=\"answer_Q13_3\" id=\"answer_Q13_3_5\" value=\"74.3556\"/>\n74.3556\n</label>\n<br/>\n<label>\n<input type=\"radio\" name=\"answer_Q13_3\" id=\"answer_Q13_3_6\" value=\"123.3076\"/>\n123.3076\n</label>\n<br/>\n<input type=\"submit\" value=\"Check answer\"/>\n<div id=\"result_Q13_3\"></div>\n</form>\n<script>function validate_form_Q13_3() {var x, text; var x = document.forms['form_Q13_3']['answer_Q13_3'].value;if (x == '71.1133'){text = 'Absolutely, well done!';} else {text = 'No, that’s it. Check the hint below.';} document.getElementById('result_Q13_3').innerHTML = text; evaluate_final_score(); return false;}function evaluate_final_score(){\n         element = document.getElementById('checkdown_final_score');\n         if(element === null){return false;} else {var element, text, res1, res2, res3;res1 = document.getElementById('result_Q13_1').innerText == 'That’s right, well done!'; res2 = document.getElementById('result_Q13_2').innerText == 'Excellent!'; res3 = document.getElementById('result_Q13_3').innerText == 'Absolutely, well done!';text = res1 + res2 + res3;element.innerHTML = text;\n         return false;\n         }}</script>\n```\n\n:::\n\n::: {.cell-output-display}\n\n```{=html}\n<div id=\"hint_26351\" onclick=\"return show_hint_26351()\">🐭 Click on the mouse for a hint.</div>\n<div id=\"result_26351\" onclick=\"return show_hint_26351()\"></div>\n<script>function show_hint_26351(){var x = document.getElementById('result_26351').innerHTML; if(!x){document.getElementById('result_26351').innerHTML = 'The person described corresponds to the reference levels of all the predictors except for their occupational group and ART score.';} else {document.getElementById('result_26351').innerHTML = '';}}</script>\n```\n\n:::\n:::\n\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\" code-summary=\"Show sample code to answer Q13.3.\"}\n# We must add together the coefficient for the intercept, the coefficient for the manual occupation (which is negative), and the ART coefficient multiplied by 20 (as we did not center this predictor):\n62.5728 + -2.5115 + 0.5526*20\n```\n:::\n\n\n[**Q13.4**]{style=\"color:green;\"} By default, the `visreg()` function displays a 95% confidence band around predicted values, corresponding to a significance level of 0.05. How can you change this default to display a 99% confidence band instead? Run the command `?visreg()` to find out how to achieve this from the function's help file.\n\n\n::: {.cell}\n::: {.cell-output-display}\n\n```{=html}\n<form name=\"form_Q13_4\" onsubmit=\"return validate_form_Q13_4()\" method=\"post\">\n<label>\n<input type=\"radio\" name=\"answer_Q13_4\" id=\"answer_Q13_4_1\" value=\"visreg(model.ART, xvar = &quot;ART&quot;, trans = CI(0.99))\"/>\nvisreg(model.ART, xvar = \"ART\", trans = CI(0.99))\n</label>\n<br/>\n<label>\n<input type=\"radio\" name=\"answer_Q13_4\" id=\"answer_Q13_4_2\" value=\"visreg(model.ART, xvar = &quot;ART&quot;, alpha = 99)\"/>\nvisreg(model.ART, xvar = \"ART\", alpha = 99)\n</label>\n<br/>\n<label>\n<input type=\"radio\" name=\"answer_Q13_4\" id=\"answer_Q13_4_3\" value=\"visreg(model.ART, xvar = &quot;ART&quot;, CI = 0.01)\"/>\nvisreg(model.ART, xvar = \"ART\", CI = 0.01)\n</label>\n<br/>\n<label>\n<input type=\"radio\" name=\"answer_Q13_4\" id=\"answer_Q13_4_4\" value=\"visreg(model.ART, xvar = &quot;ART&quot;, alpha = &quot;99%&quot;)\"/>\nvisreg(model.ART, xvar = \"ART\", alpha = \"99%\")\n</label>\n<br/>\n<label>\n<input type=\"radio\" name=\"answer_Q13_4\" id=\"answer_Q13_4_5\" value=\"visreg(model.ART, xvar = &quot;ART&quot;, alpha = 0.01)\"/>\nvisreg(model.ART, xvar = \"ART\", alpha = 0.01)\n</label>\n<br/>\n<input type=\"submit\" value=\"Check answer\"/>\n<div id=\"result_Q13_4\"></div>\n</form>\n<script>function validate_form_Q13_4() {var x, text; var x = document.forms['form_Q13_4']['answer_Q13_4'].value;if (x == 'visreg(model.ART, xvar = \"ART\", alpha = 0.01)'){text = 'That’s right, well done!';} else {text = 'No, that’s not it. Have you tried to run the command to see if it works?';} document.getElementById('result_Q13_4').innerHTML = text; evaluate_final_score(); return false;}function evaluate_final_score(){\n         element = document.getElementById('checkdown_final_score');\n         if(element === null){return false;} else {var element, text, res1, res2, res3, res4;res1 = document.getElementById('result_Q13_1').innerText == 'That’s right, well done!'; res2 = document.getElementById('result_Q13_2').innerText == 'Excellent!'; res3 = document.getElementById('result_Q13_3').innerText == 'Absolutely, well done!'; res4 = document.getElementById('result_Q13_4').innerText == 'That’s right, well done!';text = res1 + res2 + res3 + res4;element.innerHTML = text;\n         return false;\n         }}</script>\n```\n\n:::\n\n::: {.cell-output-display}\n\n```{=html}\n<div id=\"hint_42138\" onclick=\"return show_hint_42138()\">🐭 Click on the mouse for a hint.</div>\n<div id=\"result_42138\" onclick=\"return show_hint_42138()\"></div>\n<script>function show_hint_42138(){var x = document.getElementById('result_42138').innerHTML; if(!x){document.getElementById('result_42138').innerHTML = '99% expressed as a probability is 0.99. The significance level is equal to 1 minus the confidence level expressed as a probability.';} else {document.getElementById('result_42138').innerHTML = '';}}</script>\n```\n\n:::\n:::\n\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\" code-summary=\"Show sample code to answer Q13.4.\"}\n# The argument that you need to change is called \"alpha\". This is because the significance level is also called the alpha level (see Section 11.3). \n\n# The alpha value that corresponds to a 99% confidence interval is equal to:\n1 - 0.99\n\n# Hence the code should (minimally) include these arguments:\nvisreg(model.ART, \n       xvar = \"ART\", \n       alpha = .01)\n```\n:::\n\n\nObserve how the width of the confidence bands changes when you increase the significance level from 0.01 to 0.1: the higher the significance level, the narrower the confidence band becomes. Remember that the significance level corresponds to the risk that we are willing to take of wrongly rejecting the null hypothesis when it is actually true. Therefore, when we lower this risk by choosing a lower significance level (i.e., 0.01), we end up with wider confidence bands that are more likely to allow us to draw a flat line (see @sec-Correlations). If we can draw a flat line through a 99% confidence band, this means that we do not have enough evidence to reject the null hypothesis at the significance level of 0.01.\n:::\n\n## Relative importance of predictors\n\nWhen interpreting a model summary, it is important to remember that the coefficient estimates of each predictor correspond to a change in prediction for a one-unit change in that predictor, e.g. for the predictor `Age`, an increase of one year. However, within a single model, it's quite common for the predictor variables to be measured in different units. For example, in `summary(model4_c)`, the coefficient estimate for `Age_c` is `0.3718`, which means that, holding all other predictors constant, for every year that a participant is older than the median age, their predicted `Vocab` score increases by `0.3718`. By contrast, the coefficient estimate for the `Blocks_c` predictor (`1.3011`) corresponds to an increase in `Vocab` scores for every additional point that participants score on the non-verbal IQ Blocks test. Its unit is therefore test points. For categorical predictor variables, a single-unit change represents a change from one predictor level to another, e.g. from L1 to L2, or from female to male.\n\nBecause they are in different units that represent different quantities or levels, the raw coefficient estimates of a model cannot be compared to each other. Indeed, depending on the predictor, a one-unit change may correspond to either a big or a small change. This is where measures of the relative importance of predictors come in handy. In this chapter, we will use the **lmg** metric [that was first proposed by **L**indeman, **M**erenda & **G**old in -@lindemanIntroductionBivariateMultivariate1980: 119 ff.] to compare the importance of predictors within a single multiple linear regression model.\n\nAlthough not currently widely used in the language sciences [but see, e.g. @DabrowskaExperienceAptitudeIndividual2019: 14], lmg has a number of advantages. Its interpretation is fairly intuitive because it is similar to a coefficient of determination (R^2^): a value of 0 means that, in this model, a predictor accounts for 0% of the variance in the outcome variable, while a value of 1 would mean that it can be used to perfectly predict the outcome variable. Calculating lmg values is computationally involved because the metric includes both direct effects and is adjusted for all the other predictors of the model. But this need not worry us because a researcher and statistician, Ulrike Grömping, has developed and published an `R` package that will do the computation for us. 😊\n\nOnce we have installed and loaded the {[relaimpo](https://cran.r-universe.dev/relaimpo/doc/manual.html)} package[^13_multiplelinearregression-1] [@grömping2006], we can use its `calc.relimp()` function to calculate a range of relative importance metrics for linear models. With the argument \"type\", we specify that we are interested in the lmg metric:\n\n[^13_multiplelinearregression-1]: Loading the {relaimpo} package returns several warnings informing us, on the one hand, about packages that {relaimpo} requires to work and which are therefore also automatically loaded (these are called **dependencies**) and, on the other, about objects being **masked** by different packages, e.g.:\n\n    ```         \n    The following object is masked from ‘package:dplyr’:\n\n    select\n    ```\n\n    It is worth paying attention to the latter set of warnings because it means that some function names, e.g. `select()`, are now shared by more than one package in our `R` environment. This can cause code that previously worked fine to suddenly return errors. For example, after loading the {relaimpo} package, you may find that the `select()` function no longer works as expected because `R` attempts to use the `select()` function from the {MASS} package rather than from the tidyverse {dplyr} package. To avoid this happening, we can manually assign the correct package to the function name like this:\n\n\n    ::: {.cell}\n    \n    ```{.r .cell-code}\n    select <- dplyr::select\n    ```\n    :::\n\n\n    This ensures that any future mentions of the `select()` function are, by default, interpreted as the function defined in the {dplyr} package.\n\n\n::: {.cell}\n\n```{.r .cell-code}\ninstall.packages(\"relaimpo\")\nlibrary(relaimpo)\nselect <- dplyr::select\n\nrel.imp.metric <- calc.relimp(model4_c, \n                              type = \"lmg\")\n```\n:::\n\n\n\n::: {.cell}\n\n:::\n\n\nThe output of the function is long. We have therefore saved it as a new `R` object (`rel.imp.metric`) in order to retrieve only the part that we are interested in, namely the lmp values for each predictor, as a single data frame (`rel.imp.metric.df`):\n\n\n::: {.cell}\n\n```{.r .cell-code}\nrel.imp.metric.df <- data.frame(lmg = rel.imp.metric$lmg) |> \n    rownames_to_column(var = \"Predictor\")\n```\n:::\n\n\nWe display this data frame in descending order of lmp values, rounded to two decimal values:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nrel.imp.metric.df |> \n  mutate(lmg = round(lmg, digits = 2)) |> \n  arrange(-lmg)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n   Predictor  lmg\n1      Group 0.15\n2 OccupGroup 0.07\n3 EduTotal_c 0.05\n4      Age_c 0.04\n5   Blocks_c 0.04\n6     Gender 0.00\n```\n\n\n:::\n:::\n\n\nThese values indicate that, on average, whether or not a participant is a native or non-native speaker of English (`Group`) makes the biggest difference in terms of predicted `Vocab` scores. Gender, by contrast, is practically irrelevant in this model.\n\nWe can also visualise these values in the form of a bar plot (see @fig-ModelLmg). Note that another nice thing about the lmg metric is that the lmg values for all the predictors entered in `model4_c` add up to the model's (unadjusted) multiple R^2^ (`0.3621`).\n\n\n::: {.cell}\n\n```{.r .cell-code}\nrel.imp.metric.df |> \n  ggplot(mapping = aes(x = fct_reorder(Predictor, lmg),\n                       y = lmg)) +\n  geom_col() +\n  theme_minimal() +\n  labs(x = \"Predictor in model4_c\") +\n  coord_flip() \n```\n\n::: {.cell-output-display}\n![Relative importance of predictors in `model 4_c`](13_MultipleLinearRegression_files/figure-html/fig-ModelLmg-1.png){#fig-ModelLmg fig-alt='Bar plot showing the relative importance of six predictors in model4_c, with predictor names on the y-axis and lmg values on the x-axis. Group has the highest importance and Gender has the lowest one.' width=576}\n:::\n:::\n\n\nIt is also worth noting that the second most important predictor is `OccupGroup`. This may come as a surprise given that none of its levels (or rather none of the differences between the reference level of `C` for clerical occupations and the remaining levels) make a statistically significant contribution to the model. This result illustrates the value of this type of analysis compared to only looking at a model's coefficient estimates.\n\nMany studies will compare the coefficient estimates of multiple regression models using **standardised coefficients** \\[see e.g. \\@winterStatisticsLinguistsIntroduction2020: Section 6.2\\]; however, this approach can lead to misleading conclusions [see e.g. @mizumotoCalculatingRelativeImportance2023].\n\n::: {.callout-tip collapse=\"false\"}\n#### Your turn! {.unnumbered}\n\nIn the last [Your turn!]{style=\"color:green;\"} section, you fitted a multiple linear regression model to predict `Vocab` scores among L1 and L2 speakers using all of the predictors that we used in `model4_c` plus `ART` scores.\n\n[**Q13.5**]{style=\"color:green;\"} Calculate the relative importance of each of the predictors in this model using the {relaimpo} package. What is the relative importance of the predictor `ART` in this model as estimated by the lmg metric and rounded to two decimal places?\n\n\n::: {.cell}\n::: {.cell-output-display}\n\n```{=html}\n<form name=\"form_Q13_5\" onsubmit=\"return validate_form_Q13_5()\" method=\"post\">\n<input type=\"text\" placeholder=\"\" name=\"answer_Q13_5\"/>\n<input type=\"submit\" value=\"Check answer\"/>\n<div id=\"result_Q13_5\"></div>\n</form>\n<script>function validate_form_Q13_5() {var x, text; var x = document.forms['form_Q13_5']['answer_Q13_5'].value;if (x == '0.11'|x == '0,11'){text = 'That’s right! Note that entering this predictor in the model changes the relative importance of all the other predictors, too.';} else {text = 'No, that’s incorrect.';} document.getElementById('result_Q13_5').innerHTML = text; evaluate_final_score(); return false;}function evaluate_final_score(){\n         element = document.getElementById('checkdown_final_score');\n         if(element === null){return false;} else {var element, text, res1, res2, res3, res4, res5;res1 = document.getElementById('result_Q13_1').innerText == 'That’s right, well done!'; res2 = document.getElementById('result_Q13_2').innerText == 'Excellent!'; res3 = document.getElementById('result_Q13_3').innerText == 'Absolutely, well done!'; res4 = document.getElementById('result_Q13_4').innerText == 'That’s right, well done!'; res5 = document.getElementById('result_Q13_5').innerText == 'That’s right! Note that entering this predictor in the model changes the relative importance of all the other predictors, too.';text = res1 + res2 + res3 + res4 + res5;element.innerHTML = text;\n         return false;\n         }}</script>\n```\n\n:::\n:::\n\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\" code-summary=\"Show sample code to answer Q13.5.\"}\n# Fit the model:\nmodel.ART <- lm(Vocab ~ Group + Age_c + OccupGroup + Gender + Blocks_c + EduTotal_c + ART, \n             data = Dabrowska.data)\n\n# Compute the lmg values and extract them as a data frame\nlibrary(relaimpo)\nrel.imp.metric <- calc.relimp(model.ART, \n                              type = \"lmg\")\n\nrel.imp.metric.df <- data.frame(lmg = rel.imp.metric$lmg) |> \n    rownames_to_column(var = \"Predictor\")\n\nrel.imp.metric.df |> \n  mutate(lmg = round(lmg, digits = 2)) |> \n  arrange(-lmg)\n```\n:::\n\n:::\n\n## Modelling interactions between predictors\n\nOne of the strengths of multiple linear regression is that we can also model interactions between predictors. This is important because a predictor's relationship with the outcome variable may depend on another predictor. Consider `Age` as a predictor of `Vocab` scores. In `model4_c`, we saw that this predictor made a statistically significant contribution to the model. The coefficient was positive, which means that the model predicts that the older the participants, the higher their receptive English vocabulary.\n\nHowever, if you completed [**Task 11.1**]{style=\"color:green;\"}, you might remember that `Age` correlates positively with `Vocab` scores among L1 participants, but does not among L2 participants (see @fig-CorVocabAge below). If anything, the correlation visualised in the right-hand panel of @fig-CorVocabAge is slightly negative. Moreover, the confidence band is wide enough to draw a horizontal line through it, which suggests that the data are also compatible with the null hypothesis of no correlation. As a result, we can conclude that this slightly negative correlation is not statistically significant.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nDabrowska.data |> \n   ggplot(mapping = aes(x = Age, \n                        y = Vocab)) +\n     geom_point() +\n     facet_wrap(~ Group) +\n     geom_smooth(method = \"lm\", \n                 se = TRUE) +\n  theme_bw()\n```\n\n::: {.cell-output-display}\n![Observed correlation between participants' vocabulary scores and their age in both the L1 and L2 groups](13_MultipleLinearRegression_files/figure-html/fig-CorVocabAge-1.png){#fig-CorVocabAge fig-alt='Two-panel scatter plot showing vocabulary scores versus age for L1 and L2 groups, with data points and blue regression lines with gray confidence bands. The L1 panel shows a positive correlation, while the L2 panel shows a negative correlation.' width=576}\n:::\n:::\n\n\n@fig-CorVocabAge informs us that what we really need is a model that can account for the fact that `Age` is probably a useful predictor of `Vocab` scores for L1 speakers, but not so much for L2 speakers. In other words, we'd like to model an **interaction** between the predictors `Age` and `Group`.\n\nIn `R`'s formula syntax, interaction terms are denoted with a colon (`:`) or an asterisk (`*`). In the following model, therefore, we are attempting to predict `Vocab` scores on the basis of a person's native-speaker status (`Group`), their age, occupational group, gender, Blocks test score, number of years in formal education, and the interaction between their age and native-speaker status (`Age_c:Group`):\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmodel5 <- lm(Vocab ~ Group + Age_c + OccupGroup + Gender + Blocks_c + EduTotal_c + Age_c:Group, \n             data = Dabrowska.data)\n\nsummary(model5)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nCall:\nlm(formula = Vocab ~ Group + Age_c + OccupGroup + Gender + Blocks_c + \n    EduTotal_c + Age_c:Group, data = Dabrowska.data)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-66.720 -10.651   1.224  11.939  45.415 \n\nCoefficients:\n              Estimate Std. Error t value Pr(>|t|)    \n(Intercept)    69.1314     3.6286  19.052  < 2e-16 ***\nGroupL2       -19.9128     3.4699  -5.739 5.26e-08 ***\nAge_c           0.5466     0.1471   3.717 0.000286 ***\nOccupGroupI     7.8267     5.4824   1.428 0.155525    \nOccupGroupM    -4.0769     4.3852  -0.930 0.354058    \nOccupGroupPS   -1.7774     4.2686  -0.416 0.677729    \nGenderM        -1.6285     3.1213  -0.522 0.602644    \nBlocks_c        1.2414     0.3132   3.964 0.000115 ***\nEduTotal_c      2.5520     0.6126   4.166 5.27e-05 ***\nGroupL2:Age_c  -0.8982     0.2867  -3.133 0.002089 ** \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 18.12 on 147 degrees of freedom\nMultiple R-squared:  0.402,\tAdjusted R-squared:  0.3654 \nF-statistic: 10.98 on 9 and 147 DF,  p-value: 5.537e-13\n```\n\n\n:::\n:::\n\n\nIn the model summary above, the interaction term between `Age` and `Group` is the last coefficient listed (`GroupL2:Age_c`). The values confirm our intuition based on our descriptive visualisation of the data (@fig-CorVocabAge): there is a statistically significant interaction between age and native-speaker status (*p* = 0.002089) and the interaction coefficient for this interaction term (`Age_c:Group`) is negative (`-0.8982`). This means that, whilst being older is generally associated with higher `Vocab` scores for the reference level of L1 speakers, if a participant is an L2 English speaker, this trend is reversed.\n\nTo understand how this works in practice, let's compare the predicted `Vocab` scores of two 35-year-olds: one a native English speaker and the other a non-native. For the purposes of this illustration, we will assume that, apart from their native-speaker status, all their other characteristics correspond to the reference level in our model (i.e. they are both female, have a clerical occupation, scored average on the Blocks test and were in formal education for the median number of years). For the L1 speaker, we calculate their predicted `Vocab` score as before. We take the intercept (`69.1314`) as our starting point and then add the `Age_c` coefficient (`0.5466`) multiplied by the difference between their age and the median age (which is the reference level of our centered predictor) (i.e., 35 - 31 = 4). This means that their predicted `Vocab` score is:\n\n\n::: {.cell}\n\n```{.r .cell-code}\n69.1314 + 0.5466*4\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 71.3178\n```\n\n\n:::\n:::\n\n\n\n\nFor the L2 speaker, we begin by combining the same coefficient estimates as above but, this time, we also add the `GroupL2` coefficient (`-19.9128`), and the interaction coefficient (`GroupL2:Age_c`). The interaction coefficient (`-0.8982`) has to be multiplied by the difference between the speaker's age and the median age (which remains 4 years). This L2 speaker's predicted score is therefore:\n\n\n::: {.cell}\n\n```{.r .cell-code}\n69.1314 + 0.5466*4 + -19.9128 + -0.8982*4\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 47.8122\n```\n\n\n:::\n:::\n\n\n\n\n::: callout-caution\n#### Important {.unnumbered}\n\nWhenever we have a model with an interaction, we can no longer interpret the individual coefficient estimates of the predictors that enter into the interaction by themselves: instead, we must interpret our model's main effects together with their interaction!\n\nFor example, in `model5`, if we only took account of the model's main effect for age, we would be misled into thinking that age is *always* positively associated with `Vocab` scores. However, as illustrated in @fig-CorVocabAge, we know that this is not true for L2 speakers — hence the statistically significant interaction between `Age_c` and `Group` in `model5`.\n:::\n\nThe best way to avoid misinterpreting interaction effects is to make sure you always visualise the predictions of models that involve interactions. The `visreg()` function includes a \"by\" argument, which is ideal for this:\n\n\n::: {.cell source-line-numbers='3'}\n\n```{.r .cell-code}\nvisreg(model5, \n       xvar = \"Age_c\", \n       by = \"Group\",\n       xtrans = function(x) x + median(Dabrowska.data$Age), \n       gg = TRUE) + \n  labs(x = \"Age (in years)\",\n       y = \"Predicted Vocab scores\") +\n  theme_bw()\n```\n\n::: {.cell-output-display}\n![`Vocab` scores as predicted by `model5` for L1 and L2 speakers of various ages (blue lines) and partial model residuals (grey points)](13_MultipleLinearRegression_files/figure-html/fig-PredictedVocabAgeInteraction-1.png){#fig-PredictedVocabAgeInteraction fig-alt='Two-panel plot showing vocabulary scores versus age for L1 and L2 groups, with data points and blue regression lines with gray confidence bands. The L1 panel shows a positive correlation, while the L2 panel shows a negative correlation.' width=576}\n:::\n:::\n\n\nIf we compare @fig-PredictedVocabAgeInteraction (in which the points represent the model's partial residuals) to @fig-CorVocabAge (in which the points represent the actual, observed values), we can see that the partial residuals are, on average, smaller than the differences between the observed values and the regression lines of @fig-CorVocabAge. This is because the regression lines of @fig-CorVocabAge correspond to a model that only includes three coefficients, `Age_c`, `Group` and their interaction (`Age_c:Group`), whereas the partial residuals in @fig-PredictedVocabAgeInteraction correspond to the left-over variance in `Vocab` scores once all other predictors of the `model5` have been taken into account.\n\nComparing the model summaries of `model4_c` and `model5`, we can see that adding the interaction term between age and native-speaker status considerably boosted the amount of variance in `Vocab` scores that our model now accounts for: whereas the adjusted R^2^ of the model without the interaction was `0.3276` (33%), it has now reached `0.3654` (37%) thanks to the added interaction.\n\n::: {.callout-tip collapse=\"false\"}\n#### Your turn! {.unnumbered}\n\nIn this task, we will explore the possibility of an interaction between participants' native-speaker status (`Group`) and the number of years they spent in formal education (`EduTotal`). The underlying idea is that, for the L1 speakers, their formal education will most likely have been in English; hence the longer they were in formal education, the higher they might score on the `Vocab` test. For the L2 speakers, however, their formal education will more likely have been in a language other than English. As a result, years in formal education may be a weaker predictor of `Vocab` scores than for L1 speakers.\n\n[**Q13.6**]{style=\"color:green;\"} To begin, generate a plot to visualise this interaction in the observed data: map the `EduTotal` variable onto the *x*-axis and `Vocab` onto the *y*-axis, and split the plot into two facets, one for L1 and the other for L2 participants. Based on your interpretation of your plot, which of these statements is/are correct?\n\n\n::: {.cell}\n::: {.cell-output-display}\n\n```{=html}\n<form name=\"form_Q13_6\" onsubmit=\"return validate_form_Q13_6()\" method=\"post\">\n<label>\n<input type=\"checkbox\" id=\"answer_Q13_6_1\" value=\"For both L1 and L2 participants, the correlation between the number of years that they spent in formal education and their Vocab scores is not statistically significant.\"/>\nFor both L1 and L2 participants, the correlation between the number of years that they spent in formal education and their Vocab scores is not statistically significant.\n</label>\n<br/>\n<label>\n<input type=\"checkbox\" id=\"answer_Q13_6_2\" value=\"For both L1 and L2 participants, the number of years that they spent in formal education is positively correlated with their Vocab scores.\"/>\nFor both L1 and L2 participants, the number of years that they spent in formal education is positively correlated with their Vocab scores.\n</label>\n<br/>\n<label>\n<input type=\"checkbox\" id=\"answer_Q13_6_3\" value=\"For both L1 and L2 participants, the number of years that they spent in formal education is negatively correlated with their Vocab scores.\"/>\nFor both L1 and L2 participants, the number of years that they spent in formal education is negatively correlated with their Vocab scores.\n</label>\n<br/>\n<label>\n<input type=\"checkbox\" id=\"answer_Q13_6_4\" value=\"The number of years that L1 participants spent in formal education is positively correlated with their Vocab scores. This is not the case for L2 participants.\"/>\nThe number of years that L1 participants spent in formal education is positively correlated with their Vocab scores. This is not the case for L2 participants.\n</label>\n<br/>\n<input type=\"submit\" value=\"Check answer\"/>\n<div id=\"result_Q13_6\"></div>\n</form>\n<script>function validate_form_Q13_6() {var text; var x1 = document.getElementById('answer_Q13_6_1'); var x2 = document.getElementById('answer_Q13_6_2'); var x3 = document.getElementById('answer_Q13_6_3'); var x4 = document.getElementById('answer_Q13_6_4'); if (x1.checked == false&x2.checked == true&x3.checked == false&x4.checked == false){text = 'That’s right, well done!';} else {text = 'No, that’s incorrect. Check the code below if you’re struggling to generate the plot.';} document.getElementById('result_Q13_6').innerHTML = text; evaluate_final_score(); return false;}function evaluate_final_score(){\n         element = document.getElementById('checkdown_final_score');\n         if(element === null){return false;} else {var element, text, res1, res2, res3, res4, res5, res6;res1 = document.getElementById('result_Q13_1').innerText == 'That’s right, well done!'; res2 = document.getElementById('result_Q13_2').innerText == 'Excellent!'; res3 = document.getElementById('result_Q13_3').innerText == 'Absolutely, well done!'; res4 = document.getElementById('result_Q13_4').innerText == 'That’s right, well done!'; res5 = document.getElementById('result_Q13_5').innerText == 'That’s right! Note that entering this predictor in the model changes the relative importance of all the other predictors, too.'; res6 = document.getElementById('result_Q13_6').innerText == 'That’s right, well done!';text = res1 + res2 + res3 + res4 + res5 + res6;element.innerHTML = text;\n         return false;\n         }}</script>\n```\n\n:::\n\n::: {.cell-output-display}\n\n```{=html}\n<div id=\"hint_55978\" onclick=\"return show_hint_55978()\">🐭 Click on the mouse for a hint.</div>\n<div id=\"result_55978\" onclick=\"return show_hint_55978()\"></div>\n<script>function show_hint_55978(){var x = document.getElementById('result_55978').innerHTML; if(!x){document.getElementById('result_55978').innerHTML = 'Only one of these statements is correct.';} else {document.getElementById('result_55978').innerHTML = '';}}</script>\n```\n\n:::\n:::\n\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\" code-summary=\"Show code to generate the plot needed to complete Q13.6\"}\nDabrowska.data |> \n   ggplot(mapping = aes(x = EduTotal, \n                        y = Vocab)) +\n     geom_point() +\n     facet_wrap(~ Group) +\n     geom_smooth(method = \"lm\", \n                 se = TRUE) +\n     theme_bw()\n```\n:::\n\n\n[**Q13.7**]{style=\"color:green;\"} Below is the model formula for `model5`:\n\n```         \nVocab ~ Group + Age_c + OccupGroup + Gender + Blocks_c + EduTotal_c + Age_c:Group\n```\n\nWhat do you need to add to this formula to also model the interaction that you just visualised?\n\n\n::: {.cell}\n::: {.cell-output-display}\n\n```{=html}\n<form name=\"form_Q13_7\" onsubmit=\"return validate_form_Q13_7()\" method=\"post\">\n<label>\n<input type=\"radio\" name=\"answer_Q13_7\" id=\"answer_Q13_7_1\" value=\"+ EduTotal:Group\"/>\n+ EduTotal:Group\n</label>\n<br/>\n<label>\n<input type=\"radio\" name=\"answer_Q13_7\" id=\"answer_Q13_7_2\" value=\"+ Vocab ~ EduTotal_c:Group\"/>\n+ Vocab ~ EduTotal_c:Group\n</label>\n<br/>\n<label>\n<input type=\"radio\" name=\"answer_Q13_7\" id=\"answer_Q13_7_3\" value=\"+ EduTotal_c:Group\"/>\n+ EduTotal_c:Group\n</label>\n<br/>\n<label>\n<input type=\"radio\" name=\"answer_Q13_7\" id=\"answer_Q13_7_4\" value=\"+ EduTotal_c:Group:Vocab\"/>\n+ EduTotal_c:Group:Vocab\n</label>\n<br/>\n<input type=\"submit\" value=\"Check answer\"/>\n<div id=\"result_Q13_7\"></div>\n</form>\n<script>function validate_form_Q13_7() {var x, text; var x = document.forms['form_Q13_7']['answer_Q13_7'].value;if (x == '+ EduTotal_c:Group'){text = 'That’s right. Now fit the model and check the model summary to see if this interaction makes a significant contribution to the model!';} else {text = 'No, that’s not it.';} document.getElementById('result_Q13_7').innerHTML = text; evaluate_final_score(); return false;}function evaluate_final_score(){\n         element = document.getElementById('checkdown_final_score');\n         if(element === null){return false;} else {var element, text, res1, res2, res3, res4, res5, res6, res7;res1 = document.getElementById('result_Q13_1').innerText == 'That’s right, well done!'; res2 = document.getElementById('result_Q13_2').innerText == 'Excellent!'; res3 = document.getElementById('result_Q13_3').innerText == 'Absolutely, well done!'; res4 = document.getElementById('result_Q13_4').innerText == 'That’s right, well done!'; res5 = document.getElementById('result_Q13_5').innerText == 'That’s right! Note that entering this predictor in the model changes the relative importance of all the other predictors, too.'; res6 = document.getElementById('result_Q13_6').innerText == 'That’s right, well done!'; res7 = document.getElementById('result_Q13_7').innerText == 'That’s right. Now fit the model and check the model summary to see if this interaction makes a significant contribution to the model!';text = res1 + res2 + res3 + res4 + res5 + res6 + res7;element.innerHTML = text;\n         return false;\n         }}</script>\n```\n\n:::\n:::\n\n\n[**Q13.8**]{style=\"color:green;\"} Fit the model with the added interaction. Does the interaction make a statistically significant contribution to the model at the significance level of 0.05?\n\n\n::: {.cell}\n::: {.cell-output-display}\n\n```{=html}\n<form name=\"form_Q13_8\" onsubmit=\"return validate_form_Q13_8()\" method=\"post\">\n<label>\n<input type=\"radio\" name=\"answer_Q13_8\" id=\"answer_Q13_8_1\" value=\"No, it does not.\"/>\nNo, it does not.\n</label>\n<br/>\n<label>\n<input type=\"radio\" name=\"answer_Q13_8\" id=\"answer_Q13_8_2\" value=\"Yes, it does.\"/>\nYes, it does.\n</label>\n<br/>\n<input type=\"submit\" value=\"Check answer\"/>\n<div id=\"result_Q13_8\"></div>\n</form>\n<script>function validate_form_Q13_8() {var x, text; var x = document.forms['form_Q13_8']['answer_Q13_8'].value;if (x == 'No, it does not.'){text = 'That’s right. The <em>p</em>-value associated with the interaction coefficient is greater than 0.05.';} else {text = 'No. The <em>p</em>-value associated with the interaction coefficient is greater than 0.05.';} document.getElementById('result_Q13_8').innerHTML = text; evaluate_final_score(); return false;}function evaluate_final_score(){\n         element = document.getElementById('checkdown_final_score');\n         if(element === null){return false;} else {var element, text, res1, res2, res3, res4, res5, res6, res7, res8;res1 = document.getElementById('result_Q13_1').innerText == 'That’s right, well done!'; res2 = document.getElementById('result_Q13_2').innerText == 'Excellent!'; res3 = document.getElementById('result_Q13_3').innerText == 'Absolutely, well done!'; res4 = document.getElementById('result_Q13_4').innerText == 'That’s right, well done!'; res5 = document.getElementById('result_Q13_5').innerText == 'That’s right! Note that entering this predictor in the model changes the relative importance of all the other predictors, too.'; res6 = document.getElementById('result_Q13_6').innerText == 'That’s right, well done!'; res7 = document.getElementById('result_Q13_7').innerText == 'That’s right. Now fit the model and check the model summary to see if this interaction makes a significant contribution to the model!'; res8 = document.getElementById('result_Q13_8').innerText == 'That’s right. The p-value associated with the interaction coefficient is greater than 0.05.';text = res1 + res2 + res3 + res4 + res5 + res6 + res7 + res8;element.innerHTML = text;\n         return false;\n         }}</script>\n```\n\n:::\n:::\n\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\" code-summary=\"Show code to complete Q13.8\"}\nmodel5.int <- lm(Vocab ~ Group + Age_c + OccupGroup + Gender + Blocks_c + EduTotal_c + Age_c:Group + EduTotal_c:Group,\n                 data = Dabrowska.data)\n\nsummary(model5.int)\n```\n:::\n\n\n[**Q13.9**]{style=\"color:green;\"} Use the {visreg} package to visualise the interaction effect `EduTotal_c:Group` as predicted by your model. Looking at your plot of predicted values and partial residuals, which conclusion can you draw?\n\n\n::: {.cell}\n::: {.cell-output-display}\n\n```{=html}\n<form name=\"form_Q13_9\" onsubmit=\"return validate_form_Q13_9()\" method=\"post\">\n<label>\n<input type=\"radio\" name=\"answer_Q13_9\" id=\"answer_Q13_9_1\" value=\"Years in formal education is a statistically significant predictor of Vocab scores for both L1 and L2 speakers, and there is no striking difference in the strength of this association between the L1 and the L2 group.\"/>\nYears in formal education is a statistically significant predictor of Vocab scores for both L1 and L2 speakers, and there is no striking difference in the strength of this association between the L1 and the L2 group.\n</label>\n<br/>\n<label>\n<input type=\"radio\" name=\"answer_Q13_9\" id=\"answer_Q13_9_2\" value=\"Years in formal education is a statistically significant predictor of Vocab scores for L1 speakers, but not L2 speakers.\"/>\nYears in formal education is a statistically significant predictor of Vocab scores for L1 speakers, but not L2 speakers.\n</label>\n<br/>\n<label>\n<input type=\"radio\" name=\"answer_Q13_9\" id=\"answer_Q13_9_3\" value=\"Years in formal education is a statistically significant predictor of Vocab scores for L2 speakers, but not L1 speakers.\"/>\nYears in formal education is a statistically significant predictor of Vocab scores for L2 speakers, but not L1 speakers.\n</label>\n<br/>\n<label>\n<input type=\"radio\" name=\"answer_Q13_9\" id=\"answer_Q13_9_4\" value=\"The model makes almost perfect predictions for L1 speakers, but not L2 speakers.\"/>\nThe model makes almost perfect predictions for L1 speakers, but not L2 speakers.\n</label>\n<br/>\n<label>\n<input type=\"radio\" name=\"answer_Q13_9\" id=\"answer_Q13_9_5\" value=\"None of these conclusions can be drawn from the plot alone.\"/>\nNone of these conclusions can be drawn from the plot alone.\n</label>\n<br/>\n<input type=\"submit\" value=\"Check answer\"/>\n<div id=\"result_Q13_9\"></div>\n</form>\n<script>function validate_form_Q13_9() {var x, text; var x = document.forms['form_Q13_9']['answer_Q13_9'].value;if (x == 'Years in formal education is a statistically significant predictor of Vocab scores for both L1 and L2 speakers, and there is no striking difference in the strength of this association between the L1 and the L2 group.'){text = 'That’s right, well done! We can tell from the plot that years in education is a statistically significant predictor because, in both the L1 and the L2 panel, it is impossible to draw a horizontal line that stays within the confidence band. A horizontal line would represent the null hypothesis of no association and, if we cannot draw it within the confidence band, this means that we can reject the null hypothesis. Concerning the statistical significance of the interaction, however, it is not obvious that the slopes of the two lines differ much. All the predicted Vocab scores for L2 speakers are lower than for L1 speakers, but the increase associated with more years of formal education, as represented by the gradients of the two slopes, look about the same. This is why the interaction coefficient turned out not to be statistically significant.';} else {text = 'No. Remember that the strength of the association is represented by the gradient of the slope of the regression lines.';} document.getElementById('result_Q13_9').innerHTML = text; evaluate_final_score(); return false;}function evaluate_final_score(){\n         element = document.getElementById('checkdown_final_score');\n         if(element === null){return false;} else {var element, text, res1, res2, res3, res4, res5, res6, res7, res8, res9;res1 = document.getElementById('result_Q13_1').innerText == 'That’s right, well done!'; res2 = document.getElementById('result_Q13_2').innerText == 'Excellent!'; res3 = document.getElementById('result_Q13_3').innerText == 'Absolutely, well done!'; res4 = document.getElementById('result_Q13_4').innerText == 'That’s right, well done!'; res5 = document.getElementById('result_Q13_5').innerText == 'That’s right! Note that entering this predictor in the model changes the relative importance of all the other predictors, too.'; res6 = document.getElementById('result_Q13_6').innerText == 'That’s right, well done!'; res7 = document.getElementById('result_Q13_7').innerText == 'That’s right. Now fit the model and check the model summary to see if this interaction makes a significant contribution to the model!'; res8 = document.getElementById('result_Q13_8').innerText == 'That’s right. The p-value associated with the interaction coefficient is greater than 0.05.'; res9 = document.getElementById('result_Q13_9').innerText == 'That’s right, well done! We can tell from the plot that years in education is a statistically significant predictor because, in both the L1 and the L2 panel, it is impossible to draw a horizontal line that stays within the confidence band. A horizontal line would represent the null hypothesis of no association and, if we cannot draw it within the confidence band, this means that we can reject the null hypothesis. Concerning the statistical significance of the interaction, however, it is not obvious that the slopes of the two lines differ much. All the predicted Vocab scores for L2 speakers are lower than for L1 speakers, but the increase associated with more years of formal education, as represented by the gradients of the two slopes, look about the same. This is why the interaction coefficient turned out not to be statistically significant.';text = res1 + res2 + res3 + res4 + res5 + res6 + res7 + res8 + res9;element.innerHTML = text;\n         return false;\n         }}</script>\n```\n\n:::\n\n::: {.cell-output-display}\n\n```{=html}\n<div id=\"hint_12413\" onclick=\"return show_hint_12413()\">🐭 Click on the mouse for a hint.</div>\n<div id=\"result_12413\" onclick=\"return show_hint_12413()\"></div>\n<script>function show_hint_12413(){var x = document.getElementById('result_12413').innerHTML; if(!x){document.getElementById('result_12413').innerHTML = 'Think about whether a horizontal line indicating no correlation (i.e. the null hypothesis) could be drawn within the confidence bands.';} else {document.getElementById('result_12413').innerHTML = '';}}</script>\n```\n\n:::\n:::\n\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\" code-summary=\"Show code to help you complete Q13.9\"}\nvisreg(model5.int, \n       xvar = \"EduTotal_c\", \n       by = \"Group\",\n       xtrans = function(x) x + median(Dabrowska.data$EduTotal), \n       gg = TRUE) + \n  labs(x = \"Years in formal education\",\n       y = \"Predicted Vocab scores\") +\n  theme_bw()\n```\n:::\n\n:::\n\n### Interactions between two numeric predictors\n\nWe can also model interactions between two numeric predictors. For instance, we may hypothesise that the positive effect of time spent in formal education is moderated by age. If this interaction effect were negative, this would mean that, as people get older, the fact that they spent longer in formal education becomes less relevant to predict their current vocabulary knowledge.\n\nLet's add an `Age_c:EduTotal_c` interaction to our model to find out if our data support this hypothesis.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmodel6 <- lm(Vocab ~ Group + Age_c + OccupGroup + Gender + Blocks_c + EduTotal_c + Group:Age_c + Age_c:EduTotal_c,\n             data = Dabrowska.data)\n\nsummary(model6)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nCall:\nlm(formula = Vocab ~ Group + Age_c + OccupGroup + Gender + Blocks_c + \n    EduTotal_c + Group:Age_c + Age_c:EduTotal_c, data = Dabrowska.data)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-68.346 -10.460   0.981  11.830  45.360 \n\nCoefficients:\n                  Estimate Std. Error t value Pr(>|t|)    \n(Intercept)       69.27826    3.65827  18.937  < 2e-16 ***\nGroupL2          -20.11637    3.51829  -5.718 5.89e-08 ***\nAge_c              0.53820    0.14902   3.612 0.000418 ***\nOccupGroupI        7.56857    5.53734   1.367 0.173781    \nOccupGroupM       -4.14901    4.40173  -0.943 0.347449    \nOccupGroupPS      -1.88806    4.29021  -0.440 0.660525    \nGenderM           -1.74885    3.14526  -0.556 0.579044    \nBlocks_c           1.24165    0.31409   3.953 0.000120 ***\nEduTotal_c         2.66662    0.68007   3.921 0.000135 ***\nGroupL2:Age_c     -0.87396    0.29409  -2.972 0.003464 ** \nAge_c:EduTotal_c  -0.01776    0.04520  -0.393 0.694947    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 18.17 on 146 degrees of freedom\nMultiple R-squared:  0.4027,\tAdjusted R-squared:  0.3618 \nF-statistic: 9.842 on 10 and 146 DF,  p-value: 1.78e-12\n```\n\n\n:::\n:::\n\n\nLooking at the last coefficient estimate in the model summary (`Age_c:EduTotal_c`), we can see that this second interaction coefficient is negative -- in line with our hypothesis. However, this coefficient is also very small (`-0.01776`). Moreover, its associated *p*-value (`0.694947`) warns us that, if there were no interaction effect (i.e. under the null hypothesis), we would have a 69% probability of observing such a small effect in a dataset this size simply due to random variation alone.\n\nThe model summary also tells us that the amount of variance in `Vocab` scores that `model6` accounts for is 36.18% (`Adjusted R-squared:  0.3618`). This is actually slightly *less* than `model5` (`Adjusted R-squared:  0.3654`), which did not include this interaction. In other words, this additional interaction does not help us to model the association between our predictor variables and `Vocab` scores more accurately.\n\nIn @fig-PredictedVocabAgeByEdu, we visualise this statistically non-significant interaction to better understand what it corresponds to. When used to visualise an interaction effect between two numeric predictors, the `visreg()` function automatically splits the second predictor variable (the \"by\" variable) into three categories corresponding to low, middle, and high values of the variable. It therefore shows the predicted effect of the numeric predictor predicted on the *x*-axis in these three different contexts. If, as in @fig-PredictedVocabAgeByEdu, the three slopes are of the same gradient and the regression lines therefore run parallel to each other, this indicates that there is no noteworthy interaction between the two numeric predictors.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nvisreg(model6,\n       xvar = \"Age_c\", \n       by = \"EduTotal_c\",\n       xtrans = function(x) x + median(Dabrowska.data$Age), \n       gg = TRUE) + \n  labs(x = \"Age\",\n       y = \"Predicted Vocab scores\") +\n  theme_bw()\n```\n\n::: {.cell-output-display}\n![`Vocab` scores as predicted by `model6` for English speakers of various ages who were in formal education for a below-average, average, and above-average length of time (in blue) and partial model residuals (grey points)](13_MultipleLinearRegression_files/figure-html/fig-PredictedVocabAgeByEdu-1.png){#fig-PredictedVocabAgeByEdu fig-alt='Three-panel plot showing predicted vocabulary scores versus age for different education levels, with partial residual points and blue regression lines with gray confidence bands. All three panels show positive correlations between age and vocabulary scores, with higher education levels showing higher predicted scores overall.' width=576}\n:::\n:::\n\n\nExamining @fig-PredictedVocabAgeByEdu, we can therefore conclude that the effect of age on `Vocab` scores is not moderated by the number of years that participants spent in formal education.\n\nThe `visreg()` function provides two ways to visualise interaction effects between two numeric variables: in @fig-PredictedVocabAgeByEdu, below-average, average, and above-average number of years in formal education were visualised across three panels. @fig-PredictedVocabAgeRL shows the same predictions but, this time, the code includes the argument \"overlay = TRUE\", which results in a single panel with three coloured regression lines superimposed. This can make it easier to check whether the lines are parallel. From @fig-PredictedVocabAgeRL, it is easier to see that the three lines are pretty much parallel to each other. This suggests that the positive effect of `Age` on `Vocab` scores does not change as a function of the number of years that participants were in formal education.\n\n\n::: {.cell source-line-numbers='4'}\n\n```{.r .cell-code}\nvisreg(model6,\n       xvar = \"Age_c\", \n       by = \"EduTotal_c\",\n       overlay = TRUE,\n       xtrans = function(x) x + median(Dabrowska.data$Age), \n       gg = TRUE) + \n  labs(x = \"Age\",\n       y = \"Predicted Vocab scores\") +\n  theme_bw()\n```\n\n::: {.cell-output-display}\n![`Vocab` scores as predicted by `model4_c` for English speakers of various ages who were in formal education for a below-average (red line), average (green line), and above-average (blue line) period of time and partial model residuals (coloured points).](13_MultipleLinearRegression_files/figure-html/fig-PredictedVocabAgeRL-1.png){#fig-PredictedVocabAgeRL fig-alt='Visreg plot showing predicted vocabulary scores versus age for three education levels, with color-coded partial residual points and regression lines with confidence bands. The red line is rising from approximately 55 to 80, the green line is rising from about 65 to 90, and the blue lines is rising from approximately 75 to 95.' width=576}\n:::\n:::\n\n\nIn order to interpret the output of a model featuring a significant interaction between two numeric predictors, we will now fit a simpler model predicting the `Vocab` scores of the L1 participants only (`L1.data`) using only two predictor variables: years in formal education (`EduTotal`) and Author Recognition Test (`ART`) scores.\n\nThe Author Recognition Test [@acheson2008] is a measure of print exposure to literature, which is known to be a strong predictor of vocabulary knowledge (see [**Your turn!**]{style=\"color:green;\"} in @sec-ModelPredictions above). This is confirmed in the L1 dataset as `ART` and `Vocab` scores are strongly correlated:\n\n\n::: {.cell}\n\n```{.r .cell-code}\ncor(L1.data$ART, L1.data$Vocab)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 0.6032758\n```\n\n\n:::\n:::\n\n\nAt the same time, we also know that there is a positive, though less strong, correlation between the number of years that L1 participants were in formal education and their `Vocab` test results:\n\n\n::: {.cell}\n\n```{.r .cell-code}\ncor(L1.data$EduTotal, L1.data$Vocab)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 0.4268695\n```\n\n\n:::\n:::\n\n\nIn the following, we explore the possibility that this positive association between Author Recognition Test (`ART`) scores and `Vocab` scores may be moderated by the number of years spent in formal education (`EduTotal`). If this interaction effect were negative, this would mean that, if two individuals both have the same high `ART` score, but one spent longer in formal education, then the effect of those extra years of education would not be as strong as they would be for someone with a lower `ART` score. To test this hypothesis, we formulate the following null hypothesis:\n\n-   **H~0~**: The number of years spent in formal education does not moderate the association of L1 English speakers' `ART` scores with their `Vocab` scores.\n\nWe now fit a model to find out if we have enough evidence to reject this null hypothesis:\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# First, we center the numeric variables in the L1 dataset:\nL1.data <- L1.data |> \n   mutate(EduTotal_c = EduTotal - median(EduTotal),\n          Blocks_c = Blocks - median(Blocks),\n          Age_c = Age - median(Age))\n\n# Second, we fit the model with both variables and their two-way interaction as predictors:\nL1.model <- lm(Vocab ~ ART + EduTotal_c + ART:EduTotal_c,\n              data = L1.data)\n\n# Finally, we inspect the model:\nsummary(L1.model)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nCall:\nlm(formula = Vocab ~ ART + EduTotal_c + ART:EduTotal_c, data = L1.data)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-54.807  -6.113   0.065  10.927  26.379 \n\nCoefficients:\n               Estimate Std. Error t value Pr(>|t|)    \n(Intercept)     51.9162     2.7622  18.795  < 2e-16 ***\nART              1.3088     0.1955   6.696 2.09e-09 ***\nEduTotal_c       5.2626     1.3272   3.965 0.000151 ***\nART:EduTotal_c  -0.1803     0.0530  -3.402 0.001017 ** \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 15.18 on 86 degrees of freedom\nMultiple R-squared:  0.4625,\tAdjusted R-squared:  0.4437 \nF-statistic: 24.67 on 3 and 86 DF,  p-value: 1.311e-11\n```\n\n\n:::\n:::\n\n\nThe model summary confirms that both predictors individually (i.e. as main effects) make statistically significant, positive contributions to the prediction of `Vocab` scores. Crucially, the summary also indicates that the interaction effect (`ART:EduTotal_c`) is statistically significant at α = 0.05 (*p* = `0.001017`). The negative coefficient estimate of `-0.1803` means that, for each additional year of formal education, our model predicts that the effect of a participant's `ART` score on `Vocab` decreases by 0.1803 points. In simpler terms, the positive effect of reading literature, as measured by the Author Recognition Test [@acheson2008], decreases slightly for every year spent in formal education.\n\nRemember that, whenever we report an interaction, we can no longer interpret the estimated coefficients of the individual predictors in isolation. That is because we must also consider the interaction effect. To understand what this means in practice, let's compare two speakers from the L1 dataset:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nL1.data |> \n  slice(2, 18) |> \n  select(Occupation, OccupGroup, ART, EduTotal, Vocab)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n              Occupation OccupGroup ART EduTotal    Vocab\n1 Student/Support Worker         PS  31       13 95.55556\n2              Housewife          I  31       17 84.44444\n```\n\n\n:::\n:::\n\n\n-   Participant No. 2 is a student and support worker with an ART score of 31 points, who has (so far) spent 13 years in formal education.\n\n-   Participant No. 18 is a housewife who also scored 31 points on the ART, but who was in formal education for a total of 17 years.\n\nIn general, we can calculate the `Vocab` scores that our `L1.model` predicts by combining the model's coefficient estimates like this:\n\n> Intercept +\\\n> `ART` coefficient\\*`ART` score +\\\n> `EduTotal` coefficient\\*(`EduTotal` in years - median `EduTotal`) +\\\n> `ART:EduTotal` coefficient\\*`ART` score\\*(`EduTotal` in years - median `EduTotal`)\n\nBased on the coefficient estimates of the model summary, we can therefore calculate the predicted `Vocab` score of the student / support worker as follows:\n\n\n::: {.cell}\n\n```{.r .cell-code}\n51.9162 + # <1>\n1.3088 * 31 + # <2>\n5.2626 * (13 - median(L1.data$EduTotal)) + # <3>\n-0.1803 * 31 * (13 - median(L1.data$EduTotal)) # <4>\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 92.489\n```\n\n\n:::\n:::\n\n\n1.  Intercept coefficient\n2.  Main effect of 31 points on the ART test\n3.  Main effect of 13 years in formal education\n4.  Interaction effect between 31 points on the ART and having spent 13 years in formal education\n\nAnd similarly for the housewife with the same ART score:\n\n\n::: {.cell}\n\n```{.r .cell-code}\n51.9162 + # <1>\n1.3088 * 31 + # <2>\n5.2626 * (17 - median(L1.data$EduTotal)) + # <3>\n-0.1803 * 31 * (17 - median(L1.data$EduTotal)) # <4>\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 91.1822\n```\n\n\n:::\n:::\n\n\n1.  Intercept coefficient\n2.  Main effect of 31 points on ART test\n3.  Main effect of 17 years in formal education\n4.  Interaction effect between scoring 31 points on the ART and having spent 17 years in formal education\n\nWe can check that we did the maths correctly by checking the model's prediction for these two individuals. Remember that minor differences after the decimal point are due to us using rounded coefficient estimates.\n\n\n::: {.cell}\n\n```{.r .cell-code}\npredict(L1.model)[2]\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n       2 \n92.49038 \n```\n\n\n:::\n\n```{.r .cell-code}\npredict(L1.model)[18]\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n      18 \n91.18172 \n```\n\n\n:::\n:::\n\n\nNotice how these two predicted scores are very similar, even though the housewife spent longer in formal education than the student / support worker. This is because, for L1 speakers, greater print exposure and more education generally lead to a larger vocabulary (as indicated by the positive main-effect coefficient estimates in `L1.model`), but the increase in vocabulary for each additional year of education is predicted to be smaller for individuals with higher ART scores.\n\n@fig-VocabEduART visualises the predictions of `L1.model`. How can we interpret these three regression lines?\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\" code-summary=\"Show code to generate plot.\"}\nvisreg(L1.model,\n       xvar = \"EduTotal_c\", \n       by = \"ART\",\n       xtrans = function(x) x + median(L1.data$EduTotal), \n       gg = TRUE) + \n  labs(x = \"Years in formal education\",\n       y = \"Predicted Vocab scores\") +\n  theme_bw()\n```\n\n::: {.cell-output-display}\n![`Vocab` scores as predicted by `L1.model` (in blue) and partial model residuals (grey points) as a function of the number of years speakers were in formal education and for three ART test scores](13_MultipleLinearRegression_files/figure-html/fig-VocabEduART-1.png){#fig-VocabEduART fig-alt='Three-panel plot showing predicted vocabulary scores versus years in formal education for three ART scores (3, 10, and 31), with partial residual points and blue regression lines with gray confidence bands. The left panel (ART: 3) shows a strong positive correlation, the middle panel (ART: 10) shows a moderate positive correlation, and the right panel (ART: 31) shows a nearly flat but negative relationship around 90.' width=576}\n:::\n:::\n\n\nFor low and mid-level ART scores, the model predicts a positive correlation between the number of years a participant has spent in formal education and their predicted `Vocab` scores. However, this is not the case for participants who scored high on the ART test (third panel). The three regression lines representing the model's predicted scores are clearly not parallel, and it would not be possible to draw three parallel lines that each stay within their respective 95% confidence bands. This confirms that, in this L1 model, the interaction between ART scores and years in formal education is statistically significant at α = 0.05. The main effects of these two predictors cannot be meaningfully interpreted without considering this interaction.\n\n## Model selection\n\nTypically, the more predictors we enter in a model, the better the model fits the data. However, having predictors that contribute very little to the model and/or whose contributions are not statistically significant risks lowering the accuracy of the model's predictions on new data. In this case, we say that the model **overfits**. A model that overfits the sample data risks not generalising to other data. If the aim of our statistical modelling is to infer from our sample to the general population (see @sec-Inferential), it can sometimes make sense to try to find an 'optimal' model that accounts for as much of the variance in the outcome variable as possible whilst relying only on association effects that we can be fairly confident could not have occurred due to chance only. This is where model selection comes into play.\n\nSome people consider model selection to be a bit of an art. This chapter only aims to introduce the topic and does not cover — let alone compare or endorse — different model selection procedures. Ultimately, what really matters is that, *if* we intend to apply a model selection procedure, we decide on the method *before* analysing the data. This is because method selection bears the very real risk of (consciously or unconsciously) \"fishing\" for statistically significant results. Fishing is a highly Questionable Research Practice (QRP, see @sec-pHacking) that consists in trying out different methods until we arrive at findings that match our theory and/or hypotheses. For this reason, selection procedures in regression modelling have been heavily criticised over the years and there are very good arguments for not engaging in any model selection at all [@thompsonStepwiseRegressionStepwise1995; @smithStepAwayStepwise2018; @harrellRegressionModelingStrategies2015: Section 4.3].\n\n> A fundamental problem with stepwise regression is that some real explanatory variables that have causal effects on the dependent variable may happen to not be statistically significant, while nuisance variables may be coincidentally significant. As a result, the model may fit the data well in-sample, but do poorly out-of-sample. [@smithStepAwayStepwise2018: 1]\n\nNonetheless, in the following section, we will see how we might - *if* we decide to narrow down predictor variables using model selection - arrive at an optimal model of `Vocab` scores among L1 and L2 speakers of English using the **adjusted R^2^** as our model selection decision criterion. Recall that R^2^ values correspond to the amount of variance in the outcome variable that a model can predict. The adjusted R^2^ is particularly useful because it is adjusted for the number of predictors entered in the model; models with more predictors are penalised.\n\n> When using adjusted R^2^ as the decision criterion, we seek to eliminate or add predictors depending on whether they lead to the largest improvement in adjusted R^2^ and we stop when adding or eliminating another predictor does not lead to further improvement in adjusted R^2^.\n>\n> Adjusted R^2^ describes the strength of a model fit, and it is a useful tool for evaluating which predictors are adding value to the model, where *adding value* means they are (likely) improving the accuracy in predicting future outcomes. [@cetinkaya-rundelIntroductionModernStatistics2021: [Section 8.4](https://openintro-ims.netlify.app/model-mlr#sec-model-selection)]\n\nThere are two common ways to add or remove predictors in a multiple regression model. These are called backward elimination and forward selection. They are often called **stepwise selection** because they add or remove one variable at a time.\n\n> **Backward elimination** starts with the full model – the model that includes all potential predictor variables. Predictors are eliminated one-at-a-time from the model until we cannot improve the model any further.\n>\n> **Forward selection** is the reverse of the backward elimination technique. Instead of eliminating predictors one-at-a-time, we add predictors one-at-a-time until we cannot find any predictors that improve the model any further. [@cetinkaya-rundelIntroductionModernStatistics2021: [Section 8.4](https://openintro-ims.netlify.app/model-mlr#sec-model-selection)]\n\nWe will use backward elimination as it allows us to start with a **full model** that includes all the predictors and any interactions that we believe are justified on the basis of theory and/or prior research. At this stage, it is absolutely crucial to think about which variables and which interactions are genuinely meaningful and which are not!\n\nWith the @DabrowskaExperienceAptitudeIndividual2019 data, several full models can be justified. In this section, we will attempt to model `Vocab` scores among L1 participants using four predictors (`ART`, `Blocks_c`, `Age_c`, `EduTotal_c`, and `OccupGroup`) and the following four interactions (`ART:EduTotal_c`, `Blocks_c:EduTotal_c`, `ART:Age_c`, and `Blocks:Age_c`). We can justify this choice of predictors based on our current understanding of language learning.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nL1.model.full <- lm(Vocab ~ ART + Blocks_c + Age_c + EduTotal_c + OccupGroup + ART:EduTotal_c + Blocks_c:EduTotal_c + ART:Age_c + Blocks_c:Age_c, \n           data = L1.data)\n\nsummary(L1.model.full)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nCall:\nlm(formula = Vocab ~ ART + Blocks_c + Age_c + EduTotal_c + OccupGroup + \n    ART:EduTotal_c + Blocks_c:EduTotal_c + ART:Age_c + Blocks_c:Age_c, \n    data = L1.data)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-42.927  -4.064  -0.374   8.295  28.282 \n\nCoefficients:\n                      Estimate Std. Error t value Pr(>|t|)    \n(Intercept)         53.1677121  3.7269444  14.266  < 2e-16 ***\nART                  1.1304963  0.2330505   4.851 6.16e-06 ***\nBlocks_c             1.4066157  0.3164938   4.444 2.88e-05 ***\nAge_c                0.5955643  0.1895092   3.143  0.00237 ** \nEduTotal_c           4.4423564  1.3560678   3.276  0.00157 ** \nOccupGroupI          4.0757889  4.7833634   0.852  0.39678    \nOccupGroupM          0.1584647  4.3523775   0.036  0.97105    \nOccupGroupPS         0.4096426  4.3947432   0.093  0.92597    \nART:EduTotal_c      -0.1523719  0.0513417  -2.968  0.00398 ** \nBlocks_c:EduTotal_c -0.1428729  0.1311735  -1.089  0.27942    \nART:Age_c           -0.0125418  0.0096286  -1.303  0.19656    \nBlocks_c:Age_c      -0.0007549  0.0194954  -0.039  0.96921    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 13.45 on 78 degrees of freedom\nMultiple R-squared:  0.6172,\tAdjusted R-squared:  0.5632 \nF-statistic: 11.43 on 11 and 78 DF,  p-value: 2.492e-12\n```\n\n\n:::\n:::\n\n\nOur full model has an adjusted R^2^ of `0.5632`, which means that the combination of these variables and the four interactions account for about 56% of the variance in `Vocab` scores in the L1 data. However, many of the model coefficients in `L1.model.full` are not statistically significant, so we could try to remove them to see whether this leads to a lower adjusted R^2^ or not. Strictly speaking, a stepwise selection procedure would entail removing each interaction one-by-one. To save space here, we remove all three non-significant interaction terms in a single backward step:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nL1.model.back1 <- lm(Vocab ~ ART + Blocks_c + Age_c + EduTotal_c + OccupGroup + ART:EduTotal_c, \n           data = L1.data)\n\nsummary(L1.model.back1)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nCall:\nlm(formula = Vocab ~ ART + Blocks_c + Age_c + EduTotal_c + OccupGroup + \n    ART:EduTotal_c, data = L1.data)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-42.282  -4.835   0.367   8.867  29.110 \n\nCoefficients:\n               Estimate Std. Error t value Pr(>|t|)    \n(Intercept)    53.61458    3.60809  14.860  < 2e-16 ***\nART             0.97262    0.20158   4.825 6.48e-06 ***\nBlocks_c        1.37827    0.31278   4.407 3.19e-05 ***\nAge_c           0.42996    0.13122   3.276  0.00155 ** \nEduTotal_c      4.17372    1.30919   3.188  0.00204 ** \nOccupGroupI     4.00028    4.65106   0.860  0.39228    \nOccupGroupM     0.74751    4.29748   0.174  0.86235    \nOccupGroupPS   -0.22682    4.17410  -0.054  0.95680    \nART:EduTotal_c -0.13709    0.04903  -2.796  0.00646 ** \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 13.38 on 81 degrees of freedom\nMultiple R-squared:  0.6067,\tAdjusted R-squared:  0.5679 \nF-statistic: 15.62 on 8 and 81 DF,  p-value: 1.153e-13\n```\n\n\n:::\n:::\n\n\nThis procedure has actually led to a (very) small increase in our adjusted R^2^, which is now `0.5679`, or 57%. Can we simplify our model even further and still account for as much variance in `Vocab` scores by dropping categorical predictor variable `OccupGroup`?\n\n\n::: {.cell}\n\n```{.r .cell-code}\nL1.model.back2 <-  lm(Vocab ~ ART + Blocks_c + Age_c + EduTotal_c + ART:EduTotal_c, \n           data = L1.data)\n\nsummary(L1.model.back2)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nCall:\nlm(formula = Vocab ~ ART + Blocks_c + Age_c + EduTotal_c + ART:EduTotal_c, \n    data = L1.data)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-43.379  -5.410   0.824   8.369  32.573 \n\nCoefficients:\n               Estimate Std. Error t value Pr(>|t|)    \n(Intercept)     54.2022     2.4512  22.113  < 2e-16 ***\nART              0.9970     0.1922   5.187 1.46e-06 ***\nBlocks_c         1.3251     0.3030   4.373 3.49e-05 ***\nAge_c            0.4843     0.1092   4.434 2.78e-05 ***\nEduTotal_c       4.3116     1.2812   3.365  0.00115 ** \nART:EduTotal_c  -0.1472     0.0471  -3.125  0.00244 ** \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 13.21 on 84 degrees of freedom\nMultiple R-squared:  0.6025,\tAdjusted R-squared:  0.5788 \nF-statistic: 25.46 on 5 and 84 DF,  p-value: 1.521e-15\n```\n\n\n:::\n:::\n\n\nThis new model has a slightly higher adjusted R^2^ (`0.5788`), so it looks like this was another sensible simplification of our model. All of the remaining coefficient estimates in `L1.model.back2` make statistically significant contributions to the model. If we try to remove one, we can expect that the amount of variance that our model can account for will drop. For example, we can try to remove `Age` as a predictor from our model to see what happens:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nL1.model.back3 <- lm(Vocab ~ ART + Blocks_c + EduTotal_c + ART:EduTotal_c, \n           data = L1.data)\n\nsummary(L1.model.back3)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nCall:\nlm(formula = Vocab ~ ART + Blocks_c + EduTotal_c + ART:EduTotal_c, \n    data = L1.data)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-48.816  -7.486  -0.458   9.970  26.546 \n\nCoefficients:\n               Estimate Std. Error t value Pr(>|t|)    \n(Intercept)    52.08245    2.65487  19.618  < 2e-16 ***\nART             1.38099    0.18951   7.287  1.5e-10 ***\nBlocks_c        0.90754    0.31806   2.853  0.00543 ** \nEduTotal_c      3.59093    1.40344   2.559  0.01228 *  \nART:EduTotal_c -0.15028    0.05201  -2.890  0.00489 ** \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 14.59 on 85 degrees of freedom\nMultiple R-squared:  0.5095,\tAdjusted R-squared:  0.4864 \nF-statistic: 22.07 on 4 and 85 DF,  p-value: 1.615e-12\n```\n\n\n:::\n:::\n\n\nIndeed, `L1.model.back3` accounts for 49% of the variance (adjusted R^2^ = `0.4864`), which is considerably less than `L1.model.back2`. We will therefore report and interpret `L1.model.back2`.\n\n:::: callout-note\n## Reporting a multiple regression model\n\nThere are many ways to report the **numerical** results of a statistical model. Researchers typically include a table reporting the model's coefficient estimates (sometimes referred to as β, \"beta\"), together with a measure of variability around these estimates (e.g., standard error or confidence intervals), as well as their associated *p*-values. In addition, it is important to report the accuracy of the model. Different so-called **goodness-of-fit measures** are used for this; one of the most common being the adjusted coefficient of determination, R^2^. The output of the `summary()` function includes all of these statistics and is therefore suitable for a research report.\n\nAlternatively, the [{sjPlot}](https://strengejacke.github.io/sjPlot/) library [@lüdecke2020] includes a handy function that produces nicely formatted tables to report all kinds of models, including multiple linear regression models. When you run the `tab_model()` function in RStudio, the table will be displayed in the Viewer pane. By default, it includes the model's coefficient estimates and 95% confidence intervals around these estimates, as well as *p*-values formatted in bold if they are below 0.05.\n\n\n::: {.cell}\n\n```{.r .cell-code}\ninstall.packages(\"sjPlot\")\nlibrary(sjPlot)\n\ntab_model(L1.model.back2)\n```\n:::\n\n\n\n::: {.cell}\n::: {.cell-output-display}\n`````{=html}\n<table style=\"border-collapse:collapse; border:none;\">\n<tr>\n<th style=\"border-top: double; text-align:center; font-style:normal; font-weight:bold; padding:0.2cm;  text-align:left; \">&nbsp;</th>\n<th colspan=\"3\" style=\"border-top: double; text-align:center; font-style:normal; font-weight:bold; padding:0.2cm; \">Vocab</th>\n</tr>\n<tr>\n<td style=\" text-align:center; border-bottom:1px solid; font-style:italic; font-weight:normal;  text-align:left; \">Predictors</td>\n<td style=\" text-align:center; border-bottom:1px solid; font-style:italic; font-weight:normal;  \">Estimates</td>\n<td style=\" text-align:center; border-bottom:1px solid; font-style:italic; font-weight:normal;  \">CI</td>\n<td style=\" text-align:center; border-bottom:1px solid; font-style:italic; font-weight:normal;  \">p</td>\n</tr>\n<tr>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:left; \">(Intercept)</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \">54.20</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \">49.33&nbsp;&ndash;&nbsp;59.08</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \"><strong>&lt;0.001</strong></td>\n</tr>\n<tr>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:left; \">ART</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \">1.00</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \">0.61&nbsp;&ndash;&nbsp;1.38</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \"><strong>&lt;0.001</strong></td>\n</tr>\n<tr>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:left; \">Blocks c</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \">1.33</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \">0.72&nbsp;&ndash;&nbsp;1.93</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \"><strong>&lt;0.001</strong></td>\n</tr>\n<tr>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:left; \">Age c</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \">0.48</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \">0.27&nbsp;&ndash;&nbsp;0.70</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \"><strong>&lt;0.001</strong></td>\n</tr>\n<tr>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:left; \">EduTotal c</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \">4.31</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \">1.76&nbsp;&ndash;&nbsp;6.86</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \"><strong>0.001</strong></td>\n</tr>\n<tr>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:left; \">ART × EduTotal c</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \">&#45;0.15</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \">&#45;0.24&nbsp;&ndash;&nbsp;-0.05</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \"><strong>0.002</strong></td>\n</tr>\n<tr>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:left; padding-top:0.1cm; padding-bottom:0.1cm; border-top:1px solid;\">Observations</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; padding-top:0.1cm; padding-bottom:0.1cm; text-align:left; border-top:1px solid;\" colspan=\"3\">90</td>\n</tr>\n<tr>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:left; padding-top:0.1cm; padding-bottom:0.1cm;\">R<sup>2</sup> / R<sup>2</sup> adjusted</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; padding-top:0.1cm; padding-bottom:0.1cm; text-align:left;\" colspan=\"3\">0.603 / 0.579</td>\n</tr>\n\n</table>\n\n`````\n:::\n:::\n\n\n::: column-margin\n![Hex sticker of the [{sjPlot}](https://strengejacke.github.io/sjPlot/) package](images/hex_sjPlot.png){width=\"100\"}\n:::\n\nCheck the documentation of the `tab_model()` function and the [sjPlot website](https://strengejacke.github.io/sjPlot/) to learn about its many useful formatting options:\n\n\n::: {.cell}\n\n```{.r .cell-code}\n?tab_model\n```\n:::\n\n\nIt is also recommended to **visualise** the model's predictions and its (partial) residuals. Again, there are many ways to achieve this in `R`, but we will stick to using the {visreg} library. Run the following command and follow the instructions displayed in the Console to view all the plots in RStudio. You may need to resize your Plot pane or use the Zoom button to properly view the plots.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nvisreg(L1.model.back2)\n```\n:::\n\n\nRunning the `visreg()` function on this multiple regression model outputs several warning messages in the Console. These messages are important and should not be ignored:\n\n```         \nNote that you are attempting to plot a 'main effect' in a model that contains an interaction. This is potentially misleading; you may wish to consider using the 'by' argument.\n```\n\nThe message warns us that we should not attempt to interpret `ART` and `EduTotal_c` as **main effects** because our model includes an **interaction** that involves these two variables. Indeed, the fourth plot (see @fig-PredictedVocabEduL1) suggests that the more years an L1 speaker spends in formal education, the greater their `Vocab` score; however, because our model includes an interaction effect, the authors of the {visreg} package are warning us that the strength or even the direction of this effect could change depending on individuals' `ART` score.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nvisreg(fit = L1.model.back2, \n       xvar = \"EduTotal_c\",\n       xtrans = function(x) x + median(L1.data$EduTotal), \n       gg = TRUE) +\n  labs(x = \"Years in formal education\",\n       y = \"Predicted Vocab scores\") +\n  theme_bw()    \n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nConditions used in construction of plot\nART: 10.5\nBlocks_c: 0\nAge_c: 0\n```\n\n\n:::\n\n::: {.cell-output-display}\n![Predicted vocabulary scores for L1 speakers as a function of the number of years that they were in formal education (in blue) and partial residuals (grey points).](13_MultipleLinearRegression_files/figure-html/fig-PredictedVocabEduL1-1.png){#fig-PredictedVocabEduL1 fig-alt='Scatter plot showing predicted vocabulary scores versus years in formal education for L1 speakers, with partial residual points and a blue regression line with gray confidence band. The plot shows a positive correlation, with predicted scores increasing from approximately 57 at 10 years of education to approximately 87 at 21 years of education.' width=576}\n:::\n:::\n\n\nAs suggested by the warning message, we can (and should!) visualise interactions like this one using the \"by\" argument.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nvisreg(fit = L1.model.back2, \n       xvar = \"EduTotal_c\", \n       xtrans = function(x) x + median(L1.data$EduTotal), \n       by = \"ART\",\n       gg = TRUE) +\n  labs(x = \"Years in formal education\",\n       y = \"Predicted Vocab scores\") +\n  theme_bw()  \n```\n\n::: {.cell-output-display}\n![Predicted vocabulary scores for L1 speakers as a function of the number of years that they were in formal education and across three different ART scores (in blue) and partial residuals (grey points).](13_MultipleLinearRegression_files/figure-html/fig-PredictedVocabEduLit-1.png){#fig-PredictedVocabEduLit fig-alt='Three-panel plot showing predicted vocabulary scores versus years in formal education for L1 speakers at different ART scores (3, 10, and 31), with partial residual points and blue regression lines with gray confidence bands. The relationship between education and vocabulary scores weakens with higher ART scores.' width=576}\n:::\n:::\n\n\n@fig-PredictedVocabEduLit shows the predicted effect of the number of years in formal education on `Vocab` scores for participants who scored 3, 10, and 31 points on the `ART`. The regression line shows a positive relation between `Vocab` scores and years in formal education for below-average and average `ART` scores, but the regression line is almost flat for above-average `ART` scores. This indicates that, for individuals who score very high on the `ART`, years in education is no longer a useful predictor of their `Vocab` scores.\n\nFinally, we should also report the outcome of our model assumption checks. This is covered in the following section.\n::::\n\n## Checking model assumptions {#sec-ModelAssumptions}\n\nAs we saw in @sec-AssumptionsLR, it is crucial that we check that our models meet the assumptions of linear regression models before we interpret them because, if they don't, our models may be unreliable. In some cases, modelling issues may already be visible from the model summary. Warning signs include very large model residuals, coefficient estimates reported as `NA`, and warning messages stating that the model is \"singular\" or that it has \"failed to converge\".\n\nThese problems can occur for a number of reasons, but most often because the model is too complex given the data available: the sample size may be too small or the data too sparse for certain combinations of predictors (e.g. if you try to enter gender and native language as predictors in a model, but for some languages only female native speakers are represented in the dataset). There are often ways around these issues, but they are beyond the scope of this introductory textbook (see recommended readings below and [next-step resources](https://elenlefoll.github.io/RstatsTextbook/A_FurtherResources.html)).\n\nThe model assumptions for multiple linear regression models are the same as for simple linear regression models (see @sec-AssumptionsLR):\n\n-   Independence of the data points (see @sec-Independence and @sec-IndependenceSLR)\n-   Linear relationships between the predictors (see @sec-Linearity and @sec-LinearitySLR)\n-   Homogeneity of the model residuals (see @sec-Homoscedasticity and @sec-Residuals)\n-   Normality of the model residuals (see @sec-Normality)\n-   No overly influential outliers (see @sec-Linearity)\n\nThere is only one additional assumption that is specific to models that include multiple predictors:\n\n-   No multicollinearity\n\nIn the following, we use the `check_model()` function from the {[performance](https://easystats.github.io/performance)} package [@ludeckePerformancePackageAssessment2021] to check these assumptions graphically. The `check_model()` function also requires the installation of the {[qqplotr](https://aloy.github.io/qqplotr/index.html)} [@almeidaGgplot2CompatibleQuantilequantile2018] and {[see](https://easystats.github.io/see/)} [@ludeckeSeePackageVisualizing2021] packages to work.\n\n::: column-margin\n![Hex sticker of the [{performance}](https://easystats.github.io/performance/) package](images/hex_performance.png){width=\"100\"}\n:::\n\n\n::: {.cell}\n\n```{.r .cell-code}\ninstall.packages(c(\"performance\", \"qqplotr\", \"see\"))\nlibrary(performance)\n```\n:::\n\n\nRunning the function on the saved model object should generate a large figure comprising six plots[^13_multiplelinearregression-2] (see @fig-6plots). In the following, we will learn to interpret them one-by-one.\n\n[^13_multiplelinearregression-2]: If your version of RStudio does not display the six-panelled figure but instead only a white canvas, this is probably because your Plots pane is too small. In this case, you will need to make it as large as possible and then try running the function again. If that doesn't work either, don't worry as we will save and examine individual plots from now on.\n\n\n::: {.cell}\n\n```{.r .cell-code}\ncheck_model(L1.model.back2)\n```\n\n::: {.cell-output-display}\n![Six plots output by the `check_model()` function for assessing key assumptions of linear regression models](13_MultipleLinearRegression_files/figure-html/fig-6plots-1.png){#fig-6plots fig-alt='Six-panel plot for linear regression model assessment. Posterior Predictive Check shows green model-predicted density curve closely overlapping blue observed data density; Linearity plot shows residuals versus fitted values with points scattered around a horizontal dashed reference line. Homogeneity of Variance shows square root of absolute residuals versus fitted values with a green trend line; Influential Observations shows standardized residuals versus leverage. Collinearity shows VIF values for predictors in blue; Normality of Residuals shows standard normal distribution quantiles and sample quantile deviations.' width=768}\n:::\n:::\n\n\nBy default, `check_model()` outputs a single figure that allows us to check the most important model assumptions. This large figure is useful for reporting purposes, but it is rather unwieldy for interpretation. Changing the \"panel\" argument of the `check_model()` function to `FALSE` returns a list of {ggplot} objects that we can save to our local environment as `diagnostic.plots`:\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndiagnostic.plots <- plot(check_model(L1.model.back2, panel = FALSE))\n```\n:::\n\n\nThen we can use the double square bracket operator to display a single diagnostic plot from this saved list:\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndiagnostic.plots[[1]]\n```\n\n::: {.cell-output-display}\n![Comparing the distribution of observed vocabulary scores (green) with data simulated based on model predictions (blue)](13_MultipleLinearRegression_files/figure-html/fig-PosteriorPredictiveCheck-1.png){#fig-PosteriorPredictiveCheck width=576}\n:::\n:::\n\n\nThis first plot (@fig-PosteriorPredictiveCheck) is another way to compare the model's predicted values (represented as here blue distributions) with the real-life (i.e observed) outcome variable (represented here in green). We can see that the center of the distribution of observed `Vocab` scores is slightly shifted to the right compared to most distributions of model-predicted data. That said, the simulated distributions are close to the real distribution and largely follow a similar shape. If they didn't, this would suggest that a linear regression model may not be suitable for our data.\n\nThe second plot (@fig-Linearity) is designed to check the assumption of **linearity**. If the predictors are linearly related, the green reference line should be flat and horizontal. Our reference line is slightly curved, but it remains possible to draw a horizontal line through the grey band, hence we can conclude that the assumption of linearity is not severely violated.\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndiagnostic.plots[[2]]\n```\n\n::: {.cell-output-display}\n![The relationship between model predictions (fitted values) and model residuals](13_MultipleLinearRegression_files/figure-html/fig-Linearity-1.png){#fig-Linearity width=576}\n:::\n:::\n\n\nNote that @fig-Linearity is actually the same kind of plot as @fig-VocabResidual that we generated to check the assumption of equal (or constant) variance, i.e. **homoscedasticity**. Fitted values is another term for predicted values. Thus, in @fig-Linearity, the *x*-axis represents the `Vocab` scores predicted by the model. When the assumption of homoscedasticity is met, the model residuals are randomly distributed above and below 0, i.e. they do not notably increase or decrease as predicted values increase.\n\nThe {performance} package proposes a different kind of diagnostic plot to check the assumption of **homoscedasticity** (see @fig-Homoscedasticity) with the square-root of the absolute standardised residuals on the *y*-axis. A roughly flat and horizontal green reference line indicates homoscedasticity. Again, although the reference line in @fig-Homoscedasticity is by no means perfectly flat, a flat line can be drawn within the grey band, suggesting that the assumption is met.\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndiagnostic.plots[[3]]\n```\n\n::: {.cell-output-display}\n![The relationship between the model predictions (fitted values) and the square root of absolute standardised residuals](13_MultipleLinearRegression_files/figure-html/fig-Homoscedasticity-1.png){#fig-Homoscedasticity width=576}\n:::\n:::\n\n\nThe fourth diagnostic plot (@fig-Influential) helps to detect **outliers** in the data that may have a particularly strong influence on our model. It is based on Cook's distance [see @LevshinaHowlinguisticsData2015: Section 7.2.4; @sondereggerRegressionModelingLinguistic2023: Section 5.7.3]. Any points that fall outside the dashed green lines fall outside Cook's distance and are considered **influential observations**.\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndiagnostic.plots[[4]]\n```\n\n::: {.cell-output-display}\n![The relationship between leverage as estimated using Cook's distance and standardised residuals](13_MultipleLinearRegression_files/figure-html/fig-Influential-1.png){#fig-Influential width=576}\n:::\n:::\n\n\nIn @fig-Influential, no data point falls outside of Cook's distance so we are not concerned about influential observations violating the assumptions of our model. Still, it is interesting to briefly explore the most influential observations, which are labelled by their index number in the dataset. In @fig-Influential, one of these is participant number 21:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nL1.data |> \n  slice(21) |> \n  select(Age, Gender, Occupation, Blocks, EduTotal, ART, Vocab)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n  Age Gender      Occupation Blocks EduTotal ART    Vocab\n1  41      F Senior Lecturer      9       21  43 93.33333\n```\n\n\n:::\n:::\n\n\nAs you can see, this female senior lecturer is rather unusual: she performed below average in the non-verbal IQ test (`Blocks`), yet achieved the second-highest `Vocab` score. She also performed far above average on the author recognition test (`ART`) and reported the longest period in formal education among the L1 participants (`EduTotal`).\n\nIn some cases, it may be justified to remove overly influential outliers; however, this should typically only be done when we are fairly certain that the outliers were caused by a technical error, such as a measuring instrument not functioning properly, or a human error, such as a participant misunderstanding the direction of a response scale. All other outliers may be theoretically interesting: if our aim is to generalise our model to the full population, we must be prepared to include some unusual observations that also belong to that population. In the case of L1 English speakers, this includes people who spent more than 20 years in formal education and are seemingly much more into languages than the kind of abstract puzzles typically found in non-verbal IQ tests!\n\n\n\nThe fifth diagnostic plot output by the `check_model()` function (@fig-Collinearity) serves to check the assumption of a no **multicollinearity**. Multicollinearity, or **high collinearity**, refers to a strong linear dependence between predictors such that they do not contribute unique or independent information to the model. Multicollinearity should not be confused with a strong correlation between two individual predictors as measured using the `cor.test()` function (see @sec-Correlations). What matters here is the association between one or more predictor variables, conditional on the other variables in the model. This is considerably more complex to calculate, but luckily, there are several functions that allow us to do just that in `R`.\n\nThe {performance} package relies on the Variance Inflation Factor (VIF) to quantify collinearity. Typically, VIF scores above 10 are considered to indicate a problematic degree of collinearity between some predictors. @fig-Collinearity indicates that our model does not suffer from multicollinearity.\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndiagnostic.plots[[5]]\n```\n\n::: {.cell-output-display}\n![VIF factor and 95% confidence interval for each predictor in the model](13_MultipleLinearRegression_files/figure-html/fig-Collinearity-1.png){#fig-Collinearity width=576}\n:::\n:::\n\n\nFinally, the sixth plot output by the `check_model()` function serves to check the assumption of the normality of the residuals. In @sec-NormalityResiduals, we achieved this by visualising the distribution of residuals as a density plot (see @fig-VocabResidualDensity). The diagnostic plot presented in @fig-Normality, by contrast, is a so-called Q-Q plot (quantile-quantile plot). These plots are designed to compare the shapes of distributions. If the residuals follow a perfect normal distribution, the points should all fall along the straight reference line (in green).\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndiagnostic.plots[[6]]\n```\n\n::: {.cell-output-display}\n![Q-Q plot](13_MultipleLinearRegression_files/figure-html/fig-Normality-1.png){#fig-Normality width=576}\n:::\n:::\n\n\nIn @fig-Normality, we see that most residuals follow a normal distribution, except some observations at the tails of the distribution. This is fairly typical and, if the other model assumptions are not violated, minor deviations from normality like this are unlikely to be a problem, especially with larger sample sizes.\n\n::: callout-note\nThe `check_model()` vignette provides more detailed information on these diagnostic plots, how to interpret them, and what to do if the assumptions are not met: <https://easystats.github.io/performance/articles/check_model.html>.\n:::\n\n::: {.callout-tip collapse=\"false\"}\n#### Your turn! {.unnumbered}\n\nSo far in this chapter, we have fitted a model of L1 speakers' `Vocab` scores. We have found that participants' print exposure (as measured by the ART), non-verbal intelligence (as measured by the Blocks test), their age, the number of years they were in formal education, and the interaction between ART scores and years in education all contribute to being able to predict how well they performed on the `Vocab` test. The model that we selected as the optimal model (`L1.model.back2`) was able to predict 58% of the variance in `Vocab` scores among L1 speakers.\n\nIn this task, your aim is to find out which predictors and interactions among predictors can be used to predict `Vocab` scores among L2 speakers and to what degree of accuracy. In addition to the predictors that we entered in our full L1 model, you can enter three additional predictors in your model that are relevant to L2 speakers only:\n\n-   Age at which they started living in an English-speaking country (`Arrival`)\n-   Total number of years they have been living in an English-speaking country (`LoR`)\n-   Number of hours they spend reading in English in a typical week (`ReadEng`)\n\nRun the following code to median-center some of these numeric variables in `L2.data`:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nL2.data <- L2.data |> \n  mutate(Blocks_c = Blocks - median(Blocks),\n         Age_c = Age - median(Age),\n         EduTotal_c = EduTotal - median(EduTotal),\n         Arrival_c = Arrival - median(Arrival),\n         LoR_c = LoR - median(LoR))\n```\n:::\n\n\nThen, fit the following multiple linear regression model on the L2 dataset and examine the model summary:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nL2.model <- lm(formula = Vocab ~ ART + Blocks_c + Age_c + EduTotal_c + Arrival_c + LoR_c + ReadEng + ART:EduTotal_c + ART:ReadEng + EduTotal_c:ReadEng + Arrival_c:Age_c + LoR_c:Arrival_c,\n             data = L2.data)\n\nsummary(L2.model)\n```\n:::\n\n\n[**Q13.10**]{style=\"color:green;\"} How many interaction terms contribute to the predictions made by `L2.model`?\n\n\n::: {.cell}\n::: {.cell-output-display}\n\n```{=html}\n<form name=\"form_Q13_10\" onsubmit=\"return validate_form_Q13_10()\" method=\"post\">\n<select name=\"answer_Q13_10\">\n<option>0</option>\n<option>1</option>\n<option>2</option>\n<option>3</option>\n<option>4</option>\n<option>5</option>\n</select>\n<input type=\"submit\" value=\"Check answer\"/>\n<div id=\"result_Q13_10\"></div>\n</form>\n<script>function validate_form_Q13_10() {var x, text; var x = document.forms['form_Q13_10']['answer_Q13_10'].value;if (x == '5'){text = 'That’s right. The model formula includes five interactions and they all contribute to the model predictions. That said, their coefficient estimates are very small and none of their contributions to the model are statistically significantly different from zero.';} else {text = 'No, that’s incorrect.';} document.getElementById('result_Q13_10').innerHTML = text; evaluate_final_score(); return false;}function evaluate_final_score(){\n         element = document.getElementById('checkdown_final_score');\n         if(element === null){return false;} else {var element, text, res1, res2, res3, res4, res5, res6, res7, res8, res9, res10;res1 = document.getElementById('result_Q13_1').innerText == 'That’s right, well done!'; res2 = document.getElementById('result_Q13_2').innerText == 'Excellent!'; res3 = document.getElementById('result_Q13_3').innerText == 'Absolutely, well done!'; res4 = document.getElementById('result_Q13_4').innerText == 'That’s right, well done!'; res5 = document.getElementById('result_Q13_5').innerText == 'That’s right! Note that entering this predictor in the model changes the relative importance of all the other predictors, too.'; res6 = document.getElementById('result_Q13_6').innerText == 'That’s right, well done!'; res7 = document.getElementById('result_Q13_7').innerText == 'That’s right. Now fit the model and check the model summary to see if this interaction makes a significant contribution to the model!'; res8 = document.getElementById('result_Q13_8').innerText == 'That’s right. The p-value associated with the interaction coefficient is greater than 0.05.'; res9 = document.getElementById('result_Q13_9').innerText == 'That’s right, well done! We can tell from the plot that years in education is a statistically significant predictor because, in both the L1 and the L2 panel, it is impossible to draw a horizontal line that stays within the confidence band. A horizontal line would represent the null hypothesis of no association and, if we cannot draw it within the confidence band, this means that we can reject the null hypothesis. Concerning the statistical significance of the interaction, however, it is not obvious that the slopes of the two lines differ much. All the predicted Vocab scores for L2 speakers are lower than for L1 speakers, but the increase associated with more years of formal education, as represented by the gradients of the two slopes, look about the same. This is why the interaction coefficient turned out not to be statistically significant.'; res10 = document.getElementById('result_Q13_10').innerText == 'That’s right. The model formula includes five interactions and they all contribute to the model predictions. That said, their coefficient estimates are very small and none of their contributions to the model are statistically significantly different from zero.';text = res1 + res2 + res3 + res4 + res5 + res6 + res7 + res8 + res9 + res10;element.innerHTML = text;\n         return false;\n         }}</script>\n```\n\n:::\n\n::: {.cell-output-display}\n\n```{=html}\n<div id=\"hint_71048\" onclick=\"return show_hint_71048()\">🐭 Click on the mouse for a hint.</div>\n<div id=\"result_71048\" onclick=\"return show_hint_71048()\"></div>\n<script>function show_hint_71048(){var x = document.getElementById('result_71048').innerHTML; if(!x){document.getElementById('result_71048').innerHTML = 'By definition, all of the interactions entered in a model make a contribution, however small, to the model. Note that the question here is not about whether these contributions are statistically significantly different from zero.';} else {document.getElementById('result_71048').innerHTML = '';}}</script>\n```\n\n:::\n:::\n\n\n[**Q13.11**]{style=\"color:green;\"} Use the `check_model()` function to visually check whether `L2.model` meets the most important assumptions of multiple linear regression models. Which assumption(s) are obviously violated?\n\n\n::: {.cell}\n::: {.cell-output-display}\n\n```{=html}\n<form name=\"form_Q13_11\" onsubmit=\"return validate_form_Q13_11()\" method=\"post\">\n<label>\n<input type=\"checkbox\" id=\"answer_Q13_11_1\" value=\"Independence of the data points\"/>\nIndependence of the data points\n</label>\n<br/>\n<label>\n<input type=\"checkbox\" id=\"answer_Q13_11_2\" value=\"Linear relationships between the predictors\"/>\nLinear relationships between the predictors\n</label>\n<br/>\n<label>\n<input type=\"checkbox\" id=\"answer_Q13_11_3\" value=\"Homogeneity of the model residuals\"/>\nHomogeneity of the model residuals\n</label>\n<br/>\n<label>\n<input type=\"checkbox\" id=\"answer_Q13_11_4\" value=\"Normality of the model residuals\"/>\nNormality of the model residuals\n</label>\n<br/>\n<label>\n<input type=\"checkbox\" id=\"answer_Q13_11_5\" value=\"No overly influential outliers\"/>\nNo overly influential outliers\n</label>\n<br/>\n<label>\n<input type=\"checkbox\" id=\"answer_Q13_11_6\" value=\"No multicollinearity\"/>\nNo multicollinearity\n</label>\n<br/>\n<label>\n<input type=\"checkbox\" id=\"answer_Q13_11_7\" value=\"None of these assumptions\"/>\nNone of these assumptions\n</label>\n<br/>\n<input type=\"submit\" value=\"Check answer\"/>\n<div id=\"result_Q13_11\"></div>\n</form>\n<script>function validate_form_Q13_11() {var text; var x1 = document.getElementById('answer_Q13_11_1'); var x2 = document.getElementById('answer_Q13_11_2'); var x3 = document.getElementById('answer_Q13_11_3'); var x4 = document.getElementById('answer_Q13_11_4'); var x5 = document.getElementById('answer_Q13_11_5'); var x6 = document.getElementById('answer_Q13_11_6'); var x7 = document.getElementById('answer_Q13_11_7'); if (x1.checked == false&x2.checked == false&x3.checked == false&x4.checked == false&x5.checked == false&x6.checked == true&x7.checked == false){text = 'Yes, well done!';} else {text = 'No, not quite.';} document.getElementById('result_Q13_11').innerHTML = text; evaluate_final_score(); return false;}function evaluate_final_score(){\n         element = document.getElementById('checkdown_final_score');\n         if(element === null){return false;} else {var element, text, res1, res2, res3, res4, res5, res6, res7, res8, res9, res10, res11;res1 = document.getElementById('result_Q13_1').innerText == 'That’s right, well done!'; res2 = document.getElementById('result_Q13_2').innerText == 'Excellent!'; res3 = document.getElementById('result_Q13_3').innerText == 'Absolutely, well done!'; res4 = document.getElementById('result_Q13_4').innerText == 'That’s right, well done!'; res5 = document.getElementById('result_Q13_5').innerText == 'That’s right! Note that entering this predictor in the model changes the relative importance of all the other predictors, too.'; res6 = document.getElementById('result_Q13_6').innerText == 'That’s right, well done!'; res7 = document.getElementById('result_Q13_7').innerText == 'That’s right. Now fit the model and check the model summary to see if this interaction makes a significant contribution to the model!'; res8 = document.getElementById('result_Q13_8').innerText == 'That’s right. The p-value associated with the interaction coefficient is greater than 0.05.'; res9 = document.getElementById('result_Q13_9').innerText == 'That’s right, well done! We can tell from the plot that years in education is a statistically significant predictor because, in both the L1 and the L2 panel, it is impossible to draw a horizontal line that stays within the confidence band. A horizontal line would represent the null hypothesis of no association and, if we cannot draw it within the confidence band, this means that we can reject the null hypothesis. Concerning the statistical significance of the interaction, however, it is not obvious that the slopes of the two lines differ much. All the predicted Vocab scores for L2 speakers are lower than for L1 speakers, but the increase associated with more years of formal education, as represented by the gradients of the two slopes, look about the same. This is why the interaction coefficient turned out not to be statistically significant.'; res10 = document.getElementById('result_Q13_10').innerText == 'That’s right. The model formula includes five interactions and they all contribute to the model predictions. That said, their coefficient estimates are very small and none of their contributions to the model are statistically significantly different from zero.'; res11 = document.getElementById('result_Q13_11').innerText == 'Yes, well done!';text = res1 + res2 + res3 + res4 + res5 + res6 + res7 + res8 + res9 + res10 + res11;element.innerHTML = text;\n         return false;\n         }}</script>\n```\n\n:::\n\n::: {.cell-output-display}\n\n```{=html}\n<div id=\"hint_96905\" onclick=\"return show_hint_96905()\">🐭 Click on the mouse for a hint.</div>\n<div id=\"result_96905\" onclick=\"return show_hint_96905()\"></div>\n<script>function show_hint_96905(){var x = document.getElementById('result_96905').innerHTML; if(!x){document.getElementById('result_96905').innerHTML = 'From the six diagnostic plots produced by the check_model() function, it transpires that one of these assumptions is severely violated.';} else {document.getElementById('result_96905').innerHTML = '';}}</script>\n```\n\n:::\n:::\n\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\" code-summary=\"Show sample code to answer Q13.11.\"}\ndiagnostic.plots.L2 <- plot(check_model(L2.model, panel = FALSE))\n\ndiagnostic.plots.L2[[1]] # No issues here.\n\ndiagnostic.plots.L2[[2]] # Also no issues here.\n\ndiagnostic.plots.L2[[3]] # Nothing major to worry about: the reference line is not perfectly flat, but it's not far off.\n\ndiagnostic.plots.L2[[4]] # No observation points appear to have an overly large influence on the model\n\ndiagnostic.plots.L2[[5]] # Here we have three coefficients with VIF scores > 10. This is problematic!\n\ndiagnostic.plots.L2[[6]] # The residuals are not normally distributed, but the largest deviation is at lowest end of the distribution which is not terribly unusual.\n```\n:::\n\n\nWe can display the exact VIF values of a model using the `vif()` function from the [{car}](https://www.john-fox.ca/Companion/index.html) package [@foxCompanionAppliedRegression2019]:\n\n\n::: {.cell}\n\n```{.r .cell-code}\ninstall.packages(\"car\")\nlibrary(car)\n\nvif(L2.model)\n```\n:::\n\n\n\n::: {.cell}\n::: {.cell-output .cell-output-stdout}\n\n```\n               ART           Blocks_c              Age_c         EduTotal_c \n          5.987790           1.216035          25.347847           5.490682 \n         Arrival_c              LoR_c            ReadEng     ART:EduTotal_c \n         23.746278          11.102277           3.661388           2.237536 \n       ART:ReadEng EduTotal_c:ReadEng    Age_c:Arrival_c    Arrival_c:LoR_c \n          8.550867           4.412402           3.349661           1.398937 \n```\n\n\n:::\n:::\n\n\nFrom this list of VIF values, we can see that three predictors display high collinearity: `Age_c`, `Arrival_c`, and `LoR_c`. This makes sense because, for most L2 participants recruited in the UK, if we know how old they were when they arrived in the UK (`Arrival`), and their length of residence in the country in years (`LoR`), then we can probably almost predict their age (`Age`) to a high degree of accuracy. We can easily check this hypothesis in a random sample of six participants from our `L2.data`:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nL2.data |> \n  select(Arrival, LoR, Age) |> \n  slice_sample(n = 6)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n  Arrival LoR Age\n1      26   3  29\n2      32   6  38\n3      22   5  28\n4      17   3  20\n5      23   4  27\n6      16  14  30\n```\n\n\n:::\n:::\n\n\nAs you can see, in most cases, participants' age is equal to their age when they first arrived in the country plus the number of years they've been living there since. This is why `Age` and the combination of the predictors `Arrival` and `LoR` are almost perfectly correlated:\n\n\n::: {.cell}\n\n```{.r .cell-code}\ncor(L2.data$Age, (L2.data$Arrival + L2.data$LoR))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 0.9768833\n```\n\n\n:::\n:::\n\n\nTo remedy this, we must remove one of these three predictors from our model. Fit a new model that does *not* include participants' age when they first arrived in the UK (`Arrival`). Save this new model as `L2.model.b`. Check that it now meets all the model assumptions and then examine its summary.\n\n[**Q13.12**]{style=\"color:green;\"} Adjusted for the number of predictors entered into `L2.model.b`, what percentage of the variance in `Vocab` scores in the L2 dataset does this model accurately predict?\n\n\n::: {.cell}\n::: {.cell-output-display}\n\n```{=html}\n<form name=\"form_Q13_12\" onsubmit=\"return validate_form_Q13_12()\" method=\"post\">\n<select name=\"answer_Q13_12\">\n<option>Practically 0%</option>\n<option>About 3%</option>\n<option>About 15%</option>\n<option>About 20%</option>\n<option>About 22%</option>\n<option>About 31%</option>\n<option>About 57%</option>\n</select>\n<input type=\"submit\" value=\"Check answer\"/>\n<div id=\"result_Q13_12\"></div>\n</form>\n<script>function validate_form_Q13_12() {var x, text; var x = document.forms['form_Q13_12']['answer_Q13_12'].value;if (x == 'About 20%'){text = 'Yes, well done!';} else {text = 'No, this is not the correct value.';} document.getElementById('result_Q13_12').innerHTML = text; evaluate_final_score(); return false;}function evaluate_final_score(){\n         element = document.getElementById('checkdown_final_score');\n         if(element === null){return false;} else {var element, text, res1, res2, res3, res4, res5, res6, res7, res8, res9, res10, res11, res12;res1 = document.getElementById('result_Q13_1').innerText == 'That’s right, well done!'; res2 = document.getElementById('result_Q13_2').innerText == 'Excellent!'; res3 = document.getElementById('result_Q13_3').innerText == 'Absolutely, well done!'; res4 = document.getElementById('result_Q13_4').innerText == 'That’s right, well done!'; res5 = document.getElementById('result_Q13_5').innerText == 'That’s right! Note that entering this predictor in the model changes the relative importance of all the other predictors, too.'; res6 = document.getElementById('result_Q13_6').innerText == 'That’s right, well done!'; res7 = document.getElementById('result_Q13_7').innerText == 'That’s right. Now fit the model and check the model summary to see if this interaction makes a significant contribution to the model!'; res8 = document.getElementById('result_Q13_8').innerText == 'That’s right. The p-value associated with the interaction coefficient is greater than 0.05.'; res9 = document.getElementById('result_Q13_9').innerText == 'That’s right, well done! We can tell from the plot that years in education is a statistically significant predictor because, in both the L1 and the L2 panel, it is impossible to draw a horizontal line that stays within the confidence band. A horizontal line would represent the null hypothesis of no association and, if we cannot draw it within the confidence band, this means that we can reject the null hypothesis. Concerning the statistical significance of the interaction, however, it is not obvious that the slopes of the two lines differ much. All the predicted Vocab scores for L2 speakers are lower than for L1 speakers, but the increase associated with more years of formal education, as represented by the gradients of the two slopes, look about the same. This is why the interaction coefficient turned out not to be statistically significant.'; res10 = document.getElementById('result_Q13_10').innerText == 'That’s right. The model formula includes five interactions and they all contribute to the model predictions. That said, their coefficient estimates are very small and none of their contributions to the model are statistically significantly different from zero.'; res11 = document.getElementById('result_Q13_11').innerText == 'Yes, well done!'; res12 = document.getElementById('result_Q13_12').innerText == 'Yes, well done!';text = res1 + res2 + res3 + res4 + res5 + res6 + res7 + res8 + res9 + res10 + res11 + res12;element.innerHTML = text;\n         return false;\n         }}</script>\n```\n\n:::\n:::\n\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\" code-summary=\"Show sample code to answer Q13.12.\"}\nL2.model.b <- lm(formula = Vocab ~ ART + Blocks_c + Age_c + EduTotal_c + LoR_c + ReadEng + ART:EduTotal_c + ART:ReadEng + EduTotal_c:ReadEng,\n             data = L2.data)\n\ncheck_model(L2.model.b) # Now all looking much better than earlier!\n\nsummary(L2.model.b) # Adjusted R-squared:  0.2027\n```\n:::\n\n\n[**Q13.13**]{style=\"color:green;\"} Which main-effect predictor(s) make a statistically significant contribution to `L2.model.b` at α = 0.05?\n\n\n::: {.cell}\n::: {.cell-output-display}\n\n```{=html}\n<form name=\"form_Q13_13\" onsubmit=\"return validate_form_Q13_13()\" method=\"post\">\n<label>\n<input type=\"checkbox\" id=\"answer_Q13_13_1\" value=\"ART\"/>\nART\n</label>\n<br/>\n<label>\n<input type=\"checkbox\" id=\"answer_Q13_13_2\" value=\"Blocks_c\"/>\nBlocks_c\n</label>\n<br/>\n<label>\n<input type=\"checkbox\" id=\"answer_Q13_13_3\" value=\"Age_c\"/>\nAge_c\n</label>\n<br/>\n<label>\n<input type=\"checkbox\" id=\"answer_Q13_13_4\" value=\"EduTotal_c\"/>\nEduTotal_c\n</label>\n<br/>\n<label>\n<input type=\"checkbox\" id=\"answer_Q13_13_5\" value=\"Arrival_c\"/>\nArrival_c\n</label>\n<br/>\n<label>\n<input type=\"checkbox\" id=\"answer_Q13_13_6\" value=\"LoR_c\"/>\nLoR_c\n</label>\n<br/>\n<label>\n<input type=\"checkbox\" id=\"answer_Q13_13_7\" value=\"ReadEng\"/>\nReadEng\n</label>\n<br/>\n<input type=\"submit\" value=\"Check answer\"/>\n<div id=\"result_Q13_13\"></div>\n</form>\n<script>function validate_form_Q13_13() {var text; var x1 = document.getElementById('answer_Q13_13_1'); var x2 = document.getElementById('answer_Q13_13_2'); var x3 = document.getElementById('answer_Q13_13_3'); var x4 = document.getElementById('answer_Q13_13_4'); var x5 = document.getElementById('answer_Q13_13_5'); var x6 = document.getElementById('answer_Q13_13_6'); var x7 = document.getElementById('answer_Q13_13_7'); if (x1.checked == false&x2.checked == false&x3.checked == false&x4.checked == false&x5.checked == false&x6.checked == false&x7.checked == true){text = 'That’s right, only one main-effect predictor makes a statistically significant contribution to this model of receptive vocabularly knowledge among L2 speakers of English.';} else {text = 'Humm, not quite. Which coefficient estimate(s) are associated with p-values that are lower than 0.05?';} document.getElementById('result_Q13_13').innerHTML = text; evaluate_final_score(); return false;}function evaluate_final_score(){\n         element = document.getElementById('checkdown_final_score');\n         if(element === null){return false;} else {var element, text, res1, res2, res3, res4, res5, res6, res7, res8, res9, res10, res11, res12, res13;res1 = document.getElementById('result_Q13_1').innerText == 'That’s right, well done!'; res2 = document.getElementById('result_Q13_2').innerText == 'Excellent!'; res3 = document.getElementById('result_Q13_3').innerText == 'Absolutely, well done!'; res4 = document.getElementById('result_Q13_4').innerText == 'That’s right, well done!'; res5 = document.getElementById('result_Q13_5').innerText == 'That’s right! Note that entering this predictor in the model changes the relative importance of all the other predictors, too.'; res6 = document.getElementById('result_Q13_6').innerText == 'That’s right, well done!'; res7 = document.getElementById('result_Q13_7').innerText == 'That’s right. Now fit the model and check the model summary to see if this interaction makes a significant contribution to the model!'; res8 = document.getElementById('result_Q13_8').innerText == 'That’s right. The p-value associated with the interaction coefficient is greater than 0.05.'; res9 = document.getElementById('result_Q13_9').innerText == 'That’s right, well done! We can tell from the plot that years in education is a statistically significant predictor because, in both the L1 and the L2 panel, it is impossible to draw a horizontal line that stays within the confidence band. A horizontal line would represent the null hypothesis of no association and, if we cannot draw it within the confidence band, this means that we can reject the null hypothesis. Concerning the statistical significance of the interaction, however, it is not obvious that the slopes of the two lines differ much. All the predicted Vocab scores for L2 speakers are lower than for L1 speakers, but the increase associated with more years of formal education, as represented by the gradients of the two slopes, look about the same. This is why the interaction coefficient turned out not to be statistically significant.'; res10 = document.getElementById('result_Q13_10').innerText == 'That’s right. The model formula includes five interactions and they all contribute to the model predictions. That said, their coefficient estimates are very small and none of their contributions to the model are statistically significantly different from zero.'; res11 = document.getElementById('result_Q13_11').innerText == 'Yes, well done!'; res12 = document.getElementById('result_Q13_12').innerText == 'Yes, well done!'; res13 = document.getElementById('result_Q13_13').innerText == 'That’s right, only one main-effect predictor makes a statistically significant contribution to this model of receptive vocabularly knowledge among L2 speakers of English.';text = res1 + res2 + res3 + res4 + res5 + res6 + res7 + res8 + res9 + res10 + res11 + res12 + res13;element.innerHTML = text;\n         return false;\n         }}</script>\n```\n\n:::\n:::\n\n\n[**Q13.14**]{style=\"color:green;\"} Does the model's coefficient estimate for `ReadEng` make intuitive sense?\n\n\n::: {.cell}\n::: {.cell-output-display}\n\n```{=html}\n<form name=\"form_Q13_14\" onsubmit=\"return validate_form_Q13_14()\" method=\"post\">\n<label>\n<input type=\"radio\" name=\"answer_Q13_14\" id=\"answer_Q13_14_1\" value=\"Yes, the ReadEng coefficient is positive, which means that the more time L2 speakers regularly spend reading in English, the higher their predicted receptive English vocabulary test scores.\"/>\nYes, the ReadEng coefficient is positive, which means that the more time L2 speakers regularly spend reading in English, the higher their predicted receptive English vocabulary test scores.\n</label>\n<br/>\n<label>\n<input type=\"radio\" name=\"answer_Q13_14\" id=\"answer_Q13_14_2\" value=\"No, the ReadEng coefficient is larger than all other coefficients, which violates the model assumption of no overly influential outliers.\"/>\nNo, the ReadEng coefficient is larger than all other coefficients, which violates the model assumption of no overly influential outliers.\n</label>\n<br/>\n<input type=\"submit\" value=\"Check answer\"/>\n<div id=\"result_Q13_14\"></div>\n</form>\n<script>function validate_form_Q13_14() {var x, text; var x = document.forms['form_Q13_14']['answer_Q13_14'].value;if (x == 'Yes, the ReadEng coefficient is positive, which means that the more time L2 speakers regularly spend reading in English, the higher their predicted receptive English vocabulary test scores.'){text = 'That’s right: Reading is a great way to learn new vocabularly! And reading a statistics textbook is therefore doubly beneficial: you get to learn about quantitative data analysis <em>and</em> expand your English vocabulary! 🤓';} else {text = 'No, only individual observations (i.e. data points) can be considered outliers, not coefficient estimates.';} document.getElementById('result_Q13_14').innerHTML = text; evaluate_final_score(); return false;}function evaluate_final_score(){\n         element = document.getElementById('checkdown_final_score');\n         if(element === null){return false;} else {var element, text, res1, res2, res3, res4, res5, res6, res7, res8, res9, res10, res11, res12, res13, res14;res1 = document.getElementById('result_Q13_1').innerText == 'That’s right, well done!'; res2 = document.getElementById('result_Q13_2').innerText == 'Excellent!'; res3 = document.getElementById('result_Q13_3').innerText == 'Absolutely, well done!'; res4 = document.getElementById('result_Q13_4').innerText == 'That’s right, well done!'; res5 = document.getElementById('result_Q13_5').innerText == 'That’s right! Note that entering this predictor in the model changes the relative importance of all the other predictors, too.'; res6 = document.getElementById('result_Q13_6').innerText == 'That’s right, well done!'; res7 = document.getElementById('result_Q13_7').innerText == 'That’s right. Now fit the model and check the model summary to see if this interaction makes a significant contribution to the model!'; res8 = document.getElementById('result_Q13_8').innerText == 'That’s right. The p-value associated with the interaction coefficient is greater than 0.05.'; res9 = document.getElementById('result_Q13_9').innerText == 'That’s right, well done! We can tell from the plot that years in education is a statistically significant predictor because, in both the L1 and the L2 panel, it is impossible to draw a horizontal line that stays within the confidence band. A horizontal line would represent the null hypothesis of no association and, if we cannot draw it within the confidence band, this means that we can reject the null hypothesis. Concerning the statistical significance of the interaction, however, it is not obvious that the slopes of the two lines differ much. All the predicted Vocab scores for L2 speakers are lower than for L1 speakers, but the increase associated with more years of formal education, as represented by the gradients of the two slopes, look about the same. This is why the interaction coefficient turned out not to be statistically significant.'; res10 = document.getElementById('result_Q13_10').innerText == 'That’s right. The model formula includes five interactions and they all contribute to the model predictions. That said, their coefficient estimates are very small and none of their contributions to the model are statistically significantly different from zero.'; res11 = document.getElementById('result_Q13_11').innerText == 'Yes, well done!'; res12 = document.getElementById('result_Q13_12').innerText == 'Yes, well done!'; res13 = document.getElementById('result_Q13_13').innerText == 'That’s right, only one main-effect predictor makes a statistically significant contribution to this model of receptive vocabularly knowledge among L2 speakers of English.'; res14 = document.getElementById('result_Q13_14').innerText == 'That’s right: Reading is a great way to learn new vocabularly! And reading a statistics textbook is therefore doubly beneficial: you get to learn about quantitative data analysis and expand your English vocabulary! 🤓';text = res1 + res2 + res3 + res4 + res5 + res6 + res7 + res8 + res9 + res10 + res11 + res12 + res13 + res14;element.innerHTML = text;\n         return false;\n         }}</script>\n```\n\n:::\n:::\n\n\n[**Q13.15**]{style=\"color:green;\"} Which interaction effect(s) make a statistically significant contribution to `L2.model.b` at α = 0.05?\n\n\n::: {.cell}\n::: {.cell-output-display}\n\n```{=html}\n<form name=\"form_Q13_15\" onsubmit=\"return validate_form_Q13_15()\" method=\"post\">\n<label>\n<input type=\"checkbox\" id=\"answer_Q13_15_1\" value=\"ART:EduTotal_c\"/>\nART:EduTotal_c\n</label>\n<br/>\n<label>\n<input type=\"checkbox\" id=\"answer_Q13_15_2\" value=\"ART:ReadEng\"/>\nART:ReadEng\n</label>\n<br/>\n<label>\n<input type=\"checkbox\" id=\"answer_Q13_15_3\" value=\"EduTotal_c:ReadEng\"/>\nEduTotal_c:ReadEng\n</label>\n<br/>\n<label>\n<input type=\"checkbox\" id=\"answer_Q13_15_4\" value=\"None of them\"/>\nNone of them\n</label>\n<br/>\n<input type=\"submit\" value=\"Check answer\"/>\n<div id=\"result_Q13_15\"></div>\n</form>\n<script>function validate_form_Q13_15() {var text; var x1 = document.getElementById('answer_Q13_15_1'); var x2 = document.getElementById('answer_Q13_15_2'); var x3 = document.getElementById('answer_Q13_15_3'); var x4 = document.getElementById('answer_Q13_15_4'); if (x1.checked == false&x2.checked == false&x3.checked == false&x4.checked == true){text = 'That’s right, none of them make a statistically significant contribution to the model. However, that doesn’t necessarily mean that their coefficients do not point to any real associations: we may not have enough data to observe any statistically significant interactions.';} else {text = 'Hummm, are you sure? Check the model summary again.';} document.getElementById('result_Q13_15').innerHTML = text; evaluate_final_score(); return false;}function evaluate_final_score(){\n         element = document.getElementById('checkdown_final_score');\n         if(element === null){return false;} else {var element, text, res1, res2, res3, res4, res5, res6, res7, res8, res9, res10, res11, res12, res13, res14, res15;res1 = document.getElementById('result_Q13_1').innerText == 'That’s right, well done!'; res2 = document.getElementById('result_Q13_2').innerText == 'Excellent!'; res3 = document.getElementById('result_Q13_3').innerText == 'Absolutely, well done!'; res4 = document.getElementById('result_Q13_4').innerText == 'That’s right, well done!'; res5 = document.getElementById('result_Q13_5').innerText == 'That’s right! Note that entering this predictor in the model changes the relative importance of all the other predictors, too.'; res6 = document.getElementById('result_Q13_6').innerText == 'That’s right, well done!'; res7 = document.getElementById('result_Q13_7').innerText == 'That’s right. Now fit the model and check the model summary to see if this interaction makes a significant contribution to the model!'; res8 = document.getElementById('result_Q13_8').innerText == 'That’s right. The p-value associated with the interaction coefficient is greater than 0.05.'; res9 = document.getElementById('result_Q13_9').innerText == 'That’s right, well done! We can tell from the plot that years in education is a statistically significant predictor because, in both the L1 and the L2 panel, it is impossible to draw a horizontal line that stays within the confidence band. A horizontal line would represent the null hypothesis of no association and, if we cannot draw it within the confidence band, this means that we can reject the null hypothesis. Concerning the statistical significance of the interaction, however, it is not obvious that the slopes of the two lines differ much. All the predicted Vocab scores for L2 speakers are lower than for L1 speakers, but the increase associated with more years of formal education, as represented by the gradients of the two slopes, look about the same. This is why the interaction coefficient turned out not to be statistically significant.'; res10 = document.getElementById('result_Q13_10').innerText == 'That’s right. The model formula includes five interactions and they all contribute to the model predictions. That said, their coefficient estimates are very small and none of their contributions to the model are statistically significantly different from zero.'; res11 = document.getElementById('result_Q13_11').innerText == 'Yes, well done!'; res12 = document.getElementById('result_Q13_12').innerText == 'Yes, well done!'; res13 = document.getElementById('result_Q13_13').innerText == 'That’s right, only one main-effect predictor makes a statistically significant contribution to this model of receptive vocabularly knowledge among L2 speakers of English.'; res14 = document.getElementById('result_Q13_14').innerText == 'That’s right: Reading is a great way to learn new vocabularly! And reading a statistics textbook is therefore doubly beneficial: you get to learn about quantitative data analysis and expand your English vocabulary! 🤓'; res15 = document.getElementById('result_Q13_15').innerText == 'That’s right, none of them make a statistically significant contribution to the model. However, that doesn’t necessarily mean that their coefficients do not point to any real associations: we may not have enough data to observe any statistically significant interactions.';text = res1 + res2 + res3 + res4 + res5 + res6 + res7 + res8 + res9 + res10 + res11 + res12 + res13 + res14 + res15;element.innerHTML = text;\n         return false;\n         }}</script>\n```\n\n:::\n:::\n\n\n[**Q13.16**]{style=\"color:green;\"} Use the {visreg} library to visualise the model's predicted `Vocab` scores (on the *y*-axis) as a function of all possible `ReadEng` values (on the *x*-axis) and subdivide the figure into three panels corresponding to low, mid-level, and high ART scores. Which arguments do you have to use inside the `visreg()` function to achieve this?\n\n\n::: {.cell}\n::: {.cell-output-display}\n\n```{=html}\n<form name=\"form_Q13_16\" onsubmit=\"return validate_form_Q13_16()\" method=\"post\">\n<label>\n<input type=\"checkbox\" id=\"answer_Q13_16_1\" value=\"fit = L2.model.b\"/>\nfit = L2.model.b\n</label>\n<br/>\n<label>\n<input type=\"checkbox\" id=\"answer_Q13_16_2\" value=\"xvar = &quot;ART&quot;\"/>\nxvar = \"ART\"\n</label>\n<br/>\n<label>\n<input type=\"checkbox\" id=\"answer_Q13_16_3\" value=\"xvar = &quot;ReadEng&quot;\"/>\nxvar = \"ReadEng\"\n</label>\n<br/>\n<label>\n<input type=\"checkbox\" id=\"answer_Q13_16_4\" value=\"xtrans = function(x) x + median(L2.data$ReadEng)\"/>\nxtrans = function(x) x + median(L2.data$ReadEng)\n</label>\n<br/>\n<label>\n<input type=\"checkbox\" id=\"answer_Q13_16_5\" value=\"by = &quot;ReadEng&quot;\"/>\nby = \"ReadEng\"\n</label>\n<br/>\n<label>\n<input type=\"checkbox\" id=\"answer_Q13_16_6\" value=\"by = &quot;ART&quot;\"/>\nby = \"ART\"\n</label>\n<br/>\n<input type=\"submit\" value=\"Check answer\"/>\n<div id=\"result_Q13_16\"></div>\n</form>\n<script>function validate_form_Q13_16() {var text; var x1 = document.getElementById('answer_Q13_16_1'); var x2 = document.getElementById('answer_Q13_16_2'); var x3 = document.getElementById('answer_Q13_16_3'); var x4 = document.getElementById('answer_Q13_16_4'); var x5 = document.getElementById('answer_Q13_16_5'); var x6 = document.getElementById('answer_Q13_16_6'); if (x1.checked == true&x2.checked == false&x3.checked == true&x4.checked == false&x5.checked == false&x6.checked == true){text = 'Yes, well done! Now you can focus on interpreting your model’s predicted values (the blue lines) and examine the partial residuals (the grey points that represent the variance in Vocab scores that is not accounted for by this model). It should be clear from this plot that this L2 model is not able to predict <code>Vocab</code> scores as well as our L1 model could (hence the considerably lower adjusted coefficient of determination (R-squared). Is this because L2 learners are more diverse and therefore less predictable? Or is it (also) because the sample size is smaller (67 instead of 90 participants)? We cannot tell from this data alone. What is certain is that more research is needed to answer these fascinating questions!';} else {text = 'No, that won’t quite do.';} document.getElementById('result_Q13_16').innerHTML = text; evaluate_final_score(); return false;}function evaluate_final_score(){\n         element = document.getElementById('checkdown_final_score');\n         if(element === null){return false;} else {var element, text, res1, res2, res3, res4, res5, res6, res7, res8, res9, res10, res11, res12, res13, res14, res15, res16;res1 = document.getElementById('result_Q13_1').innerText == 'That’s right, well done!'; res2 = document.getElementById('result_Q13_2').innerText == 'Excellent!'; res3 = document.getElementById('result_Q13_3').innerText == 'Absolutely, well done!'; res4 = document.getElementById('result_Q13_4').innerText == 'That’s right, well done!'; res5 = document.getElementById('result_Q13_5').innerText == 'That’s right! Note that entering this predictor in the model changes the relative importance of all the other predictors, too.'; res6 = document.getElementById('result_Q13_6').innerText == 'That’s right, well done!'; res7 = document.getElementById('result_Q13_7').innerText == 'That’s right. Now fit the model and check the model summary to see if this interaction makes a significant contribution to the model!'; res8 = document.getElementById('result_Q13_8').innerText == 'That’s right. The p-value associated with the interaction coefficient is greater than 0.05.'; res9 = document.getElementById('result_Q13_9').innerText == 'That’s right, well done! We can tell from the plot that years in education is a statistically significant predictor because, in both the L1 and the L2 panel, it is impossible to draw a horizontal line that stays within the confidence band. A horizontal line would represent the null hypothesis of no association and, if we cannot draw it within the confidence band, this means that we can reject the null hypothesis. Concerning the statistical significance of the interaction, however, it is not obvious that the slopes of the two lines differ much. All the predicted Vocab scores for L2 speakers are lower than for L1 speakers, but the increase associated with more years of formal education, as represented by the gradients of the two slopes, look about the same. This is why the interaction coefficient turned out not to be statistically significant.'; res10 = document.getElementById('result_Q13_10').innerText == 'That’s right. The model formula includes five interactions and they all contribute to the model predictions. That said, their coefficient estimates are very small and none of their contributions to the model are statistically significantly different from zero.'; res11 = document.getElementById('result_Q13_11').innerText == 'Yes, well done!'; res12 = document.getElementById('result_Q13_12').innerText == 'Yes, well done!'; res13 = document.getElementById('result_Q13_13').innerText == 'That’s right, only one main-effect predictor makes a statistically significant contribution to this model of receptive vocabularly knowledge among L2 speakers of English.'; res14 = document.getElementById('result_Q13_14').innerText == 'That’s right: Reading is a great way to learn new vocabularly! And reading a statistics textbook is therefore doubly beneficial: you get to learn about quantitative data analysis and expand your English vocabulary! 🤓'; res15 = document.getElementById('result_Q13_15').innerText == 'That’s right, none of them make a statistically significant contribution to the model. However, that doesn’t necessarily mean that their coefficients do not point to any real associations: we may not have enough data to observe any statistically significant interactions.'; res16 = document.getElementById('result_Q13_16').innerText == 'Yes, well done! Now you can focus on interpreting your model’s predicted values (the blue lines) and examine the partial residuals (the grey points that represent the variance in Vocab scores that is not accounted for by this model). It should be clear from this plot that this L2 model is not able to predict Vocab scores as well as our L1 model could (hence the considerably lower adjusted coefficient of determination (R-squared). Is this because L2 learners are more diverse and therefore less predictable? Or is it (also) because the sample size is smaller (67 instead of 90 participants)? We cannot tell from this data alone. What is certain is that more research is needed to answer these fascinating questions!';text = res1 + res2 + res3 + res4 + res5 + res6 + res7 + res8 + res9 + res10 + res11 + res12 + res13 + res14 + res15 + res16;element.innerHTML = text;\n         return false;\n         }}</script>\n```\n\n:::\n\n::: {.cell-output-display}\n\n```{=html}\n<div id=\"hint_82268\" onclick=\"return show_hint_82268()\">🐭 Click on the mouse for a hint.</div>\n<div id=\"result_82268\" onclick=\"return show_hint_82268()\"></div>\n<script>function show_hint_82268(){var x = document.getElementById('result_82268').innerHTML; if(!x){document.getElementById('result_82268').innerHTML = 'Three of these arguments are necessary.';} else {document.getElementById('result_82268').innerHTML = '';}}</script>\n```\n\n:::\n:::\n\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\" code-summary=\"Show sample code to answer Q13.16.\"}\nvisreg(fit = L2.model.b,\n       xvar = \"ReadEng\",\n       by = \"ART\")\n```\n:::\n\n:::\n\n::: column-margin\n![Hex sticker of the [{car}](https://www.john-fox.ca/Companion/index.html) package](images/hex_car.png){width=\"100\" fig-alt=\"The hexagonal logo of the car package features a fun-looking yellow cartoon car.\"}\n:::\n\n## Tapping into the potential of statistical modelling\n\nThis chapter aimed to provide first insights into the potential of statistical modelling with multiple predictors. It has demonstrated the importance of considering interactions between predictors and of visualising both the observed sample data, as well as simulated values based on the predictions of a statistical model.\n\nYou may have noted that *p*-values were *not* at the heart of this chapter. Instead, we focused on model accuracy (as measured by the adjusted R^2^), coefficient estimates and their relative importance (as measured by the lmg metric), predicted values, and (partial) model residuals. This is because there is an unfortunate tendency among some students and researchers to be misled into thinking that, if a result turns out to be statistically significant, it must be true. As statistician Andrew Gelman puts it, some confuse statistics for \"a form of modern alchemy, transforming the uncertainty and variation of the laboratory and field measurements into clean scientific conclusions that can be taken as truth\" [@gelmanEthicsStatisticalPractice2018: 43].\n\nI hope that working through @sec-Inferential to [-@sec-MLR] has shown you that a big part of learning to work with quantitative data in the language sciences is really about \"embracing variation and accepting uncertainty\" [@gelmanEmbracingVariationAccepting2019]. If we intend to report inferential statistics based on sample data, it is important that we decide on significance level thresholds, model selection criteria, and other such parameters *before* conducting our data analysis [on the benefits of preregistrating protocols and methods in the language sciences, see e.g. @mertzenBenefitsPreregistrationHypothesisdriven2021; @roettgerPreregistrationExperimentalLinguistics2021]. If we want to test hypotheses, these must be well-defined hypotheses and we must strive to quantify (and ideally also visualise!) **uncertainty**. Ultimately, it is worth remembering that \"in almost all practical data analysis situations – we can only draw uncertain conclusions from data, regardless of whether we manage to obtain statistical significance or not\" [@vasishthHowEmbraceVariation2021: 1311]. Crucially, we must be extremely careful when extrapolating our results beyond the range of our observed data.\n\nAs explained in @sec-Inferential, statistical inference based on NHST and *p*-values comes from a statistical framework called **frequentism**, which happens to (currently) be the most widely used framework in the language sciences. Taking a frequentist approach means that the statistical properties of the hypothesis tests that we conduct are considered under hypothetical replications of our study with new sample data. This is because, in the frequentist framework, we estimate the long-run probability of observing certain effects, were we to repeat the study many times. This is one of the reasons why **replication** (see @sec-Reproducibility) is key to advancing our knowledge of linguistics and language teaching and learning. Whenever we have small sample sizes, small effect sizes (i.e. small coefficient estimates in statistical models), large measurement error, and/or lots of variability among the target population -- as is often the case in the language sciences -- we simply cannot get **reliable** results from a single sample.\n\nDoes this mean that we should give up with quantitative data analysis and statistics all together? No, of course not. On the contrary, this uncertainty makes research in the language sciences all the more interesting and worth pursuing! It also means that there is much more to be learnt in terms of methods. In this chapter, you have learnt about **frequentist fixed-effects linear regression models**. These models are incredibly useful and can be used in many contexts, but they make a number of important assumptions that do not always hold:\n\n-   Perhaps the most obvious, yet one that we have not discussed so far, is that the **outcome variable** of a linear regression model must be **quantitative**, like the `Vocab` variable in `Dabrowska.data`, which ranges from -13.33 to 95.56 (see @sec-Variables). Other types of statistical models can be used to model other types of outcome variables, including:\n\n    -   **Binomial (or binary) logistic regression models** allow us to predict **binary** outcomes (e.g. whether or not a verb is negated) [to find out more, see e.g. @LevshinaHowlinguisticsData2015: Chapter 12; @sondereggerRegressionModelingLinguistic2023: Chapter 6; @WinterStatisticsLinguistsIntroduction2019: Chapter 12].\n\n    -   **Multinomial logistic regression models** can be used to model **categorical** outcome variables with more than two levels (e.g. which modal verb is used in certain constructions) [to find out more, see e.g. @LevshinaHowlinguisticsData2015: Chapter 13].\n\n    -   **Poisson regression models** are used to model **count** variables, i.e. discrete numeric variables such as the frequency of fillers (such as *uh* and *oh*) in certain contexts [to find out more, see e.g. @WinterStatisticsLinguistsIntroduction2019: Chapter 13].\n\n-   The observations (i.e. the data points) used to fit a **fixed-effect model** must be independent of each other. In the language sciences, such a situation is actually quite rare (see @sec-IndependenceSLR). To model interdependencies between observations, we can fit **mixed-effects models** (also called multilevel or hierarchical models) [to learn more, see e.g. @griesStatisticsLinguisticsPractical2021: Chapter 6; @sondereggerRegressionModelingLinguistic2023: Chapters 8-10; @WinterStatisticsLinguistsIntroduction2019: Chapters 14-15].\n\n-   Linear regression models assume **linear** relationships between the predictors. There are different ways to circumvent this problem. In some cases, predictors can be **transformed** to meet this assumption [see @WinterStatisticsLinguistsIntroduction2019: Chapter 5]. In others, it may be wiser to model non-linear associations with other kinds of models such as Generalised Additive Mixed Models [GAMMs, see @soskuthyGeneralisedAdditiveMixed2017 and @wielingAnalyzingDynamicPhonetic2018].\n\n-   Finally, we need not stick to the **frequentist** school of statistics. In fact, quantitative linguists are increasingly turning to **Bayesian** statistics and finding that Bayesian models help them work with the particularities of linguistic data [to learn more about Bayesian statistics, see e.g. @levshinaComparingBayesianFrequentist2022; @nicenboimIntroductionBayesianData2026].\n\n::: callout-note\n## Recommended further reading 📚\n\nIn this textbook, we have only just scratched the surface of statistical modelling. We can do much, much more with these kinds of models, and there are lots of additional things to take into account. The good news is that there are lots of excellent resources to help you continue your statistical modelling journey. Here are some good places to get started (in alphabetical order):\n\n-   Gries, Stefan Thomas. 2021. *Statistics for linguistics with R: A practical introduction* (De Gruyter Mouton Textbook). 3^rd^ revised edition. De Gruyter Mouton.\n-   Levshina, Natalia. 2015. *How to do linguistics with R: Data exploration and statistical analysis*. John Benjamins.\n-   Nicenboim, Bruno, Daniel Schad & Shravan Vasishth. 2026. Introduction to Bayesian Data Analysis for cognitive science (Chapman & Hall/CRC Statistics in the Social and Behavioral Sciences Series). CRC Press. Open Access version: <https://bruno.nicenboim.me/bayescogsci/>.\n-   Sonderegger, Morgan. 2023. *Regression modeling for linguistic data*. Cambridge, Massachusetts: The MIT Press. Open Access version: <https://osf.io/pnumg/>.\n-   Winter, Bodo. 2019. Statistics for Linguists: An Introduction Using R. Routledge.\n\nAlthough they go further than the present textbook, you will also find that these resources begin by explaining many of the things already covered in this chapter and previous chapters, and that's actually a good thing. There's no harm in revising these complex topics from a different perspective, with different examples, `R` packages, and coding styles.\n:::\n\n### Check your progress 🌟 {.unnumbered}\n\nCongratulations: you have successfully completed the most difficult chapter of this textbook! You have answered [`<span id=\"checkdown_final_score\">0</span>`{=html} out of 16 questions]{style=\"color:green;\"} correctly.\n\nAre you confident that you can...?\n\n-   [ ] Fit a linear regression model in `R` with multiple numeric and categorical predictors and interpret the intercept and predictor coefficients\n-   [ ] Center numeric predictors to make the intercept more meaningful and improve model interpretability\n-   [ ] Assess the importance of predictors using metrics like lmg\n-   [ ] Visualise and interpret model predictions (with confidence bands) and partial residuals using the {visreg} library\n-   [ ] Model and interpret interactions between predictors in multiple linear regression models, and visualise these interactions to see how one predictor moderates the effect of another on the outcome variable\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {
      "include-in-header": [
        "<script src=\"site_libs/kePrint-0.0.1/kePrint.js\"></script>\n<link href=\"site_libs/lightable-0.0.1/lightable.css\" rel=\"stylesheet\" />\n"
      ]
    },
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}