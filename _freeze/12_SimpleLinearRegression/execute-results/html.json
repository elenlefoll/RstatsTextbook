{
  "hash": "2e49582f00302f37971cbf822a9ae061",
  "result": {
    "engine": "knitr",
    "markdown": "---\nengine: knitr\nbibliography: references.bib\nhtml:\n  code-link: true\n---\n\n# Int`R`oduction to statistical modelling {#sec-SLR}\n\n::: callout-warning\n## Warning\n\nAs with the rest of this textbook (see [Preface](https://elenlefoll.github.io/RstatsTextbook/)), this chapter is very much **work in progress**. All feedback is very welcome.\n:::\n\n\n\n### From tests to models {.unnumbered}\n\nThis chapter will take you from statistical tests to statistical modelling. By the end of this chapter, you will be able to:\n\n-   Use the `lm()` function to fit linear regression models with:\n    -   a single numeric predictor variable\n    -   a single (binary) categorical predictor variable\n-   Understand the relationship between:\n    -   correlation tests and linear regression models with a single numeric predictor\n    -   *t*-tests and linear regression models with a single binary categorical predictor\n-   Interpret the summary output of simple linear regression models\n-   Explain what the intercept of a simple linear regression model corresponds to\n-   Visualise the predictions of simple linear regression models\n-   Explain why \"association does not imply causation\"\n-   Check the most important assumptions of linear regression models.\n\n## Correlations as regression over a numeric variable {#sec-Correlationsregression}\n\nThis section explains how the principle of correlation, which we covered in @sec-Correlations, is integral to linear regression modelling. We begin with a 'toy' example to familiarise ourselves with the concept of statistical modelling. It is important to take the time to genuinely understand how simple linear regression works before moving on to more complex, real-world research questions.\n\n### A perfect prediction\n\nIn the following, we will fit a simple linear regression model to predict the percentage of correct answers that a student obtained in a multiple-choice test based on the number of questions that they correctly answered in this same test. Clearly, this is a purely hypothetical example because, if we know the number of questions that a student correctly answered and how many questions there were in the test, we can easily calculate the percentage of questions that the student answered correctly.\n\nIf a test has 10 questions and a student answered 8 of them correctly, we can calculate the percentage of questions that they successfully answered like this:\n\n\n::: {.cell}\n\n```{.r .cell-code}\n8 / 10 * 100\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 80\n```\n\n\n:::\n:::\n\n\nAnd we can simplify this operation to a single multiplication:\n\n\n::: {.cell}\n\n```{.r .cell-code}\n8 * 10\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 80\n```\n\n\n:::\n:::\n\n\nWe will fit our first simple linear regression model on a simulated dataset. It consists of 100 test results expressed:\n\na.  as the number of correctly answered questions (`N.correct`), and\nb.  as a percentage (`Accuracy`).\n\nThe dataset contains 100 rows corresponding to the results of 100 test-takers. @tbl-RTTable displays the first six rows of this simulated dataset (`test.results`).\n\n\n::: {#tbl-RTTable .cell}\n\n```{.r .cell-code  code-fold=\"true\" code-summary=\"Show code to simulate the dataset.\"}\n# First, we set a seed to ensure that the outcome of our randomly generated number series are always exactly the same:\nset.seed(42)\n\n# Second, we simulate the number of questions that 100 learners answered correctly using the `sample()` function that generates random numbers, specifying that learners got between 1 and 10 questions right:\nN.correct <- sample(1:10, 100, replace = TRUE)\n\n # Third, we convert the number of correctly answered questions into the percentage of questions that these learners answered correctly:\nAccuracy <- N.correct / 10 * 100\n\n# Finally, we put these two variables together in a dataframe:\ntest.results <- data.frame(N.correct, Accuracy)\n```\n:::\n\n\n\n::: {.cell}\n::: {.cell-output-display}\n\n```{=html}\n<div id=\"ukyzphwfam\" style=\"padding-left:0px;padding-right:0px;padding-top:10px;padding-bottom:10px;overflow-x:auto;overflow-y:auto;width:auto;height:auto;\">\n<style>#ukyzphwfam table {\n  font-family: system-ui, 'Segoe UI', Roboto, Helvetica, Arial, sans-serif, 'Apple Color Emoji', 'Segoe UI Emoji', 'Segoe UI Symbol', 'Noto Color Emoji';\n  -webkit-font-smoothing: antialiased;\n  -moz-osx-font-smoothing: grayscale;\n}\n\n#ukyzphwfam thead, #ukyzphwfam tbody, #ukyzphwfam tfoot, #ukyzphwfam tr, #ukyzphwfam td, #ukyzphwfam th {\n  border-style: none;\n}\n\n#ukyzphwfam p {\n  margin: 0;\n  padding: 0;\n}\n\n#ukyzphwfam .gt_table {\n  display: table;\n  border-collapse: collapse;\n  line-height: normal;\n  margin-left: auto;\n  margin-right: auto;\n  color: #333333;\n  font-size: 16px;\n  font-weight: normal;\n  font-style: normal;\n  background-color: #FFFFFF;\n  width: auto;\n  border-top-style: solid;\n  border-top-width: 2px;\n  border-top-color: #A8A8A8;\n  border-right-style: none;\n  border-right-width: 2px;\n  border-right-color: #D3D3D3;\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #A8A8A8;\n  border-left-style: none;\n  border-left-width: 2px;\n  border-left-color: #D3D3D3;\n}\n\n#ukyzphwfam .gt_caption {\n  padding-top: 4px;\n  padding-bottom: 4px;\n}\n\n#ukyzphwfam .gt_title {\n  color: #333333;\n  font-size: 125%;\n  font-weight: initial;\n  padding-top: 4px;\n  padding-bottom: 4px;\n  padding-left: 5px;\n  padding-right: 5px;\n  border-bottom-color: #FFFFFF;\n  border-bottom-width: 0;\n}\n\n#ukyzphwfam .gt_subtitle {\n  color: #333333;\n  font-size: 85%;\n  font-weight: initial;\n  padding-top: 3px;\n  padding-bottom: 5px;\n  padding-left: 5px;\n  padding-right: 5px;\n  border-top-color: #FFFFFF;\n  border-top-width: 0;\n}\n\n#ukyzphwfam .gt_heading {\n  background-color: #FFFFFF;\n  text-align: center;\n  border-bottom-color: #FFFFFF;\n  border-left-style: none;\n  border-left-width: 1px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 1px;\n  border-right-color: #D3D3D3;\n}\n\n#ukyzphwfam .gt_bottom_border {\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n}\n\n#ukyzphwfam .gt_col_headings {\n  border-top-style: solid;\n  border-top-width: 2px;\n  border-top-color: #D3D3D3;\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n  border-left-style: none;\n  border-left-width: 1px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 1px;\n  border-right-color: #D3D3D3;\n}\n\n#ukyzphwfam .gt_col_heading {\n  color: #333333;\n  background-color: #FFFFFF;\n  font-size: 100%;\n  font-weight: normal;\n  text-transform: inherit;\n  border-left-style: none;\n  border-left-width: 1px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 1px;\n  border-right-color: #D3D3D3;\n  vertical-align: bottom;\n  padding-top: 5px;\n  padding-bottom: 6px;\n  padding-left: 5px;\n  padding-right: 5px;\n  overflow-x: hidden;\n}\n\n#ukyzphwfam .gt_column_spanner_outer {\n  color: #333333;\n  background-color: #FFFFFF;\n  font-size: 100%;\n  font-weight: normal;\n  text-transform: inherit;\n  padding-top: 0;\n  padding-bottom: 0;\n  padding-left: 4px;\n  padding-right: 4px;\n}\n\n#ukyzphwfam .gt_column_spanner_outer:first-child {\n  padding-left: 0;\n}\n\n#ukyzphwfam .gt_column_spanner_outer:last-child {\n  padding-right: 0;\n}\n\n#ukyzphwfam .gt_column_spanner {\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n  vertical-align: bottom;\n  padding-top: 5px;\n  padding-bottom: 5px;\n  overflow-x: hidden;\n  display: inline-block;\n  width: 100%;\n}\n\n#ukyzphwfam .gt_spanner_row {\n  border-bottom-style: hidden;\n}\n\n#ukyzphwfam .gt_group_heading {\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 5px;\n  padding-right: 5px;\n  color: #333333;\n  background-color: #FFFFFF;\n  font-size: 100%;\n  font-weight: initial;\n  text-transform: inherit;\n  border-top-style: solid;\n  border-top-width: 2px;\n  border-top-color: #D3D3D3;\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n  border-left-style: none;\n  border-left-width: 1px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 1px;\n  border-right-color: #D3D3D3;\n  vertical-align: middle;\n  text-align: left;\n}\n\n#ukyzphwfam .gt_empty_group_heading {\n  padding: 0.5px;\n  color: #333333;\n  background-color: #FFFFFF;\n  font-size: 100%;\n  font-weight: initial;\n  border-top-style: solid;\n  border-top-width: 2px;\n  border-top-color: #D3D3D3;\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n  vertical-align: middle;\n}\n\n#ukyzphwfam .gt_from_md > :first-child {\n  margin-top: 0;\n}\n\n#ukyzphwfam .gt_from_md > :last-child {\n  margin-bottom: 0;\n}\n\n#ukyzphwfam .gt_row {\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 5px;\n  padding-right: 5px;\n  margin: 10px;\n  border-top-style: solid;\n  border-top-width: 1px;\n  border-top-color: #D3D3D3;\n  border-left-style: none;\n  border-left-width: 1px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 1px;\n  border-right-color: #D3D3D3;\n  vertical-align: middle;\n  overflow-x: hidden;\n}\n\n#ukyzphwfam .gt_stub {\n  color: #333333;\n  background-color: #FFFFFF;\n  font-size: 100%;\n  font-weight: initial;\n  text-transform: inherit;\n  border-right-style: solid;\n  border-right-width: 2px;\n  border-right-color: #D3D3D3;\n  padding-left: 5px;\n  padding-right: 5px;\n}\n\n#ukyzphwfam .gt_stub_row_group {\n  color: #333333;\n  background-color: #FFFFFF;\n  font-size: 100%;\n  font-weight: initial;\n  text-transform: inherit;\n  border-right-style: solid;\n  border-right-width: 2px;\n  border-right-color: #D3D3D3;\n  padding-left: 5px;\n  padding-right: 5px;\n  vertical-align: top;\n}\n\n#ukyzphwfam .gt_row_group_first td {\n  border-top-width: 2px;\n}\n\n#ukyzphwfam .gt_row_group_first th {\n  border-top-width: 2px;\n}\n\n#ukyzphwfam .gt_summary_row {\n  color: #333333;\n  background-color: #FFFFFF;\n  text-transform: inherit;\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 5px;\n  padding-right: 5px;\n}\n\n#ukyzphwfam .gt_first_summary_row {\n  border-top-style: solid;\n  border-top-color: #D3D3D3;\n}\n\n#ukyzphwfam .gt_first_summary_row.thick {\n  border-top-width: 2px;\n}\n\n#ukyzphwfam .gt_last_summary_row {\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 5px;\n  padding-right: 5px;\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n}\n\n#ukyzphwfam .gt_grand_summary_row {\n  color: #333333;\n  background-color: #FFFFFF;\n  text-transform: inherit;\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 5px;\n  padding-right: 5px;\n}\n\n#ukyzphwfam .gt_first_grand_summary_row {\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 5px;\n  padding-right: 5px;\n  border-top-style: double;\n  border-top-width: 6px;\n  border-top-color: #D3D3D3;\n}\n\n#ukyzphwfam .gt_last_grand_summary_row_top {\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 5px;\n  padding-right: 5px;\n  border-bottom-style: double;\n  border-bottom-width: 6px;\n  border-bottom-color: #D3D3D3;\n}\n\n#ukyzphwfam .gt_striped {\n  background-color: rgba(128, 128, 128, 0.05);\n}\n\n#ukyzphwfam .gt_table_body {\n  border-top-style: solid;\n  border-top-width: 2px;\n  border-top-color: #D3D3D3;\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n}\n\n#ukyzphwfam .gt_footnotes {\n  color: #333333;\n  background-color: #FFFFFF;\n  border-bottom-style: none;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n  border-left-style: none;\n  border-left-width: 2px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 2px;\n  border-right-color: #D3D3D3;\n}\n\n#ukyzphwfam .gt_footnote {\n  margin: 0px;\n  font-size: 90%;\n  padding-top: 4px;\n  padding-bottom: 4px;\n  padding-left: 5px;\n  padding-right: 5px;\n}\n\n#ukyzphwfam .gt_sourcenotes {\n  color: #333333;\n  background-color: #FFFFFF;\n  border-bottom-style: none;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n  border-left-style: none;\n  border-left-width: 2px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 2px;\n  border-right-color: #D3D3D3;\n}\n\n#ukyzphwfam .gt_sourcenote {\n  font-size: 90%;\n  padding-top: 4px;\n  padding-bottom: 4px;\n  padding-left: 5px;\n  padding-right: 5px;\n}\n\n#ukyzphwfam .gt_left {\n  text-align: left;\n}\n\n#ukyzphwfam .gt_center {\n  text-align: center;\n}\n\n#ukyzphwfam .gt_right {\n  text-align: right;\n  font-variant-numeric: tabular-nums;\n}\n\n#ukyzphwfam .gt_font_normal {\n  font-weight: normal;\n}\n\n#ukyzphwfam .gt_font_bold {\n  font-weight: bold;\n}\n\n#ukyzphwfam .gt_font_italic {\n  font-style: italic;\n}\n\n#ukyzphwfam .gt_super {\n  font-size: 65%;\n}\n\n#ukyzphwfam .gt_footnote_marks {\n  font-size: 75%;\n  vertical-align: 0.4em;\n  position: initial;\n}\n\n#ukyzphwfam .gt_asterisk {\n  font-size: 100%;\n  vertical-align: 0;\n}\n\n#ukyzphwfam .gt_indent_1 {\n  text-indent: 5px;\n}\n\n#ukyzphwfam .gt_indent_2 {\n  text-indent: 10px;\n}\n\n#ukyzphwfam .gt_indent_3 {\n  text-indent: 15px;\n}\n\n#ukyzphwfam .gt_indent_4 {\n  text-indent: 20px;\n}\n\n#ukyzphwfam .gt_indent_5 {\n  text-indent: 25px;\n}\n\n#ukyzphwfam .katex-display {\n  display: inline-flex !important;\n  margin-bottom: 0.75em !important;\n}\n\n#ukyzphwfam div.Reactable > div.rt-table > div.rt-thead > div.rt-tr.rt-tr-group-header > div.rt-th-group:after {\n  height: 0px !important;\n}\n</style>\n<table class=\"gt_table\" data-quarto-disable-processing=\"false\" data-quarto-bootstrap=\"false\">\n  <thead>\n    <tr class=\"gt_col_headings\">\n      <th class=\"gt_col_heading gt_columns_bottom_border gt_right\" rowspan=\"1\" colspan=\"1\" scope=\"col\" id=\"N.correct\">N.correct</th>\n      <th class=\"gt_col_heading gt_columns_bottom_border gt_right\" rowspan=\"1\" colspan=\"1\" scope=\"col\" id=\"Accuracy\">Accuracy</th>\n    </tr>\n  </thead>\n  <tbody class=\"gt_table_body\">\n    <tr><td headers=\"N.correct\" class=\"gt_row gt_right\">1</td>\n<td headers=\"Accuracy\" class=\"gt_row gt_right\">10</td></tr>\n    <tr><td headers=\"N.correct\" class=\"gt_row gt_right\">5</td>\n<td headers=\"Accuracy\" class=\"gt_row gt_right\">50</td></tr>\n    <tr><td headers=\"N.correct\" class=\"gt_row gt_right\">1</td>\n<td headers=\"Accuracy\" class=\"gt_row gt_right\">10</td></tr>\n    <tr><td headers=\"N.correct\" class=\"gt_row gt_right\">9</td>\n<td headers=\"Accuracy\" class=\"gt_row gt_right\">90</td></tr>\n    <tr><td headers=\"N.correct\" class=\"gt_row gt_right\">10</td>\n<td headers=\"Accuracy\" class=\"gt_row gt_right\">100</td></tr>\n    <tr><td headers=\"N.correct\" class=\"gt_row gt_right\">4</td>\n<td headers=\"Accuracy\" class=\"gt_row gt_right\">40</td></tr>\n  </tbody>\n  \n  \n</table>\n</div>\n```\n\n:::\n:::\n\n\nWe can now plot the two variables of our simulated dataset as a scatter plot to visualise the correlation between the number of questions learners answered correctly (`N.correct`) and the percentage of questions they answered accurately (`Accuracy`). As expected, these two variables are perfectly correlated: every data point sits exactly on the regression line.\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\" code-summary=\"Show code to generate the scatter plot.\"}\nlibrary(tidyverse)\nggplot(data = test.results,\n       aes(x = N.correct, y = Accuracy)) +\n  geom_smooth(method = \"lm\",\n              se = FALSE) +\n  geom_point(alpha = 0.5,\n             size = 2) +\n  labs(x = \"Number of correct answers\",\n       y = \"% of questions correctly answered\") +\n  scale_x_continuous(limits = c(0, 10.5), expand = c(0,0), breaks = c(0,2,4,6,8,10)) +\n  scale_y_continuous(limits = c(0, 105), expand = c(0,0), breaks = c(0, 20, 40, 60, 80, 100)) +\n  theme_bw()\n```\n\n::: {.cell-output-display}\n![The correlation between learners' test results expressed as the number of correct answers and the percentage of questions answered correctly](12_SimpleLinearRegression_files/figure-html/fig-RTScatterPLot-1.png){#fig-RTScatterPLot fig-alt='Scatter plot of learners\\' test results expressed as the number of correct answers they got on the x-axis and as the percentage of correctly answered questions on the y-axis. The data points form a perfect linear relationship. A straight blue regression line runs through all the data points.' width=576}\n:::\n:::\n\n\nThis is confirmed by a correlation test (see below), which shows:\n\na.  a correlation coefficient (Pearson's *r*) of exactly `1`,\nb.  an extremely small *p*-value (the smallest that `R` can display: `< 2.2e-16`), and\nc.  the narrowest 95% confidence interval possible `[1, 1]`.\n\n\n::: {.cell}\n\n```{.r .cell-code}\ncor.test(~ N.correct + Accuracy,\n         data = test.results)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\n\tPearson's product-moment correlation\n\ndata:  N.correct and Accuracy\nt = 156587349, df = 98, p-value < 2.2e-16\nalternative hypothesis: true correlation is not equal to 0\n95 percent confidence interval:\n 1 1\nsample estimates:\ncor \n  1 \n```\n\n\n:::\n:::\n\n\nNow, we use the base `R` function `lm()` to fit a simple linear model to predict the percentage of questions that learners correctly answered based on the number of correct answers that they gave. Like the significance test functions that we saw in @sec-Inferential, `lm()` takes a **formula** as its first argument. We want to predict the proportion of questions that learners correctly answered as a percentage (`Accuracy`) so this variable comes *before* the tilde (`~`). In statistical modelling, the variable that we want to predict is referred to as the **outcome variable**. We want to use the number of correct answers that the learners gave to make our prediction, so we place the variable `N.correct` *after* the tilde. Variables used to predict the outcome are called **predictors**.\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntest.model <- lm(formula = Accuracy ~ N.correct,\n                 data = test.results)\n```\n:::\n\n\nWe have saved our model to our local environment as an `R` object called `test.model`. We can now use the `summary()` function to examine the model:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsummary(test.model)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nCall:\nlm(formula = Accuracy ~ N.correct, data = test.results)\n\nResiduals:\n       Min         1Q     Median         3Q        Max \n-1.083e-13 -6.620e-16  1.360e-16  6.230e-16  1.311e-13 \n\nCoefficients:\n             Estimate Std. Error   t value Pr(>|t|)    \n(Intercept) 5.151e-15  3.717e-15 1.386e+00    0.169    \nN.correct   1.000e+01  6.030e-16 1.658e+16   <2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 1.736e-14 on 98 degrees of freedom\nMultiple R-squared:      1,\tAdjusted R-squared:      1 \nF-statistic: 2.75e+32 on 1 and 98 DF,  p-value: < 2.2e-16\n```\n\n\n:::\n:::\n\n\nIn addition to this model summary, the code above outputs a warning about an \"essentially perfect fit\" in the Console. We will come to this warning at the end of this section, but for now let's start by looking at the **coefficients** of our model summary. Every model has an **intercept** coefficient estimate (`(Intercept)`), which is the value that the model predicts for the outcome variable when the predictor variables are zero. In other words, it is where the regression line would cross the *y*-axis if the line were extended to go all the way to zero as in @fig-RTScatterPLotIntercept.\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\" code-summary=\"Show code to generate plot.\"}\nggplot(data = test.results,\n       aes(x = N.correct, y = Accuracy)) +\n  geom_abline(slope = 10, \n              intercept = c(0,0),\n              linetype = \"dotted\",\n              colour = \"blue\") +       \n  geom_smooth(method = \"lm\",\n              se = FALSE) +\n  geom_point(alpha = 0.5,\n             size = 2) +\n  labs(x = \"Number of correct answers\",\n       y = \"% of questions correctly answered\") +\n  scale_x_continuous(limits = c(0, 10.5), expand = c(0,0), breaks = c(0,2,4,6,8,10)) +\n  scale_y_continuous(limits = c(0, 105), expand = c(0,0), breaks = c(0, 20, 40, 60, 80, 100)) +\n  theme_bw()\n```\n\n::: {.cell-output-display}\n![The correlation between learners' test results expressed as the number of correct answers and the percentage of questions answered correctly](12_SimpleLinearRegression_files/figure-html/fig-RTScatterPLotIntercept-1.png){#fig-RTScatterPLotIntercept fig-alt='This is the same plot as above. The only difference is that a dotted blue line extends the fit blue line to zero.' width=576}\n:::\n:::\n\n\nIn our case, we only have one predictor, so the intercept coefficient that our model estimates (`5.151e-15`) corresponds to the predicted percentage of questions answered correctly (outcome) when the number of correct answers (predictor) is equal to zero. Instinctively, we know that this value should be zero because 0 points in a test = 0% correct in the test. And, indeed, our model predicts an intercept extremely close to zero (`5.151e-15`). Using the `format()` function, we can convert this coefficient estimate from **scientific notation** to standard notation:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nformat(5.151e-15, scientific = FALSE)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] \"0.000000000000005151\"\n```\n\n\n:::\n:::\n\n\nThe second, `N.correct` coefficient estimate in our model summary is displayed as `1.000e+01` which is equal to:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nformat(1.000e+01, scientific = FALSE)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] \"10\"\n```\n\n\n:::\n:::\n\n\nThis coefficient estimate means that, for every correct answer, our prediction for the percentage of questions answered correctly increases by 10%. For example, if a student answered 9 questions correctly, our model predicts that the percentage of correctly answered question is equal to the intercept coefficient of (nearly) zero plus 9 multiplied by 10, which is equal to 90%:\n\n\n::: {.cell}\n\n```{.r .cell-code}\n-5.151e-15 + 9 * 10\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 90\n```\n\n\n:::\n:::\n\n\nIn our model summary, the coefficient estimate for `N.correct` is associated with a *p*-value of `<2e-16`. It corresponds to the *p*-value of our `cor.test()` on the same data, and is actually the smallest value that `R` will display. In other words, it is extremely small. This *p*-value indicates that we can safely reject the null hypothesis that this coefficient is zero under the assumptions of a linear regression model. In other words, we can reject the null hypothesis that the number of correct answers is *not* a useful predictor to predict the percentage of correctly answered questions under the assumption of a linear regression model (more on these assumptions in @sec-Assumptions).\n\nThe penultimate line of the model summary is also important. It features two **R-squared (R^2^) values**. Like the absolute values of correlation coefficients, these can range between 0 and 1. R^2^ = 0 means that the model accounts for 0% of the variance in the outcome variable. R^2^ = 1 means that the model accounts for 100% of the variance, i.e. that it can perfectly predict the values of the outcome variable from the predictor variable(s). As our simulated `test.results` dataset is based on a perfect correlation, our model is able to perfectly predict the outcome variable, hence both our R^2^ values equal `1`. In this chapter and @sec-MLR, however, we will focus on the **adjusted R-squared value** because it accounts for the fact that the more predictors we include in our model, the easier it is to predict the outcome variable.\n\nFinally, you may have also noticed that the `lm()` function returned a warning message when we fitted this practice model:\n\n```         \nWarning message:\nIn summary.lm(test.model) :\n  essentially perfect fit: summary may be unreliable\n```\n\nWith this message, the authors of the `lm()` function are warning us that our model can make almost perfect predictions. Given that in real-life research this is extremely unlikely, an \"essentially perfect\" prediction is usually a sign that we may have made an error of some kind. Here, however, we can safely ignore this warning because we know that the number of correct answers can, indeed, be converted to percentages of correctly answered questions with perfect accuracy (hence our R^2^ of 1 or 100%).\n\n### A real-life prediction\n\nIn the remaining sections of the chapter, we fit simple regression models to real data from:\n\n> Dąbrowska, Ewa. 2019. Experience, Aptitude, and Individual Differences in Linguistic Attainment: A Comparison of Native and Nonnative Speakers. Language Learning 69(S1). 72–100. <https://doi.org/10.1111/lang.12323>.\n\n::: {.callout-warning collapse=\"false\"}\n#### Prerequisites {.unnumbered}\n\nOur starting point for this chapter is the wrangled combined dataset that we created and saved in @sec-DataWrangling. Follow the instructions in @sec-filter to create this `R` object.\n\nAlternatively, you can download `Dabrowska2019.zip` from [the textbook's GitHub repository](https://github.com/elenlefoll/RstatsTextbook/raw/69d1e31be7394f2b612825f031ebffeb75886390/Dabrowska2019.zip){.uri}. To launch the project correctly, first unzip the file and then double-click on the `Dabrowska2019.Rproj` file.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(here)\n\nDabrowska.data <- readRDS(file = here(\"data\", \"processed\", \"combined_L1_L2_data.rds\"))\n```\n:::\n\n\nBefore you get started, check that you have correctly imported the data by examining the output of `View(Dabrowska.data)` and `str(Dabrowska.data)`. In addition, run the following lines of code to load the {tidyverse} packages and create \"clean\" versions of the L1 and L2 datasets as separate `R` objects:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(tidyverse)\n\nL1.data <- Dabrowska.data |> \n  filter(Group == \"L1\")\n\nL2.data <- Dabrowska.data |> \n  filter(Group == \"L2\")\n```\n:::\n\n\nOnce you are satisfied that the data are correctly loaded, you are ready to start modelling! 🚀\n:::\n\nRecall that, in @sec-Correlations, we saw that there is a **positive correlation** between the total number of years that English L1 speakers spent in formal education (`EduTotal`) and their English grammar comprehension test scores (`Grammar`). @fig-EducationYearsVocab suggests that this positive correlation also holds for the association between the number of years participants spent in formal education and their receptive vocabulary test scores (`Vocab`).\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\" code-summary=\"See code to generate plot.\"}\nL1.data |> \n  ggplot(mapping = aes(x = EduTotal, \n                       y = Vocab)) +\n  geom_point() +\n  geom_smooth(method = \"lm\",\n              se = FALSE) + \n  theme_bw()\n```\n\n::: {.cell-output-display}\n![Relationship between years spent in formal education and vocabulary test scores among L1 speakers](12_SimpleLinearRegression_files/figure-html/fig-EducationYearsVocab-1.png){#fig-EducationYearsVocab fig-alt='Scatter plot of vocabulary scores on the y-axis, and  years of education on the x-axis. A blue regression line slopes upward, indicating a positive relationship: higher formal education tends to be associated with higher vocabulary scores.' width=576}\n:::\n:::\n\n\nOn average, the longer L1 speakers were in formal education, the better they performed on the vocabulary test. The correlation is larger than for `Grammar` scores, and it is statistically significant at an α-level of 0.05 (*r* = 0.43, 95% CI \\[0.24, 0.58\\]):\n\n\n::: {.cell}\n\n```{.r .cell-code}\ncor.test(formula = ~ Vocab + EduTotal,\n         data = L1.data)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\n\tPearson's product-moment correlation\n\ndata:  Vocab and EduTotal\nt = 4.4281, df = 88, p-value = 2.721e-05\nalternative hypothesis: true correlation is not equal to 0\n95 percent confidence interval:\n 0.2410910 0.5824698\nsample estimates:\n      cor \n0.4268695 \n```\n\n\n:::\n:::\n\n\nThe straight (i.e. linear) regression line going through our scatter plot in @fig-EducationYearsVocab, does *not* go through all the data points like it did in @fig-RTScatterPLot. This is because, if we know how long an L1 participant was in formal education, we cannot *perfectly* predict how well they will perform on the `Vocab` test, even though we do know that, on average, having spent longer in formal education correlates with `Vocab` test scores. Indeed, @fig-EducationYearsVocab clearly shows that some of the individuals who attended formal education for the least amount of time scored very low, whilst others scored very high in the `Vocab` test. This is not surprising, as we can expect that many other factors will play a role in L1 vocabulary knowledge.\n\nWe now fit a simple linear regression model using the `lm()` function (which stands for **linear model**) to the L1 data from @DabrowskaExperienceAptitudeIndividual2019 with the aim of predicting `Vocab` scores (our outcome variable) based on the number of years that they spent in formal education (`EduTotal`; our predictor variable):\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmodel1 <- lm(formula = Vocab ~ EduTotal,\n             data = L1.data)\n```\n:::\n\n\nWe examine the model using the `summary()` function:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsummary(model1)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nCall:\nlm(formula = Vocab ~ EduTotal, data = L1.data)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-57.725 -10.716   0.526  12.417  36.033 \n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)    \n(Intercept)  20.5159    11.1519   1.840   0.0692 .  \nEduTotal      3.5460     0.8008   4.428 2.72e-05 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 18.51 on 88 degrees of freedom\nMultiple R-squared:  0.1822,\tAdjusted R-squared:  0.1729 \nF-statistic: 19.61 on 1 and 88 DF,  p-value: 2.721e-05\n```\n\n\n:::\n:::\n\n\nThis time, we'll begin our interpretation of the model summary from the top:\n\n-   The first line is a reminder of the model **formula** and of the **data** on which we fitted our linear model (`lm`).\n\n-   The second paragraph provides information about the **residuals**. They represent the difference between participants' actual `Vocab` scores (the observed values) and the model's predictions (the predicted values). Hence, they correspond to the variance in `Vocab` scores that is left unaccounted for by the model. The closer to zero the residuals are, the better the model fits the data. However, no real-life model is perfect so we expect there to be some \"left-over\" variance.\n\n    -   `Min`, `1Q`, `Median`, `3Q`, and `Max` are the minimum, first quartile, median, third quartile, and maximum residuals, respectively. These are the descriptive statistics of a distribution that are typically displayed in a boxplot (see @sec-IQR). These statistics give us a sense of the spread of the residuals. Whilst these values can be informative, it's best to plot residuals to get a sense of their distribution (see @sec-Residuals). Ideally, the residuals should be normally distributed and centred around zero (see @sec-AssumptionsLR).\n\n-   The **intercept coefficient estimate** of `20.516` is the model's prediction for the vocabulary score of participants who spent zero years (!) in formal education (`EduTotal` = 0). It is the model's baseline or reference `Vocab` score.\n\n-   The **EduTotal coefficient estimate** of `3.546` means that, for each year of formal education, our model predicts that `Vocab` test scores will increase by an additional 3.546 units on top of the baseline score of `20.516`, provided that all other variables remain the same. Hence, if an individual spent 14 years in formal education, their predicted `Vocab` score is:\n\n\n    ::: {.cell}\n    \n    ```{.r .cell-code}\n    20.5159 + 14*3.5460\n    ```\n    \n    ::: {.cell-output .cell-output-stdout}\n    \n    ```\n    [1] 70.1599\n    ```\n    \n    \n    :::\n    :::\n\n\n-   The ***p-*****value** associated with the `EduTotal` coefficient is very small (`2.72e-05`).\n\n\n    ::: {.cell}\n    \n    ```{.r .cell-code}\n    format(2.72e-05, scientific = FALSE)\n    ```\n    \n    ::: {.cell-output .cell-output-stdout}\n    \n    ```\n    [1] \"0.0000272\"\n    ```\n    \n    \n    :::\n    :::\n\n\n    It suggests that the predictor `EduTotal` makes a statistically significant contribution to our model predicting `Vocab` scores among L1 speakers.\n\n-   The **adjusted R-squared (R²)** is `0.1729`, which means that our model accounts for ca. 17% of the total variance in `Vocab` scores. That may not seem a lot, but it is worth recalling that our model only includes one predictor variable. We can reasonably assume that other predictors will help us to predict L1 speakers' vocabulary knowledge more accurately (e.g., their age, how much they read, perhaps their profession, etc.).\n\n::: callout-note\n# It's all linear regression!\n\nDid you notice that the ***t*****-value** and the ***p*****-value** associated with the `EduTotal` coefficient in our linear regression model are *exactly the same* as those that we obtained earlier using the `cor.test()` function? This is because linear regression with a single numeric predictor is -- under the hood -- exactly the same as a Pearson's correlation test!\n\nMoreover, we said that **R²** stands for the **squared coefficient of correlation**, which is why, if we take the square root of our unadjusted R² coefficient, we get 0.43, which corresponds to the **correlation coefficient** (Pearson's *r*) that we obtained from the `cor.test()` function:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsqrt(0.1822)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 0.4268489\n```\n\n\n:::\n:::\n\n\nHaving gone through @sec-Inferential, you may now ask yourself: why do we need correlation tests if simple linear regression does the same thing? 🧐 Honestly, we don't. @sec-Inferential introduced correlation tests and *t*-tests because they are widely used in the language sciences, so it is important that you understand them, but the truth is: you can achieve much more by taking a modelling rather than a testing approach to analysing data. Read on to find out more!\n:::\n\n### Predicted values and residuals\n\n@fig-EduPredictedVocab visualises the `Vocab` scores that our first model (`model1`) predicts as a function of the number of years that L1 speakers have spent in formal education. We can access our model's predictions by applying the `predict()` function to our model object (`model1`). By definition, regression models predict perfect linear associations. As shown in @fig-EduPredictedVocab, here, our model predicts a perfect, positive linear association between our predictor variable (`EduTotal`) and our outcome variable (`Vocab`).\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\" code-summary=\"See code to generate plot.\"}\nggplot(L1.data, \n       aes(x = EduTotal, \n           y = predict(model1))) + \n  geom_abline(slope = 3.55, \n              intercept = 20.51,\n              linetype = \"dotted\",\n              colour = \"blue\") +   \n  geom_count() +\n  scale_size_area(guide = NULL) +\n  labs(y='Predicted Vocab scores', \n       x='Years in formal education') +\n  theme_bw()\n```\n\n::: {.cell-output-display}\n![Relationship between years spent in formal education and predicted vocabulary test scores](12_SimpleLinearRegression_files/figure-html/fig-EduPredictedVocab-1.png){#fig-EduPredictedVocab fig-alt='A scatter plot showing the relationship between years in formal education and predicted vocabulary scores. The points form an upward linear trend and their size corresponds to the number of people in the L1 dataset who reported being in formal education for that many years. Most people reported spending between 11 and 14 years in formal education but some as many 21 years.' width=576}\n:::\n:::\n\n\nYou may have noticed that there are fewer dots on @fig-EduPredictedVocab than data points in the dataset that we used to fit the model (N = 90). This is because, if more than one L1 participant reported having been in formal education for the same duration of time, the model predicts the same `Vocab` score for all these people and this means that the dots overlap on the plot of predicted values. To ensure that we keep in mind that a single dot may represent more than one participant, in @fig-EduPredictedVocab, the `geom_count()` function is used to map the size of each dot onto the number of participants that it represents.\n\nThis is all very well, but as we learnt from @fig-EducationYearsVocab, in reality, our predictor variable `EduTotal` does not correlate perfectly with `Vocab` scores — far from it! Let us now compare the **predicted values** of our model with the **observed values** from the data. How well does our model fit the data? To help us answer this question, @fig-ActualPredictedVocab visualises the relationship between L1 participants' actual `Vocab` scores (*x*-axis) and the scores that the model predicted for these participants (*y*-axis).\n\n\n::: {.cell fig-heigth='8'}\n\n```{.r .cell-code  code-fold=\"true\" code-summary=\"Show code to generate plot.\"}\npred_vals   <- predict(model1) # Vector of predictions\nxmin_pred   <- min(pred_vals)  # Lowest predicted score\n\nhighlight_df <- data.frame(\n  x = c(xmin_pred, pred_vals[68]),\n  y = c(L1.data$Vocab[which.min(pred_vals)],\n      91))\n\nggplot(L1.data, \n       aes(x = pred_vals, \n           y = Vocab)) + \n  geom_point() +\n  # 45° reference line (the \"perfect‑prediction\" line):\n  geom_abline(intercept = 0, \n              slope = 1,\n              linetype = \"dotted\",\n              colour = \"blue\") +\n  annotate(\"segment\",\n           x = xmin_pred, \n           y = 29, \n           yend = xmin_pred,\n           colour = \"blue\",\n           arrow = arrow(length = unit(0.25, \"cm\"))) +\n  annotate(\"segment\",\n           x = pred_vals[68], \n           y = 91, \n           yend = pred_vals[68],\n           colour = \"blue\",\n           arrow = arrow(length = unit(0.25, \"cm\"))) +  \n  geom_point(data = highlight_df,\n             aes(x = x, y = y),\n             colour = \"blue\") +  \n  scale_y_continuous(limits = c(0, 100), \n                     expand = c(0,0)) +\n  scale_x_continuous(limits = c(0, 100), \n                     expand = c(0,0)) +\n  labs(x = \"Predicted Vocab scores\", \n       y = \"Actual Vocab scores\") +\n  theme_bw()\n```\n\n::: {.cell-output-display}\n![Relationship between actual and predicted `Vocab` test scores](12_SimpleLinearRegression_files/figure-html/fig-ActualPredictedVocab-1.png){#fig-ActualPredictedVocab fig-alt='Scatter plot with predicted Vocab scores on the x-axis and actual Vocab scores on the y-axis with a dotted blue diagonal line showing where the dots would lie if the model\\'s prediction were perfect. The model\\'s predictions are far from perfect; few dots fall on the dotted line. For two dots, there is a blue line drawn from the dot to the dotted line; the length of these lines represent the model\\'s residuals for these two participants.' width=672}\n:::\n:::\n\n\nIn @fig-ActualPredictedVocab, the dotted blue line represents where the points would lie, if `model1` perfectly predicted `Vocab` scores based only on the number of years that participants spent in formal education. The dots that fall on or very close to the dotted line stand for L1 participants for whom our model accurately predicts their `Vocab` score based solely on the number of years they spent in formal education. The further the dots are from the dotted line, the worse the predictions for these speakers. The distances between each point and the dotted line in @fig-ActualPredictedVocab correspond to the model's residuals. **Residuals** are therefore the 'left-over' variability in the data that our model cannot account for.\n\nResiduals can be positive or negative, depending on whether the dots on the predicted vs. actual values plot are above or below the dotted line of perfect fit. However, what matters more are their absolute values. The larger the residuals, the worse the model fit. Returning to the question, 'How good is our model fit?', we can conclude from @fig-ActualPredictedVocab that it's not great. But we already knew that from the model's fairly low R² value and, crucially, we also know that many other factors are likely to account for some of the remaining variation in vocabulary scores.\n\n::: callout-warning\n### Association does not imply causation. {.unnumbered}\n\nYou may be familiar with the Latin phrase:\n\n-   ***Cum hoc ergo propter hoc*** ('with this, therefore because of this')\n\nor its English equivalent:\n\n-   ***Correlation does not imply causation***.\n\nThey both refer to the human tendency to assume that, if two things are regularly associated, one probably *causes* the other. However, this is a logical fallacy. For example, even if we had observed a very high correlation between the number of years participants were in formal education and their receptive vocabulary test scores (and had therefore reported an excellent model fit with very small residuals), this would by no means imply that, on average, spending more time in formal education *leads to* greater vocabulary knowledge. A correlation merely describes an association; it tells us nothing about any causal relationship.\n\nIt is often tempting to interpret the results of statistical tests and models causally, but this is the result of a well-known human cognitive bias [see, e.g, @matuteIllusionsCausalityHow2015; @kaufmanIllusionCausalityCognitive2018]. In the language sciences and across the social sciences more generally, there are usually far too many potential factors at play to warrant any causal interpretation. What we are modelling throughout this chapter and @sec-MLR are **statistical associations**. We cannot draw any conclusions about what *caused* what from these models. In the context of statistical modelling, we can extend the famous saying to: **Association does not imply causation**.\n\nThere are three main reasons for this:\n\n1.  There may be one or more **confounding variables** that we have not accounted for in our model. For instance, we can predict with a fair degree of accuracy how much vocabulary an infant understands based on their weight. However, the weight of young children is, of course, highly correlated with their age and, by extension, the amount of language exposure they've had so far in their life. Clearly, it is not their weight that is *causing* them to understand more words. Unfortunately, it's not always that obvious. Going back to `model1`, it is very likely that some of the younger participants in the @DabrowskaExperienceAptitudeIndividual2019 dataset were still in formal education at the time of data collection; this includes all those who reported being students. In other words, for at least some of the participants, the `EduTotal` variable confounds age and years spent in formal education.\n\n2.  Even if there is a causal effect, it may not be in the **direction** that we assume. For example, the vocabulary knowledge of adult learners of a foreign language is probably a fairly good predictor of how many foreign language classes these adult learners have attended. However, this does not mean that vocabulary knowledge *causes* adults to attend classes. If anything, it is more likely to be the other way around. Whilst it seems rather obvious in this example, in linguistics and education, complex interdependencies between predictors are very common. Consider reading ability: the more a child reads, the better they become at reading. Therefore, we might conclude that spending more time reading leads to better reading skills. However, for some children, poor reading skills may actually *cause* a lack of motivation and interest in reading in the first place. Clearly, determining causal relationships is tricky!\n\n3.  Finally, it is important to consider the possibility that even a statistically significant association could be entirely **spurious**. This happens more often than you might think, and it is more likely to happen with smaller datasets. Moreover, the more we test associations, the more likely we are to find statistically significant ones (see @sec-pHacking on the multiple testing problem and Type 1 errors). When associations are very strong, we may be tempted to think that they are real, but this may not be the case. To raise awareness of this risk, [Tyler Vigen](https://tylervigen.com/about-spurious-correlations) conducted correlation tests on millions of combinations of randomly selected variables and created a website featuring thousands of examples of very large and highly significant correlations that are all entirely spurious (e.g. @fig-SpuriousCorrelation).\n\n    ![Find this spurious correlation (CC BY 4.0) and thousands more by Tyler Vigen at <https://tylervigen.com/spurious-correlations>.](images/Vigen_unhealthy-air-quality-in-johnstown-pennsylvania_correlates-with_masters-degrees-awarded-in-education.png){#fig-SpuriousCorrelation fig-alt=\"A linear line chart with years as the X-axis and two variables on the Y-axis. The first variable is Air pollution in Johnstown, Pennsylvania and the second variable is Master's degrees awarded in Education.  The chart goes from 2012 to 2021, and the two variables track closely in value over that time. The following statistics are displayed on the graph: Pearson's r = 0.989, r-squared = 0.979, p < 0.01 Source: tylervigen.com/spurious/correlation/3139\"}\n:::\n\n::: {.callout-tip collapse=\"false\"}\n#### Your turn! {.unnumbered}\n\nIn this task, you will seek answers to the research question: To what extent can the results of the non-verbal IQ `Blocks` test be used to predict `Vocab` scores among L1 and L2 speakers of English based on the data from @DabrowskaExperienceAptitudeIndividual2019? As we will be answering this question within a linear regression framework, what we are really asking is: To what extent are these variables linearly associated with each other?\n\n[**Q12.1**]{style=\"color:green;\"} Fit a linear model to predict `Vocab` scores among L1 participants based on their `Blocks` test scores. What is the adjusted R^2^ value of this model?\n\n\n::: {.cell}\n::: {.cell-output-display}\n\n```{=html}\n<form name=\"form_53559\" onsubmit=\"return validate_form_53559()\" method=\"post\">\n<label>\n<input type=\"radio\" name=\"answer_53559\" id=\"answer_53559_1\" value=\"0.0009\"/>\n0.0009\n</label>\n<br/>\n<label>\n<input type=\"radio\" name=\"answer_53559\" id=\"answer_53559_2\" value=\"0.006\"/>\n0.006\n</label>\n<br/>\n<label>\n<input type=\"radio\" name=\"answer_53559\" id=\"answer_53559_3\" value=\"0.007\"/>\n0.007\n</label>\n<br/>\n<label>\n<input type=\"radio\" name=\"answer_53559\" id=\"answer_53559_4\" value=\"0.07\"/>\n0.07\n</label>\n<br/>\n<label>\n<input type=\"radio\" name=\"answer_53559\" id=\"answer_53559_5\" value=\"0.08\"/>\n0.08\n</label>\n<br/>\n<label>\n<input type=\"radio\" name=\"answer_53559\" id=\"answer_53559_6\" value=\"0.7\"/>\n0.7\n</label>\n<br/>\n<label>\n<input type=\"radio\" name=\"answer_53559\" id=\"answer_53559_7\" value=\"0.9\"/>\n0.9\n</label>\n<br/>\n<input type=\"submit\" value=\"Check answer\"/>\n<div id=\"result_53559\"></div>\n</form>\n<script>function validate_form_53559() {var x, text; var x = document.forms['form_53559']['answer_53559'].value;if (x == '0.07'){text = 'That’s right, well done!';} else {text = 'No, that’s not it. Are you modelling the L1 data only?';} document.getElementById('result_53559').innerHTML = text; evaluate_final_score(); return false;}function evaluate_final_score(){\n         element = document.getElementById('checkdown_final_score');\n         if(element === null){return false;} else {var element, text, res1;res1 = document.getElementById('result_53559').innerText == 'That’s right, well done!';text = res1;element.innerHTML = text;\n         return false;\n         }}</script>\n```\n\n:::\n:::\n\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\" code-summary=\"Show sample code to answer Q12.1.\"}\ntaskmodel1 <- lm(formula = Vocab ~ Blocks,\n                 data = L1.data)\n\nsummary(taskmodel1) # Adjusted R-squared:  0.07232 \n```\n:::\n\n\n[**Q12.2**]{style=\"color:green;\"} According to your model, which of these values is the predicted `Vocab` score of an L1 speaker with a `Blocks` score of 20?\n\n\n::: {.cell}\n::: {.cell-output-display}\n\n```{=html}\n<form name=\"form_35078\" onsubmit=\"return validate_form_35078()\" method=\"post\">\n<label>\n<input type=\"radio\" name=\"answer_35078\" id=\"answer_35078_1\" value=\"About 75\"/>\nAbout 75\n</label>\n<br/>\n<label>\n<input type=\"radio\" name=\"answer_35078\" id=\"answer_35078_2\" value=\"About 21\"/>\nAbout 21\n</label>\n<br/>\n<label>\n<input type=\"radio\" name=\"answer_35078\" id=\"answer_35078_3\" value=\"About 55\"/>\nAbout 55\n</label>\n<br/>\n<label>\n<input type=\"radio\" name=\"answer_35078\" id=\"answer_35078_4\" value=\"About 1\"/>\nAbout 1\n</label>\n<br/>\n<label>\n<input type=\"radio\" name=\"answer_35078\" id=\"answer_35078_5\" value=\"Just over 0\"/>\nJust over 0\n</label>\n<br/>\n<label>\n<input type=\"radio\" name=\"answer_35078\" id=\"answer_35078_6\" value=\"About -54\"/>\nAbout -54\n</label>\n<br/>\n<input type=\"submit\" value=\"Check answer\"/>\n<div id=\"result_35078\"></div>\n</form>\n<script>function validate_form_35078() {var x, text; var x = document.forms['form_35078']['answer_35078'].value;if (x == 'About 75'){text = 'Awesome! Note that we also use the predict() function to extract the model’s predicted value for any combination of predictor values, e.g. <code>predict(taskmodel1, data.frame(Blocks = 20))</code>';} else {text = 'Humm, are you sure?';} document.getElementById('result_35078').innerHTML = text; evaluate_final_score(); return false;}function evaluate_final_score(){\n         element = document.getElementById('checkdown_final_score');\n         if(element === null){return false;} else {var element, text, res1, res2;res1 = document.getElementById('result_53559').innerText == 'That’s right, well done!'; res2 = document.getElementById('result_35078').innerText == 'Awesome! Note that we also use the predict() function to extract the model’s predicted value for any combination of predictor values, e.g. predict(taskmodel1, data.frame(Blocks = 20))';text = res1 + res2;element.innerHTML = text;\n         return false;\n         }}</script>\n```\n\n:::\n\n::: {.cell-output-display}\n\n```{=html}\n<div id=\"hint_15607\" onmouseover=\"return show_hint_15607()\">🦉 Hover over the owl for a first hint.</div>\n<div id=\"result_15607\" onmouseover=\"return show_hint_15607()\"></div>\n<script>function show_hint_15607(){var x = document.getElementById('result_15607').innerHTML; if(!x){document.getElementById('result_15607').innerHTML = 'You can answer this question either by plotting the predicted values of your model and reading the value off your graph or by doing some maths using the coefficient estimates provided in the summary of your model.';} else {document.getElementById('result_15607').innerHTML = '';}}</script>\n```\n\n:::\n\n::: {.cell-output-display}\n\n```{=html}\n<div id=\"hint_2707\" onclick=\"return show_hint_2707()\">🐭 Click on the mouse for a second hint.</div>\n<div id=\"result_2707\" onclick=\"return show_hint_2707()\"></div>\n<script>function show_hint_2707(){var x = document.getElementById('result_2707').innerHTML; if(!x){document.getElementById('result_2707').innerHTML = 'If you choose to do solve this question numerically, you will need to multiply the coefficient estimate for the Blocks variable by 20 and add this to the coefficient estimate for the intercept.';} else {document.getElementById('result_2707').innerHTML = '';}}</script>\n```\n\n:::\n:::\n\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\" code-summary=\"Show code to answer Q12.2\"}\n# a) Taking a numerical approach, you can add up the model coefficients printed in the model summary. As always, start with the intercept coefficient and add to it the coefficient corresponding to an increase in one point on the Blocks test multiplied by the number of points that this participant achieved (20):\nsummary(taskmodel1)\n\n54.5614 + 1.0527*20\n\n# Alternatively, we can take the coefficient estimate values directly from the model object to get an even more precise prediction like this:\ntaskmodel1$coefficients[1] + (taskmodel1$coefficients[2] * 20)\n\n# b) Taking a graphical approach, we need to plot the model's predicted Vocab scores against all Blocks test scores in the dataset in order to find out how what the model's prediction is for a Blocks test score of 20. The ggplot code below adds an arrow and a dotted line to help you read the predicted Vocab score from the plot:\nggplot(L1.data, \n       aes(x = Blocks, \n           y = predict(taskmodel1))) + \n  geom_point() +\n  annotate(\"segment\",\n           x = 20, \n           y = 50, \n           yend = 75,\n           colour = \"blue\",\n           arrow = arrow(length = unit(0.25, \"cm\"))) +\n  annotate(\"segment\",\n           x = 0, \n           xend = 19.5, \n           y = 75.6,\n           colour = \"blue\",\n           linetype = \"dotted\") +\n  labs(y='Predicted Vocab scores', \n       x='Blocks test scores') +\n  theme_minimal()\n```\n:::\n\n\n[**Q12.3**]{style=\"color:green;\"} Now fit a new linear model to predict `Vocab` scores among L2 participants based on their `Blocks` test scores. Comparing the adjusted R^2^ value of this new L2 model to your previous L1 model, which of these statements is/are true?\n\n\n::: {.cell}\n::: {.cell-output-display}\n\n```{=html}\n<form name=\"form_20558\" onsubmit=\"return validate_form_20558()\" method=\"post\">\n<label>\n<input type=\"checkbox\" id=\"answer_20558_1\" value=\"Blocks test scores are a much more useful predictor of Vocab scores for L1 than L2 participants.\"/>\nBlocks test scores are a much more useful predictor of Vocab scores for L1 than L2 participants.\n</label>\n<br/>\n<label>\n<input type=\"checkbox\" id=\"answer_20558_2\" value=\"Blocks test scores are a much useful predictor of Vocab scores for L2 than L1 participants.\"/>\nBlocks test scores are a much useful predictor of Vocab scores for L2 than L1 participants.\n</label>\n<br/>\n<label>\n<input type=\"checkbox\" id=\"answer_20558_3\" value=\"Higher Blocks test scores lead to statistically significantly higher Vocab scores among L1 participants.\"/>\nHigher Blocks test scores lead to statistically significantly higher Vocab scores among L1 participants.\n</label>\n<br/>\n<label>\n<input type=\"checkbox\" id=\"answer_20558_4\" value=\"Blocks test scores allow us to almost perfectly predict Vocab scores among L1 participants.\"/>\nBlocks test scores allow us to almost perfectly predict Vocab scores among L1 participants.\n</label>\n<br/>\n<label>\n<input type=\"checkbox\" id=\"answer_20558_5\" value=\"Blocks test scores allow us to almost perfectly predict Vocab scores among L2 participants.\"/>\nBlocks test scores allow us to almost perfectly predict Vocab scores among L2 participants.\n</label>\n<br/>\n<input type=\"submit\" value=\"Check answer\"/>\n<div id=\"result_20558\"></div>\n</form>\n<script>function validate_form_20558() {var text; var x1 = document.getElementById('answer_20558_1'); var x2 = document.getElementById('answer_20558_2'); var x3 = document.getElementById('answer_20558_3'); var x4 = document.getElementById('answer_20558_4'); var x5 = document.getElementById('answer_20558_5'); if (x1.checked == true&x2.checked == false&x3.checked == false&x4.checked == false&x5.checked == false){text = 'That’s right, well done!';} else {text = 'No, compare the adjusted R-squared values of the two models.';} document.getElementById('result_20558').innerHTML = text; evaluate_final_score(); return false;}function evaluate_final_score(){\n         element = document.getElementById('checkdown_final_score');\n         if(element === null){return false;} else {var element, text, res1, res2, res3;res1 = document.getElementById('result_53559').innerText == 'That’s right, well done!'; res2 = document.getElementById('result_35078').innerText == 'Awesome! Note that we also use the predict() function to extract the model’s predicted value for any combination of predictor values, e.g. predict(taskmodel1, data.frame(Blocks = 20))'; res3 = document.getElementById('result_20558').innerText == 'That’s right, well done!';text = res1 + res2 + res3;element.innerHTML = text;\n         return false;\n         }}</script>\n```\n\n:::\n\n::: {.cell-output-display}\n\n```{=html}\n<div id=\"hint_24013\" onmouseover=\"return show_hint_24013()\">🦉 Hover over the owl for a first hint.</div>\n<div id=\"result_24013\" onmouseover=\"return show_hint_24013()\"></div>\n<script>function show_hint_24013(){var x = document.getElementById('result_24013').innerHTML; if(!x){document.getElementById('result_24013').innerHTML = 'Remember that we cannot interpret linear regression models causally.';} else {document.getElementById('result_24013').innerHTML = '';}}</script>\n```\n\n:::\n\n::: {.cell-output-display}\n\n```{=html}\n<div id=\"hint_25602\" onclick=\"return show_hint_25602()\">🐭 Click on the mouse for a second hint.</div>\n<div id=\"result_25602\" onclick=\"return show_hint_25602()\"></div>\n<script>function show_hint_25602(){var x = document.getElementById('result_25602').innerHTML; if(!x){document.getElementById('result_25602').innerHTML = 'Only one of these statements is true.';} else {document.getElementById('result_25602').innerHTML = '';}}</script>\n```\n\n:::\n:::\n\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\" code-summary=\"Show sample code to answer Q12.3.\"}\ntaskmodel2 <- lm(formula = Vocab ~ Blocks,\n                 data = L2.data)\n\nsummary(taskmodel2) # Adjusted R-squared:  0.007177 \nsummary(taskmodel1) # Adjusted R-squared:  0.07232 \n```\n:::\n\n\n[**Q12.4**]{style=\"color:green;\"} In your L2 model, the *p*-value for the `Blocks` predictor should be `0.228620`. True or false: This *p*-value means that there is a 23% chance of obtaining a Blocks coefficient estimate of 0.72 or higher in a random sample of 67 L2 speakers of English when there is actually no association between the results of the `Blocks` test and those of the `Vocab` test?\n\n\n::: {.cell}\n::: {.cell-output-display}\n\n```{=html}\n<form name=\"form_68806\" onsubmit=\"return validate_form_68806()\" method=\"post\">\n<label>\n<input type=\"radio\" name=\"answer_68806\" id=\"answer_68806_1\" value=\"True.\"/>\nTrue.\n</label>\n<br/>\n<label>\n<input type=\"radio\" name=\"answer_68806\" id=\"answer_68806_2\" value=\"False.\"/>\nFalse.\n</label>\n<br/>\n<input type=\"submit\" value=\"Check answer\"/>\n<div id=\"result_68806\"></div>\n</form>\n<script>function validate_form_68806() {var x, text; var x = document.forms['form_68806']['answer_68806'].value;if (x == 'True.'){text = 'Indeed!';} else {text = 'No, remember that the <em>p</em>-value is statement about the likelihood of the data given the null hypothesis of no association.';} document.getElementById('result_68806').innerHTML = text; evaluate_final_score(); return false;}function evaluate_final_score(){\n         element = document.getElementById('checkdown_final_score');\n         if(element === null){return false;} else {var element, text, res1, res2, res3, res4;res1 = document.getElementById('result_53559').innerText == 'That’s right, well done!'; res2 = document.getElementById('result_35078').innerText == 'Awesome! Note that we also use the predict() function to extract the model’s predicted value for any combination of predictor values, e.g. predict(taskmodel1, data.frame(Blocks = 20))'; res3 = document.getElementById('result_20558').innerText == 'That’s right, well done!'; res4 = document.getElementById('result_68806').innerText == 'Indeed!';text = res1 + res2 + res3 + res4;element.innerHTML = text;\n         return false;\n         }}</script>\n```\n\n:::\n:::\n\n\n \n:::\n\n## *t*-tests as regression over a binary variable {#sec-Ttestsregression}\n\nLet us now see how much of the variation across all receptive English vocabulary test scores in the @DabrowskaExperienceAptitudeIndividual2019 data we can accurately predict if we only include a single **categorical binary variable** predictor in our model: whether the `Vocab` scores belong to L1 or L2 speakers of English. Hence, in the following model, we keep the same outcome variable (`Vocab`), but now we try to predict it using the `Group` variable as our single predictor.\n\nWe know that, on average, L1 speakers score better on the `Vocab` test than L2 speakers. However, as illustrated in @fig-IQL1L2, we also know that there is quite a bit of variability around the mean scores of the L1 and L2 speakers.\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\" code-summary=\"See code to generate plot.\"}\ngroup_means <- Dabrowska.data |> \n  group_by(Group) |> \n  summarise(mean_vocab = mean(Vocab))\n\nggplot(data = Dabrowska.data, \n       aes(x = Group, \n           y = Vocab)) +\n  geom_boxplot(width = 0.5) +\n  stat_summary(\n    fun = mean,                     # what to plot\n    geom = \"point\",                 # as a point\n    shape = 18,                     # in a diamond shape\n    size = 4,                       # a little larger than the default\n    colour = \"blue\") +\n  geom_line(\n    data = group_means,                   \n    aes(x = as.numeric(Group), \n        y = mean_vocab),\n    colour = \"blue\",\n    linewidth = 1,\n    linetype = \"dashed\") +\n  geom_text(data = group_means,\n    aes(x = as.numeric(Group), \n        y = mean_vocab,\n        label = sprintf(\"%.2f\", mean_vocab)), # print the means to two decimal points\n    vjust = -1.4,\n    colour = \"purple\") +\n  labs(x = NULL,\n    y = \"Non-verbal IQ (Blocks) test\") +\n  theme_bw(base_size = 14)\n```\n\n::: {.cell-output-display}\n![Comparison of non-verbal IQ (Blocks) test scores between L1 and L2 groups](12_SimpleLinearRegression_files/figure-html/fig-IQL1L2-1.png){#fig-IQL1L2 fig-alt='Box plot comparing non-verbal IQ scores between two groups, L1 and L2. A blue dashed trend line connects the medians, showing that the median L1 score is lower than the median L2 score. Both groups display outliers at the lower end of their distributions.' width=576}\n:::\n:::\n\n\nA *t*-test shows that the mean difference between L1 and L2 speakers is statistically significant (*p* = `7.032e-06`):\n\n\n::: {.cell}\n\n```{.r .cell-code}\nt.test(Vocab ~ Group, \n       data = Dabrowska.data)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\n\tWelch Two Sample t-test\n\ndata:  Vocab by Group\nt = 4.6768, df = 133.83, p-value = 7.032e-06\nalternative hypothesis: true difference in means between group L1 and group L2 is not equal to 0\n95 percent confidence interval:\n  9.425801 23.240497\nsample estimates:\nmean in group L1 mean in group L2 \n        69.13580         52.80265 \n```\n\n\n:::\n:::\n\n\nCohen's *d* is large (`0.77`) and the 95% confidence interval does not go anywhere near zero:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(effectsize)\n\ncohens_d(Vocab ~ Group, \n         data = Dabrowska.data)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nCohen's d |       95% CI\n------------------------\n0.77      | [0.44, 1.09]\n\n- Estimated using pooled SD.\n```\n\n\n:::\n:::\n\n\nSo we can be confident that the `Group` variable will be a useful predictor to predict `Vocab` in a simple linear regression model. We can use exactly the same formula as earlier to fit our model:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmodel2 <- lm(formula = Vocab ~ Group, \n             data = Dabrowska.data)\n\nsummary(model2)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nCall:\nlm(formula = Vocab ~ Group, data = Dabrowska.data)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-66.136 -13.580   2.753  17.531  38.308 \n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)    \n(Intercept)   69.136      2.247  30.763  < 2e-16 ***\nGroupL2      -16.333      3.440  -4.748 4.64e-06 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 21.32 on 155 degrees of freedom\nMultiple R-squared:  0.127,\tAdjusted R-squared:  0.1213 \nF-statistic: 22.54 on 1 and 155 DF,  p-value: 4.644e-06\n```\n\n\n:::\n:::\n\n\nLet's break down the model summary:\n\n-   The **intercept coefficient estimate** is the predicted `Vocab` score when `Group` is at its reference level. By default, in `R`, the reference level of a categorical variable is the level that comes first alphabetically. Here, it's therefore 'L1' for the English native speaker group. The model's estimated `Vocab` test score for an L1 participant is therefore `69.136` points. If you check @fig-IQL1L2, you will see that this value corresponds to the mean L1 `Vocab` score in our data.\n\n-   The **GroupL2 coefficient** **estimate** is the estimated change in `Vocab` score for an L2 speaker as compared to the reference level of an L1 speaker. The estimate is `-16.333`, which means that L2 speakers are predicted to score 16.333 points *lower* than L1 speakers on this test. If you subtract this `GroupL2` coefficient estimate from the `Intercept`, you will find that it corresponds to the mean L2 `Vocab` score in our data:\n\n\n    ::: {.cell}\n    \n    ```{.r .cell-code}\n    69.136 - 16.333\n    ```\n    \n    ::: {.cell-output .cell-output-stdout}\n    \n    ```\n    [1] 52.803\n    ```\n    \n    \n    :::\n    :::\n\n\n-   The ***p*****-value** associated with the coefficient `GroupL2` is extremely small (`4.64e-06`). It informs us that `Group` is a statistically significant predictor of receptive English vocabulary knowledge based on our data.\n\n-   The **adjusted R-squared** value indicates the proportion of variation in `Vocab` scores that the model can account for when we know a participant's native-speaker status: 12.13% (`0.1213`). This value is not particularly impressive. However, this is not surprising given that our model attempts to predict vocabulary scores based solely on whether someone is an L1 or L2 speaker of English. With only this information, the model can only predict that L1 speakers will achieve the mean L1 score and L2 speakers the mean L2 score of the sample data.\n\n::: {.callout-note collapse=\"false\"}\n# It's (still) all linear regression!\n\nHere, too, it is worth noticing that fitting a simple linear regression model with a single binary predictor is — under the hood — exactly the same thing as conducting an **independent** **two-sample *t*-test**. Compare the ***t*****-statistic** of the *t*-test that we computed earlier with that of the *t*-statistic of the `GroupL2` coefficient reported in the summary of our second model. If we ignore the signs of the *t*-values, we can see that they are almost identical!\n\nAlso, notice how the ***p*****-value** computed by the `t.test()` function and that reported for our `GroupL2` coefficient are almost identical. They both correspond to values that are extremely close to zero.\n\nThe very small differences between these values are due to the default correction that the `t.test()` function in `R` makes for unequal group variances (see @sec-Variability). If we switch off this correction, both the *t*-statistic and the *p*-value are exactly the same as those reported in the summary of our second linear model above:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nt.test(Vocab ~ Group, \n       data = Dabrowska.data,\n       var.equal = TRUE)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\n\tTwo Sample t-test\n\ndata:  Vocab by Group\nt = 4.7478, df = 155, p-value = 4.644e-06\nalternative hypothesis: true difference in means between group L1 and group L2 is not equal to 0\n95 percent confidence interval:\n  9.537477 23.128821\nsample estimates:\nmean in group L1 mean in group L2 \n        69.13580         52.80265 \n```\n\n\n:::\n:::\n\n:::\n\n::: {.callout-tip collapse=\"false\"}\n#### Your turn! {.unnumbered}\n\n[**Q12.5**]{style=\"color:green;\"} Draw a boxplot showing the distribution of `Vocab` scores among male and female participants in `Dabrowska.data`. Based on your boxplot, do you expect `Gender` to be a statistically significant predictor of `Vocab` scores?\n\n\n::: {.cell}\n::: {.cell-output-display}\n\n```{=html}\n<form name=\"form_71636\" onsubmit=\"return validate_form_71636()\" method=\"post\">\n<label>\n<input type=\"radio\" name=\"answer_71636\" id=\"answer_71636_1\" value=\"No, because there is a lot of overlap between the two distributions and the female and male median Vocab scores are very close to each other.\"/>\nNo, because there is a lot of overlap between the two distributions and the female and male median Vocab scores are very close to each other.\n</label>\n<br/>\n<label>\n<input type=\"radio\" name=\"answer_71636\" id=\"answer_71636_2\" value=\"No, because the female and male mean Vocab scores are very close to each other.\"/>\nNo, because the female and male mean Vocab scores are very close to each other.\n</label>\n<br/>\n<label>\n<input type=\"radio\" name=\"answer_71636\" id=\"answer_71636_3\" value=\"Yes, because the mean Vocab score of male participants is higher than that of female participants.\"/>\nYes, because the mean Vocab score of male participants is higher than that of female participants.\n</label>\n<br/>\n<label>\n<input type=\"radio\" name=\"answer_71636\" id=\"answer_71636_4\" value=\"Yes, because there are a lot of very low Vocab scores among female participants.\"/>\nYes, because there are a lot of very low Vocab scores among female participants.\n</label>\n<br/>\n<label>\n<input type=\"radio\" name=\"answer_71636\" id=\"answer_71636_5\" value=\"Yes, because there are significantly more female participants in this dataset.\"/>\nYes, because there are significantly more female participants in this dataset.\n</label>\n<br/>\n<input type=\"submit\" value=\"Check answer\"/>\n<div id=\"result_71636\"></div>\n</form>\n<script>function validate_form_71636() {var x, text; var x = document.forms['form_71636']['answer_71636'].value;if (x == 'No, because there is a lot of overlap between the two distributions and the female and male median Vocab scores are very close to each other.'){text = 'Well done!';} else {text = 'No, that’s not it. Remember that the middle line in a boxplot represents the median.';} document.getElementById('result_71636').innerHTML = text; evaluate_final_score(); return false;}function evaluate_final_score(){\n         element = document.getElementById('checkdown_final_score');\n         if(element === null){return false;} else {var element, text, res1, res2, res3, res4, res5;res1 = document.getElementById('result_53559').innerText == 'That’s right, well done!'; res2 = document.getElementById('result_35078').innerText == 'Awesome! Note that we also use the predict() function to extract the model’s predicted value for any combination of predictor values, e.g. predict(taskmodel1, data.frame(Blocks = 20))'; res3 = document.getElementById('result_20558').innerText == 'That’s right, well done!'; res4 = document.getElementById('result_68806').innerText == 'Indeed!'; res5 = document.getElementById('result_71636').innerText == 'Well done!';text = res1 + res2 + res3 + res4 + res5;element.innerHTML = text;\n         return false;\n         }}</script>\n```\n\n:::\n:::\n\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\" code-summary=\"Show sample code to answer Q12.5.\"}\nDabrowska.data |> \n  ggplot(mapping = aes(x = Gender,\n                       y = Vocab)) +\n  geom_boxplot() +\n  labs(x = \"Gender\", \n       y = \"Vocab scores\") +\n  theme_minimal()\n```\n:::\n\n\n[**Q12.6**]{style=\"color:green;\"} Fit a model with `Vocab` as the outcome variable and `Gender` as the predictor to test your intuition based on your boxplot. Is `Gender` a statistically significant predictor of `Vocab` score in this simple linear regression model?\n\n\n::: {.cell}\n::: {.cell-output-display}\n\n```{=html}\n<form name=\"form_156\" onsubmit=\"return validate_form_156()\" method=\"post\">\n<label>\n<input type=\"radio\" name=\"answer_156\" id=\"answer_156_1\" value=\"No, the p-value associated with GenderM coefficient is higher than 0.05.\"/>\nNo, the p-value associated with GenderM coefficient is higher than 0.05.\n</label>\n<br/>\n<label>\n<input type=\"radio\" name=\"answer_156\" id=\"answer_156_2\" value=\"Yes, the p-value associated with GenderM coefficient is higher than 0.05.\"/>\nYes, the p-value associated with GenderM coefficient is higher than 0.05.\n</label>\n<br/>\n<label>\n<input type=\"radio\" name=\"answer_156\" id=\"answer_156_3\" value=\"No, the p-value associated with GenderM coefficient is lower than 0.05.\"/>\nNo, the p-value associated with GenderM coefficient is lower than 0.05.\n</label>\n<br/>\n<label>\n<input type=\"radio\" name=\"answer_156\" id=\"answer_156_4\" value=\"Yes, the p-value associated with GenderM coefficient is lower than 0.05.\"/>\nYes, the p-value associated with GenderM coefficient is lower than 0.05.\n</label>\n<br/>\n<input type=\"submit\" value=\"Check answer\"/>\n<div id=\"result_156\"></div>\n</form>\n<script>function validate_form_156() {var x, text; var x = document.forms['form_156']['answer_156'].value;if (x == 'No, the p-value associated with GenderM coefficient is higher than 0.05.'){text = 'That’s right!';} else {text = 'Are you sure? You should have obtained a p-value of 0.957.';} document.getElementById('result_156').innerHTML = text; evaluate_final_score(); return false;}function evaluate_final_score(){\n         element = document.getElementById('checkdown_final_score');\n         if(element === null){return false;} else {var element, text, res1, res2, res3, res4, res5, res6;res1 = document.getElementById('result_53559').innerText == 'That’s right, well done!'; res2 = document.getElementById('result_35078').innerText == 'Awesome! Note that we also use the predict() function to extract the model’s predicted value for any combination of predictor values, e.g. predict(taskmodel1, data.frame(Blocks = 20))'; res3 = document.getElementById('result_20558').innerText == 'That’s right, well done!'; res4 = document.getElementById('result_68806').innerText == 'Indeed!'; res5 = document.getElementById('result_71636').innerText == 'Well done!'; res6 = document.getElementById('result_156').innerText == 'That’s right!';text = res1 + res2 + res3 + res4 + res5 + res6;element.innerHTML = text;\n         return false;\n         }}</script>\n```\n\n:::\n\n::: {.cell-output-display}\n\n```{=html}\n<div id=\"hint_95173\" onclick=\"return show_hint_95173()\">🐭 Click on the mouse for a hint.</div>\n<div id=\"result_95173\" onclick=\"return show_hint_95173()\"></div>\n<script>function show_hint_95173(){var x = document.getElementById('result_95173').innerHTML; if(!x){document.getElementById('result_95173').innerHTML = 'You will need to fit a linear model with <code>Vocab</code> as the outcome variable and <code>Gender</code> as the predictor.';} else {document.getElementById('result_95173').innerHTML = '';}}</script>\n```\n\n:::\n:::\n\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\" code-summary=\"Show code to answer Q12.6\"}\ntaskmodel3 <- lm(formula = Vocab ~ Gender,\n                 data = Dabrowska.data)\n\nsummary(taskmodel3) # p-value associated with coefficient estimate for GenderM = 0.957\n```\n:::\n\n\n[**Q12.7**]{style=\"color:green;\"} The adjusted R^2^ coefficient of the model is `-0.006433`. True or false: This means that male participants, on average, score 0.006433 fewer points than female participants on the `Vocab` test?\n\n\n::: {.cell}\n::: {.cell-output-display}\n\n```{=html}\n<form name=\"form_63340\" onsubmit=\"return validate_form_63340()\" method=\"post\">\n<label>\n<input type=\"radio\" name=\"answer_63340\" id=\"answer_63340_1\" value=\"True.\"/>\nTrue.\n</label>\n<br/>\n<label>\n<input type=\"radio\" name=\"answer_63340\" id=\"answer_63340_2\" value=\"False.\"/>\nFalse.\n</label>\n<br/>\n<input type=\"submit\" value=\"Check answer\"/>\n<div id=\"result_63340\"></div>\n</form>\n<script>function validate_form_63340() {var x, text; var x = document.forms['form_63340']['answer_63340'].value;if (x == 'False.'){text = 'You’re right. This statement is completely wrong: the model’s R-squared coefficients tell us how much of the variance in Vocab scores our model accounts for. The values of the multiple R-squared are always between 0 and 1: a value of 0 means that the model cannot predict anything using these predictors. A value of 1 means that it can make perfect predictions. Here, the multiple R-squared coefficient is almost 0 (0.0000187). In this model, the multiple R-squared coefficient is so low that, once adjusted, it falls slightly below zero. The adjustment made is based on the number of predictors (or, in the case of categorical predictors, the number of levels in each predictor) that are entered into the model.';} else {text = 'No, that’s incorrect.';} document.getElementById('result_63340').innerHTML = text; evaluate_final_score(); return false;}function evaluate_final_score(){\n         element = document.getElementById('checkdown_final_score');\n         if(element === null){return false;} else {var element, text, res1, res2, res3, res4, res5, res6, res7;res1 = document.getElementById('result_53559').innerText == 'That’s right, well done!'; res2 = document.getElementById('result_35078').innerText == 'Awesome! Note that we also use the predict() function to extract the model’s predicted value for any combination of predictor values, e.g. predict(taskmodel1, data.frame(Blocks = 20))'; res3 = document.getElementById('result_20558').innerText == 'That’s right, well done!'; res4 = document.getElementById('result_68806').innerText == 'Indeed!'; res5 = document.getElementById('result_71636').innerText == 'Well done!'; res6 = document.getElementById('result_156').innerText == 'That’s right!'; res7 = document.getElementById('result_63340').innerText == 'You’re right. This statement is completely wrong: the model’s R-squared coefficients tell us how much of the variance in Vocab scores our model accounts for. The values of the multiple R-squared are always between 0 and 1: a value of 0 means that the model cannot predict anything using these predictors. A value of 1 means that it can make perfect predictions. Here, the multiple R-squared coefficient is almost 0 (0.0000187). In this model, the multiple R-squared coefficient is so low that, once adjusted, it falls slightly below zero. The adjustment made is based on the number of predictors (or, in the case of categorical predictors, the number of levels in each predictor) that are entered into the model.';text = res1 + res2 + res3 + res4 + res5 + res6 + res7;element.innerHTML = text;\n         return false;\n         }}</script>\n```\n\n:::\n:::\n\n\n \n:::\n\n## Regressing over a categorical predictor with more than two levels {#sec-Categoricalpredictor}\n\nThe beauty of the statistical modelling approach — as opposed to the testing approach — is that we can include all kinds of predictors in our models using a single function, `lm()`, and `R`'s formula syntax. So far, we have seen that predictors can be numeric variables (e.g. `EduTotal`) and categorical binary variables (e.g. `Group`). In this section, we see how a categorical variable with more than two levels can be entered in a linear regression model.\n\nTo demonstrate this, we will now attempt to predict participants' `Vocab` scores based on their occupational group (`OccupGroup`), which can be one of four broad categories (see @sec-geoms):\n\n> **C**: Clerical positions\n>\n> **I**: Occupationally inactive (i.e., unemployed, retired, or homemakers)\n>\n> **M**: Manual jobs\n>\n> **PS**: Professional-level jobs or studying for a degree\n\nAccording to the descriptive statistics visualised in @fig-VocabByOccupation, it looks like participants' professional occupation group is unlikely to be terribly useful to predict their vocabulary knowledge. Nonetheless, we can see that — perhaps somewhat counter-intuitively — so-called \"occupationally inactive\" participants (\"I\") tend to score higher than the other participants.\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\" code-summary=\"See code to generate plot.\"}\nDabrowska.data |> \n  ggplot(mapping = \n           aes(y = Vocab, \n               x = OccupGroup,\n               fill = OccupGroup,\n               colour = OccupGroup)) +\n  geom_boxplot(alpha = 0.3, \n               outliers = FALSE) + # If the outliers are plotted as part of the boxplot, these data points will be duplicated by the geom_jitter() function.\n  geom_jitter(alpha = 0.8, \n              width = 0.2) +\n  scale_color_viridis_d(guide = \"none\") +\n  scale_fill_viridis_d(guide = \"none\") +\n  theme_bw()\n```\n\n::: {.cell-output-display}\n![Distribution of vocabulary test scores across four occupational groups](12_SimpleLinearRegression_files/figure-html/fig-VocabByOccupation-1.png){#fig-VocabByOccupation fig-alt='Box plot showing predicted vocabulary scores across four occupational groups (C, I, M, and PS). Individual data points are overlaid as dots on each box plot. All groups show substantial variability and some extreme outliers at the lower end of the distribution.' width=576}\n:::\n:::\n\n\nSo, let's compute a simple linear model with `OccupGroup` as a predictor of `Vocab` and examine its summary:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmodel3 <- lm(formula = Vocab ~ OccupGroup, \n             data = Dabrowska.data)\n\nsummary(model3)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nCall:\nlm(formula = Vocab ~ OccupGroup, data = Dabrowska.data)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-74.406 -13.504   3.372  16.705  34.688 \n\nCoefficients:\n             Estimate Std. Error t value Pr(>|t|)    \n(Intercept)    63.333      3.867  16.379   <2e-16 ***\nOccupGroupI    12.393      5.775   2.146   0.0335 *  \nOccupGroupM    -9.133      5.160  -1.770   0.0787 .  \nOccupGroupPS   -2.261      4.817  -0.469   0.6395    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 21.87 on 153 degrees of freedom\nMultiple R-squared:  0.09288,\tAdjusted R-squared:  0.07509 \nF-statistic: 5.222 on 3 and 153 DF,  p-value: 0.001849\n```\n\n\n:::\n:::\n\n\n-   The estimate of the **intercept** corresponds to the reference level of the `OccupGroup` variable. Remember that the **reference level** is always the first level. We can check the order of the levels in any factor variable using the `levels()` function:\n\n\n    ::: {.cell}\n    \n    ```{.r .cell-code}\n    levels(Dabrowska.data$OccupGroup)\n    ```\n    \n    ::: {.cell-output .cell-output-stdout}\n    \n    ```\n    [1] \"C\"  \"I\"  \"M\"  \"PS\"\n    ```\n    \n    \n    :::\n    :::\n\n\n    By default, the levels are ordered alphabetically. In the `OccupGroup` variable, the first level is \"C\", which corresponds to a clerical position. This means that our third model predicts that English speakers in a clerical position will score `63.333` points on the `Vocab` test. Those that belong to the \"inactive\" group (\"I\") will score `12.393` *more* points than those, i.e.:\n\n\n    ::: {.cell}\n    \n    ```{.r .cell-code}\n    63.333 + 12.393\n    ```\n    \n    ::: {.cell-output .cell-output-stdout}\n    \n    ```\n    [1] 75.726\n    ```\n    \n    \n    :::\n    :::\n\n\n    Participants who have manual jobs (\"M\") are predicted to score `-9.133` points *fewer* than those in clerical positions, and so-called \"professionals\" (\"PS\") will do slightly worse than clerks (`-2.261` points). Compare these predicted values to those observed in the data shown in @fig-VocabByOccupation.\n\n-   The **adjusted R^2^ value** for our model is relatively low (`0.07509`). This means that our model accounts for about 7.5% of the total variance in `Vocab` scores across the dataset. Given that the R^2^ of `model1` was `0.1213`, this indicates that `OccupGroup` is a considerably less useful predictor variable to help us predict participants' `Vocab` scores than whether or not they are an L1 speaker (`Group`).\n\n-   What's more, the model summary reveals that only one of the `model3`'s three coefficient estimates is statistically significantly different from 0 at the α-level of 0.05: `OccupGroupI` with a ***p*****-value** of `0.0335`. This means that we can reject the null hypothesis that there is no difference in `Vocab` scores between speakers of the occupational group \"C\" (the reference level) and those of the occupational group \"I\". For the other two occupational groups, we do not have enough evidence to reject the null hypothesis of no difference compared to the reference level \"C\".\n\nWe can display the predicted `Vocab` scores for each occupational group, together with a 95% confidence interval around these predicted values using the `emmeans()` function from the [{emmeans}](https://rvlenth.github.io/emmeans/index.html) package [@lenthEmmeansEstimatedMarginal2025a]:\n\n\n::: {.cell}\n\n```{.r .cell-code}\n#install.packages(\"emmeans\")\nlibrary(emmeans)\n\nemmeans(model3, ~ OccupGroup)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n OccupGroup emmean   SE  df lower.CL upper.CL\n C            63.3 3.87 153     55.7     71.0\n I            75.7 4.29 153     67.3     84.2\n M            54.2 3.42 153     47.5     60.9\n PS           61.1 2.87 153     55.4     66.7\n\nConfidence level used: 0.95 \n```\n\n\n:::\n:::\n\n\nThe [{visreg}](https://pbreheny.github.io/visreg/index.html) package [@brehenyVisualizationRegressionModels2017] provides an efficient way of visualising model predictions and residuals. In @fig-PredictedVocabByOccupation we visualise the model's predicted values (as blue lines) and the confidence intervals output by the `emmeans()` function (as grey bands), together with the model's residuals (as grey dots).\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(visreg)\n\nvisreg(model3, gg = TRUE) +\n  labs(x = \"Occupational groups\",\n       y = \"Predicted Vocab scores\") +\n  theme_bw()\n```\n\n::: {.cell-output-display}\n![Distribution of predicted vocabulary test scores across four occupational groups](12_SimpleLinearRegression_files/figure-html/fig-PredictedVocabByOccupation-1.png){#fig-PredictedVocabByOccupation fig-alt='Box plot showing predicted vocabulary scores across four occupational groups (C, I, M, and PS). Individual data points are shown as gray dots overlaid on gray box plots with blue median lines.' width=576}\n:::\n:::\n\n\nWhen we use the argument \"gg = TRUE\", the `visreg()` function outputs a ggplot object that we can then manipulate and customise just like any other ggplot object (see @sec-DataViz).\n\n::: {.callout-note collapse=\"false\"}\n#### What about ANOVAs? {.unnumbered}\n\nYou may come across the type of simple linear regression model that we have just covered, involving a continuous numeric outcome variable and a categorical predictor with more than two levels, under the guise of a statistical significance test, namely the **one-way ANOVA** (ANalysis Of VAriance).\n\nIf you compare the summary of the following one-way ANOVA with that of the third model (`model3`), you will spot some similarities. However, it is necessary to carry out so-called post-hoc tests to get as much information out of an ANOVA as we can get from the summary of our simple linear regression model.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nanova1 <- aov(formula = Vocab ~ OccupGroup, \n    data = Dabrowska.data)\n\nsummary(anova1)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n             Df Sum Sq Mean Sq F value  Pr(>F)   \nOccupGroup    3   7495  2498.5   5.222 0.00185 **\nResiduals   153  73205   478.5                   \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n```\n\n\n:::\n:::\n\n:::\n\n::: {.callout-tip collapse=\"false\"}\n#### Your turn! {.unnumbered}\n\nIn this task, you will explore whether L2 participants' native language is a useful predictor when trying to model their English `Vocab` scores.\n\n[**Q12.8**]{style=\"color:green;\"} Fit a linear model to model L2 participants' `Vocab` score based on their native language (`NativeLg`). According to the model's adjusted R^2^ coefficient, how much of the variance in `Vocab` scores among L2 participants does this model account for?\n\n\n::: {.cell}\n::: {.cell-output-display}\n\n```{=html}\n<form name=\"form_1488\" onsubmit=\"return validate_form_1488()\" method=\"post\">\n<label>\n<input type=\"radio\" name=\"answer_1488\" id=\"answer_1488_1\" value=\"Practically 0%\"/>\nPractically 0%\n</label>\n<br/>\n<label>\n<input type=\"radio\" name=\"answer_1488\" id=\"answer_1488_2\" value=\"About 5%\"/>\nAbout 5%\n</label>\n<br/>\n<label>\n<input type=\"radio\" name=\"answer_1488\" id=\"answer_1488_3\" value=\"About 13%\"/>\nAbout 13%\n</label>\n<br/>\n<label>\n<input type=\"radio\" name=\"answer_1488\" id=\"answer_1488_4\" value=\"About 26%\"/>\nAbout 26%\n</label>\n<br/>\n<label>\n<input type=\"radio\" name=\"answer_1488\" id=\"answer_1488_5\" value=\"About 49%\"/>\nAbout 49%\n</label>\n<br/>\n<input type=\"submit\" value=\"Check answer\"/>\n<div id=\"result_1488\"></div>\n</form>\n<script>function validate_form_1488() {var x, text; var x = document.forms['form_1488']['answer_1488'].value;if (x == 'About 13%'){text = 'That’s right!';} else {text = 'No, this is not the correct value.';} document.getElementById('result_1488').innerHTML = text; evaluate_final_score(); return false;}function evaluate_final_score(){\n         element = document.getElementById('checkdown_final_score');\n         if(element === null){return false;} else {var element, text, res1, res2, res3, res4, res5, res6, res7, res8;res1 = document.getElementById('result_53559').innerText == 'That’s right, well done!'; res2 = document.getElementById('result_35078').innerText == 'Awesome! Note that we also use the predict() function to extract the model’s predicted value for any combination of predictor values, e.g. predict(taskmodel1, data.frame(Blocks = 20))'; res3 = document.getElementById('result_20558').innerText == 'That’s right, well done!'; res4 = document.getElementById('result_68806').innerText == 'Indeed!'; res5 = document.getElementById('result_71636').innerText == 'Well done!'; res6 = document.getElementById('result_156').innerText == 'That’s right!'; res7 = document.getElementById('result_63340').innerText == 'You’re right. This statement is completely wrong: the model’s R-squared coefficients tell us how much of the variance in Vocab scores our model accounts for. The values of the multiple R-squared are always between 0 and 1: a value of 0 means that the model cannot predict anything using these predictors. A value of 1 means that it can make perfect predictions. Here, the multiple R-squared coefficient is almost 0 (0.0000187). In this model, the multiple R-squared coefficient is so low that, once adjusted, it falls slightly below zero. The adjustment made is based on the number of predictors (or, in the case of categorical predictors, the number of levels in each predictor) that are entered into the model.'; res8 = document.getElementById('result_1488').innerText == 'That’s right!';text = res1 + res2 + res3 + res4 + res5 + res6 + res7 + res8;element.innerHTML = text;\n         return false;\n         }}</script>\n```\n\n:::\n:::\n\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\" code-summary=\"Show sample code to answer Q12.8.\"}\ntaskmodel3 <- lm(formula = Vocab ~ NativeLg,\n                data = L2.data) \n\nsummary(taskmodel3) # Adjusted R-squared:  0.1331 \n```\n:::\n\n\n[**Q12.9**]{style=\"color:green;\"} In this model, there is a greater difference between the multiple R^2^ and the adjusted R^2^ coefficients than in all previous models in this chapter. Why might that be?\n\n\n::: {.cell}\n::: {.cell-output-display}\n\n```{=html}\n<form name=\"form_4743\" onsubmit=\"return validate_form_4743()\" method=\"post\">\n<label>\n<input type=\"checkbox\" id=\"answer_4743_1\" value=\"Because knowing a participant&#39;s native language is a particularly useful predictor of Vocab scores.\"/>\nBecause knowing a participant's native language is a particularly useful predictor of Vocab scores.\n</label>\n<br/>\n<label>\n<input type=\"checkbox\" id=\"answer_4743_2\" value=\"Because the NativeLg variable includes 10 different levels.\"/>\nBecause the NativeLg variable includes 10 different levels.\n</label>\n<br/>\n<label>\n<input type=\"checkbox\" id=\"answer_4743_3\" value=\"Because a participant&#39;s native language is inherently connected to their English vocabulary knowledge.\"/>\nBecause a participant's native language is inherently connected to their English vocabulary knowledge.\n</label>\n<br/>\n<label>\n<input type=\"checkbox\" id=\"answer_4743_4\" value=\"Because the model&#39;s p-value is only just below 0.05.\"/>\nBecause the model's p-value is only just below 0.05.\n</label>\n<br/>\n<input type=\"submit\" value=\"Check answer\"/>\n<div id=\"result_4743\"></div>\n</form>\n<script>function validate_form_4743() {var text; var x1 = document.getElementById('answer_4743_1'); var x2 = document.getElementById('answer_4743_2'); var x3 = document.getElementById('answer_4743_3'); var x4 = document.getElementById('answer_4743_4'); if (x1.checked == false&x2.checked == true&x3.checked == false&x4.checked == false){text = 'That’s right, given that the dataset only includes 67 L2 participants, 10 different native languages is a lot! There is a strong risk that the model may overfit the data. The adjusted R-squared coefficient accounts for this by drastically reducing its estimation of the amount of variance in Vocab scores that can genuinely be accounted for by a model that only includes participants’ native language.';} else {text = 'No, that’s not the reason.';} document.getElementById('result_4743').innerHTML = text; evaluate_final_score(); return false;}function evaluate_final_score(){\n         element = document.getElementById('checkdown_final_score');\n         if(element === null){return false;} else {var element, text, res1, res2, res3, res4, res5, res6, res7, res8, res9;res1 = document.getElementById('result_53559').innerText == 'That’s right, well done!'; res2 = document.getElementById('result_35078').innerText == 'Awesome! Note that we also use the predict() function to extract the model’s predicted value for any combination of predictor values, e.g. predict(taskmodel1, data.frame(Blocks = 20))'; res3 = document.getElementById('result_20558').innerText == 'That’s right, well done!'; res4 = document.getElementById('result_68806').innerText == 'Indeed!'; res5 = document.getElementById('result_71636').innerText == 'Well done!'; res6 = document.getElementById('result_156').innerText == 'That’s right!'; res7 = document.getElementById('result_63340').innerText == 'You’re right. This statement is completely wrong: the model’s R-squared coefficients tell us how much of the variance in Vocab scores our model accounts for. The values of the multiple R-squared are always between 0 and 1: a value of 0 means that the model cannot predict anything using these predictors. A value of 1 means that it can make perfect predictions. Here, the multiple R-squared coefficient is almost 0 (0.0000187). In this model, the multiple R-squared coefficient is so low that, once adjusted, it falls slightly below zero. The adjustment made is based on the number of predictors (or, in the case of categorical predictors, the number of levels in each predictor) that are entered into the model.'; res8 = document.getElementById('result_1488').innerText == 'That’s right!'; res9 = document.getElementById('result_4743').innerText == 'That’s right, given that the dataset only includes 67 L2 participants, 10 different native languages is a lot! There is a strong risk that the model may overfit the data. The adjusted R-squared coefficient accounts for this by drastically reducing its estimation of the amount of variance in Vocab scores that can genuinely be accounted for by a model that only includes participants’ native language.';text = res1 + res2 + res3 + res4 + res5 + res6 + res7 + res8 + res9;element.innerHTML = text;\n         return false;\n         }}</script>\n```\n\n:::\n\n::: {.cell-output-display}\n\n```{=html}\n<div id=\"hint_57394\" onclick=\"return show_hint_57394()\">🐭 Click on the mouse for a hint.</div>\n<div id=\"result_57394\" onclick=\"return show_hint_57394()\"></div>\n<script>function show_hint_57394(){var x = document.getElementById('result_57394').innerHTML; if(!x){document.getElementById('result_57394').innerHTML = 'Only one of these reasons is correct.';} else {document.getElementById('result_57394').innerHTML = '';}}</script>\n```\n\n:::\n:::\n\n\n[**Q12.10**]{style=\"color:green;\"} One way to reduce the number of levels in the `NativeLg` variable is to model `Vocab` scores based on L2 participants' native language family, instead. Fit a model that attempts to predict `Vocab` scores among L2 participants based on the `NativeLgFamily` variable (the creation of this variable was a [Your turn!]{style=\"color:green;\"} task in @sec-casewhen). Based on your comparison of the two models, which of the following statements is/are true?\n\n\n::: {.cell}\n::: {.cell-output-display}\n\n```{=html}\n<form name=\"form_73058\" onsubmit=\"return validate_form_73058()\" method=\"post\">\n<label>\n<input type=\"checkbox\" id=\"answer_73058_1\" value=\"When adjusted for the number of predictors, the language family model is better at predicting Vocab scores.\"/>\nWhen adjusted for the number of predictors, the language family model is better at predicting Vocab scores.\n</label>\n<br/>\n<label>\n<input type=\"checkbox\" id=\"answer_73058_2\" value=\"When adjusted for the number of predictors, the language family model is worse at predicting Vocab scores.\"/>\nWhen adjusted for the number of predictors, the language family model is worse at predicting Vocab scores.\n</label>\n<br/>\n<label>\n<input type=\"checkbox\" id=\"answer_73058_3\" value=\"The more predictors there are, the easier it is to predict the Vocab scores of the sample. This is why the language family model has a lower multiple R-squared coefficient.\"/>\nThe more predictors there are, the easier it is to predict the Vocab scores of the sample. This is why the language family model has a lower multiple R-squared coefficient.\n</label>\n<br/>\n<label>\n<input type=\"checkbox\" id=\"answer_73058_4\" value=\"The language family model is statistically less significant than the other model because it features fewer predictors.\"/>\nThe language family model is statistically less significant than the other model because it features fewer predictors.\n</label>\n<br/>\n<input type=\"submit\" value=\"Check answer\"/>\n<div id=\"result_73058\"></div>\n</form>\n<script>function validate_form_73058() {var text; var x1 = document.getElementById('answer_73058_1'); var x2 = document.getElementById('answer_73058_2'); var x3 = document.getElementById('answer_73058_3'); var x4 = document.getElementById('answer_73058_4'); if (x1.checked == false&x2.checked == true&x3.checked == false&x4.checked == false){text = 'Yes, well done!';} else {text = 'No, not quite.';} document.getElementById('result_73058').innerHTML = text; evaluate_final_score(); return false;}function evaluate_final_score(){\n         element = document.getElementById('checkdown_final_score');\n         if(element === null){return false;} else {var element, text, res1, res2, res3, res4, res5, res6, res7, res8, res9, res10;res1 = document.getElementById('result_53559').innerText == 'That’s right, well done!'; res2 = document.getElementById('result_35078').innerText == 'Awesome! Note that we also use the predict() function to extract the model’s predicted value for any combination of predictor values, e.g. predict(taskmodel1, data.frame(Blocks = 20))'; res3 = document.getElementById('result_20558').innerText == 'That’s right, well done!'; res4 = document.getElementById('result_68806').innerText == 'Indeed!'; res5 = document.getElementById('result_71636').innerText == 'Well done!'; res6 = document.getElementById('result_156').innerText == 'That’s right!'; res7 = document.getElementById('result_63340').innerText == 'You’re right. This statement is completely wrong: the model’s R-squared coefficients tell us how much of the variance in Vocab scores our model accounts for. The values of the multiple R-squared are always between 0 and 1: a value of 0 means that the model cannot predict anything using these predictors. A value of 1 means that it can make perfect predictions. Here, the multiple R-squared coefficient is almost 0 (0.0000187). In this model, the multiple R-squared coefficient is so low that, once adjusted, it falls slightly below zero. The adjustment made is based on the number of predictors (or, in the case of categorical predictors, the number of levels in each predictor) that are entered into the model.'; res8 = document.getElementById('result_1488').innerText == 'That’s right!'; res9 = document.getElementById('result_4743').innerText == 'That’s right, given that the dataset only includes 67 L2 participants, 10 different native languages is a lot! There is a strong risk that the model may overfit the data. The adjusted R-squared coefficient accounts for this by drastically reducing its estimation of the amount of variance in Vocab scores that can genuinely be accounted for by a model that only includes participants’ native language.'; res10 = document.getElementById('result_73058').innerText == 'Yes, well done!';text = res1 + res2 + res3 + res4 + res5 + res6 + res7 + res8 + res9 + res10;element.innerHTML = text;\n         return false;\n         }}</script>\n```\n\n:::\n:::\n\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\" code-summary=\"Show code to answer Q.12.10\"}\ntaskmodel4 <- lm(formula = Vocab ~ NativeLgFamily,\n                data = L2.data) \n\nsummary(taskmodel4)\n```\n:::\n\n\n[**Q12.11**]{style=\"color:green;\"} According to your `NativeLgFamily` model, what is the predicted `Vocab` score of an L2 participant with a Baltic L1?\n\n\n::: {.cell}\n::: {.cell-output-display}\n\n```{=html}\n<form name=\"form_74201\" onsubmit=\"return validate_form_74201()\" method=\"post\">\n<label>\n<input type=\"radio\" name=\"answer_74201\" id=\"answer_74201_1\" value=\"0.1133\"/>\n0.1133\n</label>\n<br/>\n<label>\n<input type=\"radio\" name=\"answer_74201\" id=\"answer_74201_2\" value=\"9.497\"/>\n9.497\n</label>\n<br/>\n<label>\n<input type=\"radio\" name=\"answer_74201\" id=\"answer_74201_3\" value=\"7.768\"/>\n7.768\n</label>\n<br/>\n<label>\n<input type=\"radio\" name=\"answer_74201\" id=\"answer_74201_4\" value=\"73.778\"/>\n73.778\n</label>\n<br/>\n<label>\n<input type=\"radio\" name=\"answer_74201\" id=\"answer_74201_5\" value=\"-23.749\"/>\n-23.749\n</label>\n<br/>\n<input type=\"submit\" value=\"Check answer\"/>\n<div id=\"result_74201\"></div>\n</form>\n<script>function validate_form_74201() {var x, text; var x = document.forms['form_74201']['answer_74201'].value;if (x == '73.778'){text = 'Absolutely!';} else {text = 'No, check the hint if you can’t find the right coefficient.';} document.getElementById('result_74201').innerHTML = text; evaluate_final_score(); return false;}function evaluate_final_score(){\n         element = document.getElementById('checkdown_final_score');\n         if(element === null){return false;} else {var element, text, res1, res2, res3, res4, res5, res6, res7, res8, res9, res10, res11;res1 = document.getElementById('result_53559').innerText == 'That’s right, well done!'; res2 = document.getElementById('result_35078').innerText == 'Awesome! Note that we also use the predict() function to extract the model’s predicted value for any combination of predictor values, e.g. predict(taskmodel1, data.frame(Blocks = 20))'; res3 = document.getElementById('result_20558').innerText == 'That’s right, well done!'; res4 = document.getElementById('result_68806').innerText == 'Indeed!'; res5 = document.getElementById('result_71636').innerText == 'Well done!'; res6 = document.getElementById('result_156').innerText == 'That’s right!'; res7 = document.getElementById('result_63340').innerText == 'You’re right. This statement is completely wrong: the model’s R-squared coefficients tell us how much of the variance in Vocab scores our model accounts for. The values of the multiple R-squared are always between 0 and 1: a value of 0 means that the model cannot predict anything using these predictors. A value of 1 means that it can make perfect predictions. Here, the multiple R-squared coefficient is almost 0 (0.0000187). In this model, the multiple R-squared coefficient is so low that, once adjusted, it falls slightly below zero. The adjustment made is based on the number of predictors (or, in the case of categorical predictors, the number of levels in each predictor) that are entered into the model.'; res8 = document.getElementById('result_1488').innerText == 'That’s right!'; res9 = document.getElementById('result_4743').innerText == 'That’s right, given that the dataset only includes 67 L2 participants, 10 different native languages is a lot! There is a strong risk that the model may overfit the data. The adjusted R-squared coefficient accounts for this by drastically reducing its estimation of the amount of variance in Vocab scores that can genuinely be accounted for by a model that only includes participants’ native language.'; res10 = document.getElementById('result_73058').innerText == 'Yes, well done!'; res11 = document.getElementById('result_74201').innerText == 'Absolutely!';text = res1 + res2 + res3 + res4 + res5 + res6 + res7 + res8 + res9 + res10 + res11;element.innerHTML = text;\n         return false;\n         }}</script>\n```\n\n:::\n\n::: {.cell-output-display}\n\n```{=html}\n<div id=\"hint_89879\" onclick=\"return show_hint_89879()\">🐭 Click on the mouse for a hint.</div>\n<div id=\"result_89879\" onclick=\"return show_hint_89879()\"></div>\n<script>function show_hint_89879(){var x = document.getElementById('result_89879').innerHTML; if(!x){document.getElementById('result_89879').innerHTML = 'The Baltic language family is the first and, therefore reference, level in the variable <code>NativeLgFamily</code>.';} else {document.getElementById('result_89879').innerHTML = '';}}</script>\n```\n\n:::\n:::\n\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\" code-summary=\"Show sample code to answer Q12.11\"}\n# The Baltic language family is the first level in this categorical predictor (because we haven't changed the order which, by default, is alphabetical):\nlevels(L2.data$NativeLgFamily)\n\n# The Intercept coefficient corresponds to an L2 participant with a Baltic native language:\nsummary(taskmodel4)\n```\n:::\n\n\n[**Q12.12**]{style=\"color:green;\"} According to your `NativeLgFamily` model, what is the predicted `Vocab` score of an L2 participant with a Slavic L1?\n\n\n::: {.cell}\n::: {.cell-output-display}\n\n```{=html}\n<form name=\"form_93346\" onsubmit=\"return validate_form_93346()\" method=\"post\">\n<label>\n<input type=\"radio\" name=\"answer_93346\" id=\"answer_93346_1\" value=\"73.778\"/>\n73.778\n</label>\n<br/>\n<label>\n<input type=\"radio\" name=\"answer_93346\" id=\"answer_93346_2\" value=\"-23.749\"/>\n-23.749\n</label>\n<br/>\n<label>\n<input type=\"radio\" name=\"answer_93346\" id=\"answer_93346_3\" value=\"23.749\"/>\n23.749\n</label>\n<br/>\n<label>\n<input type=\"radio\" name=\"answer_93346\" id=\"answer_93346_4\" value=\"50.029\"/>\n50.029\n</label>\n<br/>\n<label>\n<input type=\"radio\" name=\"answer_93346\" id=\"answer_93346_5\" value=\"10.088\"/>\n10.088\n</label>\n<br/>\n<input type=\"submit\" value=\"Check answer\"/>\n<div id=\"result_93346\"></div>\n</form>\n<script>function validate_form_93346() {var x, text; var x = document.forms['form_93346']['answer_93346'].value;if (x == '50.029'){text = '✅ Absolutely!';} else {text = 'No, check the hint if you’re not sure how to proceed.';} document.getElementById('result_93346').innerHTML = text; evaluate_final_score(); return false;}function evaluate_final_score(){\n         element = document.getElementById('checkdown_final_score');\n         if(element === null){return false;} else {var element, text, res1, res2, res3, res4, res5, res6, res7, res8, res9, res10, res11, res12;res1 = document.getElementById('result_53559').innerText == 'That’s right, well done!'; res2 = document.getElementById('result_35078').innerText == 'Awesome! Note that we also use the predict() function to extract the model’s predicted value for any combination of predictor values, e.g. predict(taskmodel1, data.frame(Blocks = 20))'; res3 = document.getElementById('result_20558').innerText == 'That’s right, well done!'; res4 = document.getElementById('result_68806').innerText == 'Indeed!'; res5 = document.getElementById('result_71636').innerText == 'Well done!'; res6 = document.getElementById('result_156').innerText == 'That’s right!'; res7 = document.getElementById('result_63340').innerText == 'You’re right. This statement is completely wrong: the model’s R-squared coefficients tell us how much of the variance in Vocab scores our model accounts for. The values of the multiple R-squared are always between 0 and 1: a value of 0 means that the model cannot predict anything using these predictors. A value of 1 means that it can make perfect predictions. Here, the multiple R-squared coefficient is almost 0 (0.0000187). In this model, the multiple R-squared coefficient is so low that, once adjusted, it falls slightly below zero. The adjustment made is based on the number of predictors (or, in the case of categorical predictors, the number of levels in each predictor) that are entered into the model.'; res8 = document.getElementById('result_1488').innerText == 'That’s right!'; res9 = document.getElementById('result_4743').innerText == 'That’s right, given that the dataset only includes 67 L2 participants, 10 different native languages is a lot! There is a strong risk that the model may overfit the data. The adjusted R-squared coefficient accounts for this by drastically reducing its estimation of the amount of variance in Vocab scores that can genuinely be accounted for by a model that only includes participants’ native language.'; res10 = document.getElementById('result_73058').innerText == 'Yes, well done!'; res11 = document.getElementById('result_74201').innerText == 'Absolutely!'; res12 = document.getElementById('result_93346').innerText == '✅ Absolutely!';text = res1 + res2 + res3 + res4 + res5 + res6 + res7 + res8 + res9 + res10 + res11 + res12;element.innerHTML = text;\n         return false;\n         }}</script>\n```\n\n:::\n\n::: {.cell-output-display}\n\n```{=html}\n<div id=\"hint_93915\" onclick=\"return show_hint_93915()\">🐭 Click on the mouse for a hint.</div>\n<div id=\"result_93915\" onclick=\"return show_hint_93915()\"></div>\n<script>function show_hint_93915(){var x = document.getElementById('result_93915').innerHTML; if(!x){document.getElementById('result_93915').innerHTML = 'Remember that, to find the predicted score for Slavic L1 speakers, you need to add the Slavic L1 coefficient to the Intercept coefficient. Alternatively, you can plot the predicted values and read the prediction off the graph.';} else {document.getElementById('result_93915').innerHTML = '';}}</script>\n```\n\n:::\n:::\n\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\" code-summary=\"Show sample code to answer Q12.12\"}\n# a) Numeric approach\nsummary(taskmodel4)\n\n73.778 + -23.749\n\n# b) Graphical approach\nlibrary(visreg)\n\nvisreg(taskmodel4, gg = TRUE) +\n  labs(title = \"Participants' L1 language family\",\n       x = NULL,\n       y = \"Vocab scores\") +\n  theme_bw()\n\n# The predicted value for the Slavic L1 speakers is visualised by the last blue line.\n```\n:::\n\n\n[**Q12.13**]{style=\"color:green;\"} According to the `NativeLgFamily` model, Hellenic L1 speakers are predicted to perform considerably better than the reference level of Baltic L1 speakers. However, the *p*-value associated with this coefficient estimate is very large (`0.4591`). Why is that?\n\n\n::: {.cell}\n::: {.cell-output-display}\n\n```{=html}\n<form name=\"form_13651\" onsubmit=\"return validate_form_13651()\" method=\"post\">\n<label>\n<input type=\"radio\" name=\"answer_13651\" id=\"answer_13651_1\" value=\"Because the model chose a particularly low α-level.\"/>\nBecause the model chose a particularly low α-level.\n</label>\n<br/>\n<label>\n<input type=\"radio\" name=\"answer_13651\" id=\"answer_13651_2\" value=\"Because the data for Hellenic speakers is less reliable than for the other L2 speakers.\"/>\nBecause the data for Hellenic speakers is less reliable than for the other L2 speakers.\n</label>\n<br/>\n<label>\n<input type=\"radio\" name=\"answer_13651\" id=\"answer_13651_3\" value=\"Because p-values have nothing to do with effect sizes.\"/>\nBecause p-values have nothing to do with effect sizes.\n</label>\n<br/>\n<label>\n<input type=\"radio\" name=\"answer_13651\" id=\"answer_13651_4\" value=\"Because the dataset only includes one Greek L1 speaker.\"/>\nBecause the dataset only includes one Greek L1 speaker.\n</label>\n<br/>\n<input type=\"submit\" value=\"Check answer\"/>\n<div id=\"result_13651\"></div>\n</form>\n<script>function validate_form_13651() {var x, text; var x = document.forms['form_13651']['answer_13651'].value;if (x == 'Because the dataset only includes one Greek L1 speaker.'){text = 'Absolutely!';} else {text = 'No, check the hints if you’re not sure how to proceed. And remember that, if in doubt, visualisation is always a good idea!';} document.getElementById('result_13651').innerHTML = text; evaluate_final_score(); return false;}function evaluate_final_score(){\n         element = document.getElementById('checkdown_final_score');\n         if(element === null){return false;} else {var element, text, res1, res2, res3, res4, res5, res6, res7, res8, res9, res10, res11, res12, res13;res1 = document.getElementById('result_53559').innerText == 'That’s right, well done!'; res2 = document.getElementById('result_35078').innerText == 'Awesome! Note that we also use the predict() function to extract the model’s predicted value for any combination of predictor values, e.g. predict(taskmodel1, data.frame(Blocks = 20))'; res3 = document.getElementById('result_20558').innerText == 'That’s right, well done!'; res4 = document.getElementById('result_68806').innerText == 'Indeed!'; res5 = document.getElementById('result_71636').innerText == 'Well done!'; res6 = document.getElementById('result_156').innerText == 'That’s right!'; res7 = document.getElementById('result_63340').innerText == 'You’re right. This statement is completely wrong: the model’s R-squared coefficients tell us how much of the variance in Vocab scores our model accounts for. The values of the multiple R-squared are always between 0 and 1: a value of 0 means that the model cannot predict anything using these predictors. A value of 1 means that it can make perfect predictions. Here, the multiple R-squared coefficient is almost 0 (0.0000187). In this model, the multiple R-squared coefficient is so low that, once adjusted, it falls slightly below zero. The adjustment made is based on the number of predictors (or, in the case of categorical predictors, the number of levels in each predictor) that are entered into the model.'; res8 = document.getElementById('result_1488').innerText == 'That’s right!'; res9 = document.getElementById('result_4743').innerText == 'That’s right, given that the dataset only includes 67 L2 participants, 10 different native languages is a lot! There is a strong risk that the model may overfit the data. The adjusted R-squared coefficient accounts for this by drastically reducing its estimation of the amount of variance in Vocab scores that can genuinely be accounted for by a model that only includes participants’ native language.'; res10 = document.getElementById('result_73058').innerText == 'Yes, well done!'; res11 = document.getElementById('result_74201').innerText == 'Absolutely!'; res12 = document.getElementById('result_93346').innerText == '✅ Absolutely!'; res13 = document.getElementById('result_13651').innerText == 'Absolutely!';text = res1 + res2 + res3 + res4 + res5 + res6 + res7 + res8 + res9 + res10 + res11 + res12 + res13;element.innerHTML = text;\n         return false;\n         }}</script>\n```\n\n:::\n\n::: {.cell-output-display}\n\n```{=html}\n<div id=\"hint_78778\" onmouseover=\"return show_hint_78778()\">🦉 Hover over the owl for a first hint.</div>\n<div id=\"result_78778\" onmouseover=\"return show_hint_78778()\"></div>\n<script>function show_hint_78778(){var x = document.getElementById('result_78778').innerHTML; if(!x){document.getElementById('result_78778').innerHTML = 'It is never the model that chooses the α-level, but rather us, the researchers.';} else {document.getElementById('result_78778').innerHTML = '';}}</script>\n```\n\n:::\n\n::: {.cell-output-display}\n\n```{=html}\n<div id=\"hint_92916\" onclick=\"return show_hint_92916()\">🐭 Click on the mouse for a second hint.</div>\n<div id=\"result_92916\" onclick=\"return show_hint_92916()\"></div>\n<script>function show_hint_92916(){var x = document.getElementById('result_92916').innerHTML; if(!x){document.getElementById('result_92916').innerHTML = 'Remember that p-values depend on three different factors, see Section 11.3';} else {document.getElementById('result_92916').innerHTML = '';}}</script>\n```\n\n:::\n:::\n\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\" code-summary=\"Show sample code to answer Q12.13\"}\n# The plot of predicted values (see code below) shows that the coefficient estimate for Hellenic speakers is based on only one data point (as is also the case for Germanic speakers).\nlibrary(visreg)\nvisreg(taskmodel4, gg = TRUE) +\n  labs(title = \"Participants' L1 language family\",\n       x = NULL,\n       y = \"Vocab scores\") +\n  theme_bw()\n\n# We can check the distribution of native language family using the `table()`, `summary()` or `count()` functions:\ntable(L2.data$NativeLgFamily)\n\nsummary(L2.data$NativeLgFamily)\n\nL2.data |> \n  count(NativeLgFamily)\n```\n:::\n\n\n \n:::\n\n## Regression assumptions {#sec-AssumptionsLR}\n\nSimilar to the statistical tests that we conducted in @sec-Inferential, linear regression also has a number of assumptions that should be met if we want to obtain reliable results that we can trust. It is therefore very important that we check that these assumptions are met.\n\n### Assumption 1: Independence {#sec-IndependenceSLR}\n\nThis is the same assumption as for the statistical tests that we covered in @sec-Inferential (see @sec-Independence). It means that each observation in our dataset should be unrelated to every other observation. In other words, knowing the value of one data point shouldn't give us any information about any other data point in our dataset. This assumption is critical because violations can lead to unjustifiably low *p*-values and narrower confidence intervals.\n\nIndependence violations arise from the way data were collected. For example, if we test the same person several times, their test results are likely to be more similar to each other than to the results of other participants. Similarly, if we collect data over time, today's measurement might be influenced by yesterday's value. When pupils are sampled from different schools, pupils within the same school or class might be more similar to each other than to pupils from other schools and/or classes.\n\nIf our data do not meet the assumption of independence, we need to use a different analysis method that can account for the fact that our data points are related to each other. In the language sciences, this is most commonly achieved using **mixed-effects models**. In this textbook, however, we only cover **fixed-effects** **models** for which the assumption of independence must be held.\n\n::: {.callout-note collapse=\"false\"}\n### Further reading 📚 {.unnumbered}\n\nHere are some great starting points (in alphabetical order) to learn about mixed-effects models for linguistics research and how to fit them in `R`:\n\n-   @griesStatisticsLinguisticsPractical2021: Chapter 6\n-   @LevshinaHowlinguisticsData2015: Chapter 8\n-   @WinterStatisticsLinguistsIntroduction2019: Chapters 14-15\n:::\n\n### Assumption 2: Linearity {#sec-LinearitySLR}\n\nThe linearity assumption requires that the relationship between the numeric predictor variables entered into a model and the outcome variable follows a straight (i.e. linear) line rather than a curved one. This assumption is fundamental because linear regression, as the name suggests, can only ever fit a straight line through the data. If the true relationship between our predictors is curved, forcing a straight line through the data will lead to poor predictions and misleading conclusions.\n\nTo check this assumption, it is best to plot the predictor variable against the outcome variable in the form of a scatter plot (see @fig-RTScatterPLot). When examining such plots, we are looking for rough straight-line patterns. We are not expecting all the same data points to fall on the linear regression line (that would be entirely unrealistic with real data). However, the points should be scattered around an imaginary straight line without showing any obvious curved patterns.\n\nIn @fig-Nonlinear, by contrast, the data points follow a curved pattern. The regression line is forced to be straight, creating systematic prediction errors. Such a pattern of errors indicates that the assumption of linearity is violated.\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](12_SimpleLinearRegression_files/figure-html/fig-Nonlinear-1.png){#fig-Nonlinear width=576}\n:::\n:::\n\n\n### Assumption 3: Homogeneity of residuals {#sec-Residuals}\n\nLinear regression models assume homogeneity — or constant variance — of the residuals (see @sec-Homoscedasticity). This assumption is best checked by visually examining the model residuals. In @fig-VocabResidual, we plot the residuals of `model1` and check that their variability does not systematically increase or decrease as the outcome variable increases or decreases.\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\" code-summary=\"See code to generate plot.\"}\n# Create a data frame containing the model's residuals and predictions:\nresidual_data <- data.frame(\n  fitted_values = fitted(model1),\n  residuals = residuals(model1)\n)\n\n# Create plot of fitted values vs. residuals:\nggplot(residual_data, \n       aes(x = fitted_values, y = residuals)) +\n  geom_point(alpha = 0.6) +\n  geom_hline(yintercept = 0, color = \"blue\", linewidth = 1) +\n  labs(x = \"Predicted Vocab scores (fitted values)\", \n       y = \"Model residuals\") +\n  theme_minimal()\n```\n\n::: {.cell-output-display}\n![Comparison of model residuals with predicted vocabulary scores](12_SimpleLinearRegression_files/figure-html/fig-VocabResidual-1.png){#fig-VocabResidual width=576}\n:::\n:::\n\n\nIn @fig-VocabResidual, we can see that the residuals are not randomly spread across both sides of the blue line, but rather that they form a funnel-like shape: the spread of residuals tends to be larger for low predicted `Vocab` scores and becomes progressively smaller for higher predicted scores. This pattern indicates that our model is more accurate when it comes to predicting high `Vocab` scores than lower ones. This constitutes a violation of the assumption of equal variance or homoscedasticity.\n\n### Assumption 4: Normality of residuals {#sec-NormalityResiduals}\n\nIdeally, model residuals also ought to be normally distributed, with a mean of zero. However, this assumption becomes less important as the sample size increases [@williamsAssumptionsMultipleRegression2013: 10]. Again, it is best to check the distribution of residuals visually. As shown in @fig-VocabResidualDensity, the residuals of `model1` are fairly normally distributed.\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\" code-summary=\"See code to generate plot.\"}\nggplot(residual_data, \n       aes(x = residuals)) +\n  geom_density(fill = \"purple\",\n               alpha = 0.6) +\n  geom_vline(xintercept = 0,\n             colour = \"blue\",\n             linewidth = 0.8,\n             linetype = \"dotted\") +\n  theme_minimal()\n```\n\n::: {.cell-output-display}\n![Distribution of model residuals](12_SimpleLinearRegression_files/figure-html/fig-VocabResidualDensity-1.png){#fig-VocabResidualDensity width=576}\n:::\n:::\n\n\n@fig-VocabResidualDensity shows that the distribution of the residuals of `model1` are slightly left-skewed, but that the distribution is more or less centered around zero. Indeed, the model's mean residual is almost exactly zero:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsummary(model1$residuals)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n    Min.  1st Qu.   Median     Mean  3rd Qu.     Max. \n-57.7253 -10.7158   0.5255   0.0000  12.4168  36.0334 \n```\n\n\n:::\n:::\n\n\nWhen the sample size is small and the model residuals are not normally distributed, the inferences that we can draw from the model are less trustworthy. However, with larger sample sizes, regression is relatively robust to the assumption of normally distributed residuals [@williamsAssumptionsMultipleRegression2013: 3].\n\n## Intermediary summary\n\nIn this chapter, we fitted simple linear regression models. These models demonstrate that we can -- to a greater or lesser degree -- predict (or **model**) participants' receptive vocabulary knowledge test scores on the basis of a single predictor such as the number of years that they spent in formal education or their occupational group.\n\nWe have referred to the variable that we are trying to predict as the outcome variable. It is worth knowing that it is sometimes also called the **dependent variable** because we are attempting to model its 'dependence' on one or more **independent variables** (which we have called predictors). In @sec-MLR, we will continue to use the terminology of **outcome** and **predictor** variables, but you should be aware that some textbooks and researchers will speak of dependent and independent variables, instead.[^12_simplelinearregression-1]\n\n[^12_simplelinearregression-1]: This choice of terminology is largely a personal one but, in my experience, learners find this terminology less confusing as it is immediately obvious what is being predicted (the outcome or dependent variable) and what is used to make the prediction (the predictors or the independent variables). Another advantage is that the term predictor can be used by itself (i.e., without the word \"variable\"), which is handy because when we enter a categorical variable into a model, there are as many predictors as there are variable levels.\n\nWhile our simple linear regression models did allow us to account for some of the variance in participants' `Vocab` test scores, like the statistical tests that we conducted in @sec-Inferential, they still only allow us to capture one aspect of receptive vocabulary knowledge at a time. What we really want to do is to be able to enter several predictor variables into a single model. For example, it would be interesting to know whether the number of years spent in formal education remains a significant predictor of `Vocab` scores when controlling for participants' occupational groups. This can be achieved with multiple linear regression, and that's coming up in the next chapter!\n\n### Check your progress 🌟 {.unnumbered}\n\nWell done! You have successfully completed this chapter introducing the linear regression modelling. You have answered [`<span id=\"checkdown_final_score\">0</span>`{=html} out of 13 questions]{style=\"color:green;\"} correctly.\n\nAre you confident that you can...?\n\n-   [ ] Fit a simple linear model to predict a numeric outcome variable\n-   [ ] Visualise the predictions of a simple linear regression model\n-   [ ] Find out what the intercept of a model corresponds to and interpret the model's coefficient estimates\n-   [ ] Interpret a model's adjusted R^2^ coefficient\n-   [ ] Check for the main assumptions of linear regression: independence, linearity, homoscedasticity, and normality of residuals (@sec-AssumptionsLR)\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}