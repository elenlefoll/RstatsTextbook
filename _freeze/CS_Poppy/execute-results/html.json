{
  "hash": "f0a88bc50f74c675fdb0a5eaede7ad3e",
  "result": {
    "engine": "knitr",
    "markdown": "---\nauthor: \"Poppy Siahaan\"\ndate: \"2024-11-15\"\ntoc-title: \"Case study: 'Throw' verbs in Spanish\"\ninclude-after-body: abbrv_toc.html\n---\n\n\n\n\n# 'Throw' verbs in Spanish: Rep`R`oducing the results of a corpus linguistics study\n\n\n\n\n\n\n\n\n\n::: {.callout-note collapse=\"true\"}\n#### **About the author of this chapter** {.unnumbered}\n\n**Poppy Siahaan** \\[p…îpi siaha îan\\] is a lecturer at the Institute of Languages and Cultures of the Islamicate World at the University of Cologne. She has a keen interest in semantics, particularly metaphors, and studies the connections between language, culture, the body, and cognition, including speech-accompanying gestures. Recently, she has also been exploring the fascinating world of `R`.\n\nPoppy attended Elen Le Foll's seminar \"More than counting words: Introduction to statistics and data visualisation in R\" (University of Cologne, summer 2024) as a guest student and wrote an earlier version of this chapter as part of this seminar. Elen contributed to the present revised version of this chapter.\n:::\n\n#### **Chapter overview** {.unnumbered}\n\nThis chapter will guide you through the steps to reproduce the results of a published corpus linguistics study [@vanhulleCategoryThrowVerbs2024] using `R`.\n\nThe chapter will walk you through how to:\n\n-   Download the authors' original data [@vanhulleReplicationDataCategory2024] and load it in `R`\n-   Understand the structure of the data\n-   Wrangle the data to reproduce Tables 5 and 8 from @vanhulleCategoryThrowVerbs2024\n-   Calculate the normalized frequencies as reported in @vanhulleCategoryThrowVerbs2024\n-   Calculate the type/token ratios as reported in @vanhulleCategoryThrowVerbs2024\n-   Compare our results with those printed in @vanhulleCategoryThrowVerbs2024\n-   Visualize our results as line plots using {ggplot2} to facilitate the interpretation of the results\n\n## Introducing the study\n\nIn this chapter, we attempt to reproduce the results of a corpus linguistics study by @vanhulleCategoryThrowVerbs2024, published as a book chapter in a volume edited by @pfadenhauerRomanceMotionVerbs2024. The study focuses on the development of five throw verbs in Peninsular Spanish: *echar*, *lanzar*, *disparar*, *tirar*, and *arrojar* [@vanhulleCategoryThrowVerbs2024]. These verbs have evolved into aspectual auxiliaries in inchoative constructions that convey the beginning of an event. @vanhulleCategoryThrowVerbs2024 use historical data to trace the evolution of these verbs, and contemporary data to analyse their usage in micro-constructions. Below are examples of the five throw verbs in inchoative constructions [all taken from @vanhulleCategoryThrowVerbs2024].\n\n1.  Los nuevos rebeldes ***se arrojaron** a atacar* al sistema de control social. (‚ÄòThe new rebels *started (lit. ‚Äòthrew/launched themselves‚Äô) to attack* the system of social control.‚Äô)\n2.  El ni√±o abri√≥ los ojos y ***ech√≥** a correr* de regreso a su casa. (‚ÄòThe child opened his eyes and *started (lit. ‚Äòthrew‚Äô) to run* back to his house.‚Äô)\n3.  El grupo de investigaci√≥n ***se lanz√≥** a analizar* otros par√°metros. (‚ÄòThe investigation group *started (lit. ‚Äòlaunched itself‚Äô) to analyse* other parameters.‚Äô)\n4.  Decid√≠ no ***tirarme** a llorar* y empec√© a buscar algo que me ayudara. (‚ÄòI decided not to *start (lit. ‚Äòthrow myself‚Äô) to cry* and I started to look for something that would help me.‚Äô)\n5.  Y todos ***dispararon** a correr*, sin volver la cabeza atr√°s. (‚ÄòAnd everybody *started (lit. ‚Äòshot‚Äô) to run*, without looking back.‚Äô)\n\n::: callout-tip\n#### Quiz time! {.unnumbered}\n\nFollow the study's DOI link and read the abstract to learn about the study's research focus.\n\n> Van Hulle, Sven & Renata Enghels. 2024. The category of throw verbs as productive source of the Spanish inchoative construction. In Katrin Pfadenhauer & Evelyn Wiesinger (eds.), Romance motion verbs in language change, 213‚Äì240. De Gruyter. <https://doi.org/10.1515/9783111248141-009>.\n\n[**Q1.**]{style=\"color:green;\"} What is the main focus of this study?\n\n\n\n\n::: {.cell}\n::: {.cell-output-display}\n\n```{=html}\n<form name=\"form_16078\" onsubmit=\"return validate_form_16078()\" method=\"post\">\n<input type=\"checkbox\" id=\"answer_16078_1\" value=\"The relationship between inchoative constructions and nouns of motion.\"/>\n<label>The relationship between inchoative constructions and nouns of motion.</label>\n<br/>\n<input type=\"checkbox\" id=\"answer_16078_2\" value=\"The role of spatial expressions in the process of grammaticalization.\"/>\n<label>The role of spatial expressions in the process of grammaticalization.</label>\n<br/>\n<input type=\"checkbox\" id=\"answer_16078_3\" value=\"The development of &#39;throw&#39; verbs as aspectual auxiliaries.\"/>\n<label>The development of 'throw' verbs as aspectual auxiliaries.</label>\n<br/>\n<input type=\"checkbox\" id=\"answer_16078_4\" value=\"Semantic differences between the five Spanish &#39;throw&#39; verbs.\"/>\n<label>Semantic differences between the five Spanish 'throw' verbs.</label>\n<br/>\n<input type=\"submit\" value=\"Check answer\"/>\n<div id=\"result_16078\"></div>\n</form>\n<script>function validate_form_16078() {var text; var x1 = document.getElementById('answer_16078_1'); var x2 = document.getElementById('answer_16078_2'); var x3 = document.getElementById('answer_16078_3'); var x4 = document.getElementById('answer_16078_4'); if (x1.checked == false&x2.checked == false&x3.checked == true&x4.checked == false){text = 'That‚Äôs right!';} else {text = 'No, read the abstract again.';} document.getElementById('result_16078').innerHTML = text; evaluate_final_score(); return false;}function evaluate_final_score(){\n         element = document.getElementById('checkdown_final_score');\n         if(element === null){return false;} else {var element, text, res1;res1 = document.getElementById('result_16078').innerText == 'That‚Äôs right!';text = res1;element.innerHTML = text;\n         return false;\n         }}</script>\n```\n\n:::\n:::\n\n\n\n\n[**Q2.**]{style=\"color:green;\"} According to the study, what semantic features help explain the connection between 'throw' verbs and inchoative constructions?\n\n\n\n\n::: {.cell}\n::: {.cell-output-display}\n\n```{=html}\n<form name=\"form_61358\" onsubmit=\"return validate_form_61358()\" method=\"post\">\n<input type=\"checkbox\" id=\"answer_61358_1\" value=\"The ability of &#39;throw&#39; verbs to convey accuracy and control.\"/>\n<label>The ability of 'throw' verbs to convey accuracy and control.</label>\n<br/>\n<input type=\"checkbox\" id=\"answer_61358_2\" value=\"The meaning of abruptness and the interruption of inertia.\"/>\n<label>The meaning of abruptness and the interruption of inertia.</label>\n<br/>\n<input type=\"checkbox\" id=\"answer_61358_3\" value=\"The shift in meaning from the concrete to the abstract.\"/>\n<label>The shift in meaning from the concrete to the abstract.</label>\n<br/>\n<input type=\"checkbox\" id=\"answer_61358_4\" value=\"The aspect of moving towards a specified destination.\"/>\n<label>The aspect of moving towards a specified destination.</label>\n<br/>\n<input type=\"submit\" value=\"Check answer\"/>\n<div id=\"result_61358\"></div>\n</form>\n<script>function validate_form_61358() {var text; var x1 = document.getElementById('answer_61358_1'); var x2 = document.getElementById('answer_61358_2'); var x3 = document.getElementById('answer_61358_3'); var x4 = document.getElementById('answer_61358_4'); if (x1.checked == false&x2.checked == true&x3.checked == true&x4.checked == false){text = 'That‚Äôs right!';} else {text = 'Not quite. Read the abstract again.';} document.getElementById('result_61358').innerHTML = text; evaluate_final_score(); return false;}function evaluate_final_score(){\n         element = document.getElementById('checkdown_final_score');\n         if(element === null){return false;} else {var element, text, res1, res2;res1 = document.getElementById('result_16078').innerText == 'That‚Äôs right!'; res2 = document.getElementById('result_61358').innerText == 'That‚Äôs right!';text = res1 + res2;element.innerHTML = text;\n         return false;\n         }}</script>\n```\n\n:::\n\n::: {.cell-output-display}\n\n```{=html}\n<div id=\"hint_83942\" onclick=\"return show_hint_83942()\">üê≠ Click on the mouse for a hint.</div>\n<div id=\"result_83942\" onclick=\"return show_hint_83942()\"></div>\n<script>function show_hint_83942(){var x = document.getElementById('result_83942').innerHTML; if(!x){document.getElementById('result_83942').innerHTML = 'Two semantic features are mentioned in the abstract.';} else {document.getElementById('result_83942').innerHTML = '';}}</script>\n```\n\n:::\n:::\n\n\n\n:::\n\nIn this chapter, we will use the authors' original data to reproduce Tables 5 and 8 [@vanhulleCategoryThrowVerbs2024: 227, 232], as well as visualising the data with a series of informative line plots to facilitate interpretation.\n\n## Retrieving the authors' original data {#sec-ThrowData toc-text=\"Retrieving the data\"}\n\nIn the spirit of Open Science (see @sec-OpenScience), @vanhulleCategoryThrowVerbs2024 have made their research data openly accessible on the Troms√∏ Repository of Language and Linguistics (TROLLing):\n\n> Van Hulle, Sven & Renata Enghels. 2024. Replication Data for: ‚ÄúThe category of throw verbs as productive source of the Spanish inchoative construction.‚Äù DataverseNO. Version 1. <https://doi.org/10.18710/TR2PWJ>.\n\nFollow the link and read the description of the dataset. Next, scroll down the page where three different downloadable files are listed.\n\n-   `0_ReadME_Spanish_ThrowVerbs_Inchoatives_20230413.txt` This is a text \"file which provides general information about the nature of the dataset and how the data was collected and annotated, and brief data-specific information for each file belonging to this dataset\" [@vanhulleReplicationDataCategory2024].\n\n-   `Spanish_ThrowVerbs_Inchoatives_20230413.csv` This is a comma-separated file (see @sec-DSV) which \"contains the input data for the analysis, including the variables 'AUX', 'Century', 'INF' and 'Class', for the throw verbs *arrojar, disparar, echar, lanzar* and *tirar*\" [@vanhulleReplicationDataCategory2024].\n\n-   `Spanish_ThrowVerbs_Inchoatives_queries_20230413.txt` \"This file specifies all corpus queries \"that were used to download the samples per auxiliary from the Spanish Web corpus (esTenTen18), that was accessed via Sketch Engine, and from the Corpus Diacr√≥nico del Espa√±ol (CORDE)\" [@vanhulleReplicationDataCategory2024].\n\nIn corpus linguistics, it is often the case that corpora cannot be openly shared for copyright and/or data protection reasons. Instead, authors who strive to make their work transparent and reproducible can share details of the corpora that they analysed and of the specific corpus queries they used, so that the data that they share are only the results of the queries.\n\nAs we are interested in the frequencies retrieved from the corpora, we download the CSV file `Spanish_ThrowVerbs_Inchoatives_20230413.csv`.\n\n::: callout-tip\n#### Quiz time! {.unnumbered}\n\n[**Q3.**]{style=\"color:green;\"} Where did the data for @vanhulleReplicationDataCategory2024's study on the five Spanish 'throw' verbs come from?\n\n\n\n\n::: {.cell}\n::: {.cell-output-display}\n\n```{=html}\n<form name=\"form_46876\" onsubmit=\"return validate_form_46876()\" method=\"post\">\n<input type=\"checkbox\" id=\"answer_46876_1\" value=\"For the contemporary data, from the Spanish corpus of the Troms√∏ Repository of Language and Linguistics.\"/>\n<label>For the contemporary data, from the Spanish corpus of the Troms√∏ Repository of Language and Linguistics.</label>\n<br/>\n<input type=\"checkbox\" id=\"answer_46876_2\" value=\"For all occurrences of &#39;throw&#39; verbs, from the European Spanish Web Corpus (esTenTen18).\"/>\n<label>For all occurrences of 'throw' verbs, from the European Spanish Web Corpus (esTenTen18).</label>\n<br/>\n<input type=\"checkbox\" id=\"answer_46876_3\" value=\"For the contemporary data, from the European Spanish subcorpus of the Spanish Web Corpus (esTenTen18).\"/>\n<label>For the contemporary data, from the European Spanish subcorpus of the Spanish Web Corpus (esTenTen18).</label>\n<br/>\n<input type=\"checkbox\" id=\"answer_46876_4\" value=\"For the historical data, from the Corpus Diacr√≥nico del Espa√±ol (CORDE).\"/>\n<label>For the historical data, from the Corpus Diacr√≥nico del Espa√±ol (CORDE).</label>\n<br/>\n<input type=\"submit\" value=\"Check answer\"/>\n<div id=\"result_46876\"></div>\n</form>\n<script>function validate_form_46876() {var text; var x1 = document.getElementById('answer_46876_1'); var x2 = document.getElementById('answer_46876_2'); var x3 = document.getElementById('answer_46876_3'); var x4 = document.getElementById('answer_46876_4'); if (x1.checked == false&x2.checked == false&x3.checked == true&x4.checked == true){text = 'That‚Äôs right!';} else {text = 'Not quite. Read the description of the dataset again.';} document.getElementById('result_46876').innerHTML = text; evaluate_final_score(); return false;}function evaluate_final_score(){\n         element = document.getElementById('checkdown_final_score');\n         if(element === null){return false;} else {var element, text, res1, res2, res3;res1 = document.getElementById('result_16078').innerText == 'That‚Äôs right!'; res2 = document.getElementById('result_61358').innerText == 'That‚Äôs right!'; res3 = document.getElementById('result_46876').innerText == 'That‚Äôs right!';text = res1 + res2 + res3;element.innerHTML = text;\n         return false;\n         }}</script>\n```\n\n:::\n\n::: {.cell-output-display}\n\n```{=html}\n<div id=\"hint_25724\" onclick=\"return show_hint_25724()\">üê≠ Click on the mouse for a hint.</div>\n<div id=\"result_25724\" onclick=\"return show_hint_25724()\"></div>\n<script>function show_hint_25724(){var x = document.getElementById('result_25724').innerHTML; if(!x){document.getElementById('result_25724').innerHTML = 'The data came from two different corpora.';} else {document.getElementById('result_25724').innerHTML = '';}}</script>\n```\n\n:::\n:::\n\n\n\n\n<br>\n\n[**Q4.**]{style=\"color:green;\"} What does the term \"false positive\" refer to in the context of this study?\n\n\n\n\n::: {.cell}\n::: {.cell-output-display}\n\n```{=html}\n<form name=\"form_79660\" onsubmit=\"return validate_form_79660()\" method=\"post\">\n<input type=\"radio\" name=\"answer_79660\" id=\"answer_79660_1\" value=\"Tokens that represent infinitives following &#39;a&#39; with an incorrect auxiliary.\"/>\n<label>Tokens that represent infinitives following 'a' with an incorrect auxiliary.</label>\n<br/>\n<input type=\"radio\" name=\"answer_79660\" id=\"answer_79660_2\" value=\"Tokens removed due to being irrelevant to the study&#39;s focus on &#39;throw&#39; verbs.\"/>\n<label>Tokens removed due to being irrelevant to the study's focus on 'throw' verbs.</label>\n<br/>\n<input type=\"radio\" name=\"answer_79660\" id=\"answer_79660_3\" value=\"Tags that incorrectly label nouns as infinitives or misidentify inchoative constructions.\"/>\n<label>Tags that incorrectly label nouns as infinitives or misidentify inchoative constructions.</label>\n<br/>\n<input type=\"radio\" name=\"answer_79660\" id=\"answer_79660_4\" value=\"Tokens that were correctly identified as inchoative constructions.\"/>\n<label>Tokens that were correctly identified as inchoative constructions.</label>\n<br/>\n<input type=\"submit\" value=\"Check answer\"/>\n<div id=\"result_79660\"></div>\n</form>\n<script>function validate_form_79660() {var x, text; var x = document.forms['form_79660']['answer_79660'].value;if (x == 'Tags that incorrectly label nouns as infinitives or misidentify inchoative constructions.'){text = 'That‚Äôs right!';} else {text = 'Not quite. Read the description of the dataset again.';} document.getElementById('result_79660').innerHTML = text; evaluate_final_score(); return false;}function evaluate_final_score(){\n         element = document.getElementById('checkdown_final_score');\n         if(element === null){return false;} else {var element, text, res1, res2, res3, res4;res1 = document.getElementById('result_16078').innerText == 'That‚Äôs right!'; res2 = document.getElementById('result_61358').innerText == 'That‚Äôs right!'; res3 = document.getElementById('result_46876').innerText == 'That‚Äôs right!'; res4 = document.getElementById('result_79660').innerText == 'That‚Äôs right!';text = res1 + res2 + res3 + res4;element.innerHTML = text;\n         return false;\n         }}</script>\n```\n\n:::\n:::\n\n\n\n:::\n\n## Impo`R`ting the authors' original data {#sec-ImportingVanHulle toc-text=\"Impo`R`ting the data\"}\n\nBefore we can import the dataset, we need to load all the packages that we will need for this project. Note that you may need to install some of these packages first (see @sec-Packages for instructions).\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Loading required packages for this project\nlibrary(here)\nlibrary(tidyverse)\nlibrary(xfun)\n```\n:::\n\n\n\n\nNext, we import the dataset containing the number of occurrences of 'throw' verbs in the corpora analysed in @vanhulleCategoryThrowVerbs2024 (`Spanish_ThrowVerbs_Inchoatives_20230413.csv`) as a new object called `spanish.data`. You will need to adjust the file path to match the folder structure of your computer (see @sec-ImportingDataCSV).\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Importing the Spanish verbs dataset\nspanish.data <- read.csv(file = here(\"data\", \"Spanish_ThrowVerbs_Inchoatives_20230413.csv\"),\n                    header = TRUE,\n                    sep = \"\\t\",\n                    quote = \"\\\"\",\n                    dec = \".\")\n```\n:::\n\n\n\n\nWe check the sanity of the imported data by visually examining the output of `View(spanish.data)` (@fig-screenShot).\n\n![Screenshot showing part of the dataset using the `View()` function.](images/Poppy_viewSpanishData.png){#fig-screenShot fig-alt=\"The figure displays a table with four columns labeled AUX, Century, INF, and Class, representing Auxiliary, Century, Infinitive, and Semantic Class, respectively. The data shows pairings of auxiliaries with infinitives and their corresponding semantic classes across different centuries. For example, the auxiliary lanzar is paired with the infinitive llevar under the semantic class 'Desplazamiento' (Movement), while echar is paired with dormir under 'Fisiolog√≠a' (Physiology). The table contains 2,882 entries, with a preview of the first 15 rows shown here.\" width=\"413\"}\n\nAs you can see in @fig-screenShot, the dataset contains 2882 rows (i.e., the number of occurrences of 'throw' verbs observed in the corpora) and 4 columns (i.e., variables describing these observations).\n\nThe readme file delivered with the data (`0_ReadME_Spanish_ThrowVerbs_Inchoatives_20230413.txt`) describes the variables as follows:\n\n```         \n-----------------------------------------\nDATA-SPECIFIC INFORMATION FOR: Spanish_ThrowVerbs_Inchoatives_20230413.csv\n-----------------------------------------\n\n#   Variable    Explanation\n\n1   AUX         This column contains the inchoative auxiliary. [...]\n\n2   Century     This column contains the century to which the concrete example belongs. \n\n3   INF         This column contains the infinitive observed in the filler slot of the inchoative construction. \n\n4   Class       This column contains the semantical class to which the infinitive belongs, based on the classification of ADESSE. This lexical classification classifies Spanish verbs in semantic groups, which we adopted for the annotation (http://adesse.uvigo.es/data) (@ref Garc√≠a-Miguel & Albertuz 2005). [...]\n\n¬†\n```\n\nTo obtain a list of all the 'throw' verbs included in the dataset and their total frequencies, we use the familiar `count()` function from {dyplr} (see [Chapter 9](https://elenlefoll.github.io/RstatsTextbook/9_DataWrangling.html)).\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nspanish.data |> \n  count(AUX)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n       AUX    n\n1  arrojar  160\n2 disparar    8\n3    echar 1936\n4   lanzar  680\n5    tirar   98\n```\n\n\n:::\n:::\n\n\n\n\nAs you can see, there are five 'throw' verbs in the dataset: *echar*, *lanzar*, *tirar*, *arrojar*, and *disparar*. The most frequent one is *echar*.\n\n::: callout-tip\n#### Quiz time! {.unnumbered}\n\n[**Q5.**]{style=\"color:green;\"} Which column in the dataset contains the general meaning of the verbs in the filler slot of the inchoative construction?\n\n\n\n\n::: {.cell}\n::: {.cell-output-display}\n\n```{=html}\n<form name=\"form_12425\" onsubmit=\"return validate_form_12425()\" method=\"post\">\n<input type=\"radio\" name=\"answer_12425\" id=\"answer_12425_1\" value=\"AUX\"/>\n<label>AUX</label>\n<br/>\n<input type=\"radio\" name=\"answer_12425\" id=\"answer_12425_2\" value=\"INF\"/>\n<label>INF</label>\n<br/>\n<input type=\"radio\" name=\"answer_12425\" id=\"answer_12425_3\" value=\"Century\"/>\n<label>Century</label>\n<br/>\n<input type=\"radio\" name=\"answer_12425\" id=\"answer_12425_4\" value=\"Class\"/>\n<label>Class</label>\n<br/>\n<input type=\"submit\" value=\"Check answer\"/>\n<div id=\"result_12425\"></div>\n</form>\n<script>function validate_form_12425() {var x, text; var x = document.forms['form_12425']['answer_12425'].value;if (x == 'Class'){text = 'That‚Äôs right!';} else {text = 'No, you are looking for the column that contains semantic information about the inifinite verbs in these inchoative constructions.';} document.getElementById('result_12425').innerHTML = text; evaluate_final_score(); return false;}function evaluate_final_score(){\n         element = document.getElementById('checkdown_final_score');\n         if(element === null){return false;} else {var element, text, res1, res2, res3, res4, res5;res1 = document.getElementById('result_16078').innerText == 'That‚Äôs right!'; res2 = document.getElementById('result_61358').innerText == 'That‚Äôs right!'; res3 = document.getElementById('result_46876').innerText == 'That‚Äôs right!'; res4 = document.getElementById('result_79660').innerText == 'That‚Äôs right!'; res5 = document.getElementById('result_12425').innerText == 'That‚Äôs right!';text = res1 + res2 + res3 + res4 + res5;element.innerHTML = text;\n         return false;\n         }}</script>\n```\n\n:::\n:::\n\n\n\n\n[**Q6.**]{style=\"color:green;\"} Which of the following verbs is classified under the semantic category '*Desplazamiento*' ('movement')?\n\n\n\n\n::: {.cell}\n::: {.cell-output-display}\n\n```{=html}\n<form name=\"form_62972\" onsubmit=\"return validate_form_62972()\" method=\"post\">\n<input type=\"checkbox\" id=\"answer_62972_1\" value=\"dormir\"/>\n<label>dormir</label>\n<br/>\n<input type=\"checkbox\" id=\"answer_62972_2\" value=\"atacar\"/>\n<label>atacar</label>\n<br/>\n<input type=\"checkbox\" id=\"answer_62972_3\" value=\"llevar\"/>\n<label>llevar</label>\n<br/>\n<input type=\"checkbox\" id=\"answer_62972_4\" value=\"hacer\"/>\n<label>hacer</label>\n<br/>\n<input type=\"submit\" value=\"Check answer\"/>\n<div id=\"result_62972\"></div>\n</form>\n<script>function validate_form_62972() {var text; var x1 = document.getElementById('answer_62972_1'); var x2 = document.getElementById('answer_62972_2'); var x3 = document.getElementById('answer_62972_3'); var x4 = document.getElementById('answer_62972_4'); if (x1.checked == false&x2.checked == false&x3.checked == true&x4.checked == false){text = 'That‚Äôs right!';} else {text = 'No, check the hint if you‚Äôre unsure how to find the correct answer.';} document.getElementById('result_62972').innerHTML = text; evaluate_final_score(); return false;}function evaluate_final_score(){\n         element = document.getElementById('checkdown_final_score');\n         if(element === null){return false;} else {var element, text, res1, res2, res3, res4, res5, res6;res1 = document.getElementById('result_16078').innerText == 'That‚Äôs right!'; res2 = document.getElementById('result_61358').innerText == 'That‚Äôs right!'; res3 = document.getElementById('result_46876').innerText == 'That‚Äôs right!'; res4 = document.getElementById('result_79660').innerText == 'That‚Äôs right!'; res5 = document.getElementById('result_12425').innerText == 'That‚Äôs right!'; res6 = document.getElementById('result_62972').innerText == 'That‚Äôs right!';text = res1 + res2 + res3 + res4 + res5 + res6;element.innerHTML = text;\n         return false;\n         }}</script>\n```\n\n:::\n\n::: {.cell-output-display}\n\n```{=html}\n<div id=\"hint_78616\" onclick=\"return show_hint_78616()\">üê≠ Click on the mouse for a hint.</div>\n<div id=\"result_78616\" onclick=\"return show_hint_78616()\"></div>\n<script>function show_hint_78616(){var x = document.getElementById('result_78616').innerHTML; if(!x){document.getElementById('result_78616').innerHTML = 'Run the <code>sum()</code> command to calculate the number of occurrences of each verb within the <code>Class</code> ‚ÄúDesplazamiento‚Äù, e.g., <code>sum(spanish.data$INF == &quot;dormir&quot; &amp; spanish.data$Class == &quot;Desplazamiento&quot;)</code>.';} else {document.getElementById('result_78616').innerHTML = '';}}</script>\n```\n\n:::\n:::\n\n\n\n:::\n\n## Token (absolute) frequency\n\nAccording to Gries & Ellis [-@griesStatisticalMeasuresUsageBased2015: 232]:\n\n> \"Token frequency counts how often a particular form appears in the input.\"\n\nIn @vanhulleCategoryThrowVerbs2024, token frequency refers to the number of occurrences of combinations of 'throw' verbs and infinitives in inchoative constructions, as identified in the corpora queried for this study (see @sec-ThrowData).\n\n### Creating a table of token frequencies {#sec-TokenFreqTable}\n\nFirst of all, we want to find out how often each 'throw' verb was observed in each century. To do so, we use the `count()` function to output the number of corpus occurrences for all possible combinations of the `AUX` and `Century` variables. Then, we pipe this output into an `arrange()` command to order the rows of the table by the values of the `Century` and `AUX` columns (as shown in @tbl-Freq below), prioritising the order of the `Century` over the alphabetical order of the `AUX`. This ensures that the centuries are ordered correctly from the 13^th^ to the 21^st^ century, rather than being jumbled. We store this summary table (see @tbl-Freq) as a new `R` object called `verbs.investigated`.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nverbs.investigated <- spanish.data |>\n  count(AUX, Century, sort = TRUE) |> \n  arrange(Century, AUX)\n```\n:::\n\n\n\n\n@tbl-Freq contains 26 rows and three columns, `AUX`, `Century`, both from the original dataset, and `n` which contains the number of occurrences for each combination of the `Century`and `AUX` variables. For example, the verb *echar* occurs 32, 15, and 101 times in the corpus data from the 13^th^, 14^th^, and 15^th^ centuries respectively and so on.\n\n\n\n\n::: {#tbl-Freq .cell tbl-cap='Frequency of each Spanish \\'throw\\' verb in each century'}\n::: {.cell-output-display}\n\n\n|AUX      | Century|   n|\n|:--------|-------:|---:|\n|echar    |      13|  32|\n|echar    |      14|  15|\n|echar    |      15| 101|\n|tirar    |      15|   2|\n|arrojar  |      16|  20|\n|echar    |      16| 153|\n|arrojar  |      17|  47|\n|disparar |      17|   3|\n|echar    |      17|  95|\n|arrojar  |      18|  16|\n|echar    |      18|  40|\n|tirar    |      18|   8|\n|arrojar  |      19|  38|\n|disparar |      19|   1|\n|echar    |      19| 500|\n|lanzar   |      19|  55|\n|arrojar  |      20|  11|\n|disparar |      20|   1|\n|echar    |      20| 500|\n|lanzar   |      20| 125|\n|tirar    |      20|   7|\n|arrojar  |      21|  28|\n|disparar |      21|   3|\n|echar    |      21| 500|\n|lanzar   |      21| 500|\n|tirar    |      21|  81|\n\n\n:::\n:::\n\n\n\n\nWe will now attempt to reproduce \"Table 4: General overview of the dataset\" [@vanhulleCategoryThrowVerbs2024: 225], reprinted below as @tbl-absPaper.\n\n\n\n\n::: {#tbl-absPaper .cell tbl-cap='Absolute token frequency of Spanish \\'throw\\' verbs as reported in van Hulle & Enghels [-@vanhulleCategoryThrowVerbs2024: 225]'}\n::: {.cell-output-display}\n\n\n|AUX      |13 |14 |15  |16  |17  |18 |19  |20  |21   |Total |\n|:--------|:--|:--|:---|:---|:---|:--|:---|:---|:----|:-----|\n|arrojar  |0  |0  |0   |20  |47  |16 |38  |11  |28   |160   |\n|disparar |0  |0  |0   |0   |3   |0  |1   |1   |3    |8     |\n|echar    |32 |15 |101 |153 |95  |40 |500 |500 |500  |1936  |\n|lanzar   |0  |0  |0   |0   |0   |0  |55  |125 |500  |680   |\n|tirar    |0  |0  |0   |0   |0   |0  |0   |7   |81   |88    |\n|Total    |32 |15 |101 |173 |145 |56 |594 |644 |1112 |2872  |\n\n\n:::\n:::\n\n\n\n\nTo reproduce this table on the basis of the data provided by the authors, we begin by reshaping the data frame `spanish.data` from **long format** to **wide format** using the `pivot_wider()` function (see @sec-CombiningDatasets). This function takes the arguments \"names_from\" to specify which column is to provide the names for the output columns, and \"values_from\" to determine which column is to supply the cell values.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nverbs.investigated |>\n  pivot_wider(names_from = Century, values_from = n) \n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 5 √ó 10\n  AUX       `13`  `14`  `15`  `16`  `17`  `18`  `19`  `20`  `21`\n  <chr>    <int> <int> <int> <int> <int> <int> <int> <int> <int>\n1 echar       32    15   101   153    95    40   500   500   500\n2 tirar       NA    NA     2    NA    NA     8    NA     7    81\n3 arrojar     NA    NA    NA    20    47    16    38    11    28\n4 disparar    NA    NA    NA    NA     3    NA     1     1     3\n5 lanzar      NA    NA    NA    NA    NA    NA    55   125   500\n```\n\n\n:::\n:::\n\n\n\n\nAs you can see, this table includes a lot of `NA` values for the verbs for which zero occurrences were found in certain centuries. To replace missing values (`NA`) with a different value (here `0` to match @tbl-absPaper), we can use the tidyverse function `replace_na()` in combination with `mutate()`. By applying this operation `across(everything())`, we ensure that the modifications are performed on all columns. We pipe this output into the `arrange()` function to order the rows of the table by the alphabetical order of the `AUX`. This is important as we will later use `token.data` to calculate the type/token frequency (see @tbl-typeTokenData) for which we will merge `token.data` with the `types.wide`, which is also arranged by the alphabetical order of the `AUX`.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntoken.data <- verbs.investigated |>\n  pivot_wider(names_from = Century, values_from = n) |> \n  mutate(across(everything(), ~ replace_na(., 0))) |>\n  arrange(AUX) \n\ntoken.data\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 5 √ó 10\n  AUX       `13`  `14`  `15`  `16`  `17`  `18`  `19`  `20`  `21`\n  <chr>    <int> <int> <int> <int> <int> <int> <int> <int> <int>\n1 arrojar      0     0     0    20    47    16    38    11    28\n2 disparar     0     0     0     0     3     0     1     1     3\n3 echar       32    15   101   153    95    40   500   500   500\n4 lanzar       0     0     0     0     0     0    55   125   500\n5 tirar        0     0     2     0     0     8     0     7    81\n```\n\n\n:::\n:::\n\n\n\n\nWe now want to add the total number of verb occurrences in each row and column of our table, as in [@vanhulleCategoryThrowVerbs2024, Table 4] (see also @tbl-absPaper). We begin by calculating the total number of occurrences of each verb in `token.data`. We therefore first select just the columns containing numeric values.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nnumeric_columns <- token.data |> \n  select(where(is.numeric))\n\nnumeric_columns\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 5 √ó 9\n   `13`  `14`  `15`  `16`  `17`  `18`  `19`  `20`  `21`\n  <int> <int> <int> <int> <int> <int> <int> <int> <int>\n1     0     0     0    20    47    16    38    11    28\n2     0     0     0     0     3     0     1     1     3\n3    32    15   101   153    95    40   500   500   500\n4     0     0     0     0     0     0    55   125   500\n5     0     0     2     0     0     8     0     7    81\n```\n\n\n:::\n:::\n\n\n\n\nIt is important that we specify that we only add the values in columns representing numeric variables because if we ask `R` to do any mathematical operations with values of the `AUX` variable, we will get an error message indicating that it is impossible to add up character string values!\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsum(token.data$AUX)\n```\n:::\n\n\n\n\n```         \nError in sum(token.data$AUX) : invalid 'type' (character) of argument\n```\n\nThis is why we first created an `R` object that contains only the numeric variables of `token.data`: these are the columns that we will need to compute our sums. Next, we use the base `R` function `rowSums()` to calculate the total number of occurrences of each 'throw' verb across all corpus texts queried, from the 13^th^ to the 21^th^ century.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nrow_sums <- rowSums(numeric_columns)\n```\n:::\n\n\n\n\nWe have saved the output of the `rowSums()` function to a new object called `row_sums`. This object is a numeric vector containing just the row totals.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nrow_sums\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1]  160    8 1936  680   98\n```\n\n\n:::\n:::\n\n\n\n\nTo check that these are in fact the correct totals, we can compare these row sums to the output of `table(spanish.data$AUX)` (see also @sec-ImportingVanHulle). As the numbers match, we can now use `mutate()` to add `row_sums` as a new column to `token.data`.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntoken.data.rowSums <- token.data |> \n  mutate(Total = row_sums)\n\ntoken.data.rowSums\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 5 √ó 11\n  AUX       `13`  `14`  `15`  `16`  `17`  `18`  `19`  `20`  `21` Total\n  <chr>    <int> <int> <int> <int> <int> <int> <int> <int> <int> <dbl>\n1 arrojar      0     0     0    20    47    16    38    11    28   160\n2 disparar     0     0     0     0     3     0     1     1     3     8\n3 echar       32    15   101   153    95    40   500   500   500  1936\n4 lanzar       0     0     0     0     0     0    55   125   500   680\n5 tirar        0     0     2     0     0     8     0     7    81    98\n```\n\n\n:::\n:::\n\n\n\n\nNow, let's turn to the column totals. We can use `colSums()` to calculate the total number of 'throw' verb occurrences in each century.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ncolumn_sums <- colSums(numeric_columns)\n\ncolumn_sums\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n  13   14   15   16   17   18   19   20   21 \n  32   15  103  173  145   64  594  644 1112 \n```\n\n\n:::\n:::\n\n\n\n\nIn the original paper, the row of totals is labelled \"Total\". Furthermore, we also have a value representing the total number of verbs included in the dataset. Hence, the last row will be constructed as follows using the combine function `c()`.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntotal_row <- c(\"Total\", column_sums, sum(row_sums))\n\ntotal_row\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n             13      14      15      16      17      18      19      20      21 \n\"Total\"    \"32\"    \"15\"   \"103\"   \"173\"   \"145\"    \"64\"   \"594\"   \"644\"  \"1112\" \n        \n \"2882\" \n```\n\n\n:::\n:::\n\n\n\n\nAgain, we can check that we have not \"lost\" any verbs along the way by comparing the last value of `total_row` with the number of observations in our original long-format dataset.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nnrow(spanish.data)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 2882\n```\n\n\n:::\n:::\n\n\n\n\nFinally, we use `rbind()` to append the `total_row` vector to `token.data`, creating a complete table with both row and column totals (@tbl-absData).\n\n\n\n\n::: {#tbl-absData .cell tbl-cap='Absolute token frequency of Spanish \\'throw\\' verbs based on dataset'}\n\n```{.r .cell-code}\ntoken.table.totals <- rbind(token.data.rowSums, total_row)\n\ntoken.table.totals\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 6 √ó 11\n  AUX      `13`  `14`  `15`  `16`  `17`  `18`  `19`  `20`  `21`  Total\n  <chr>    <chr> <chr> <chr> <chr> <chr> <chr> <chr> <chr> <chr> <chr>\n1 arrojar  0     0     0     20    47    16    38    11    28    160  \n2 disparar 0     0     0     0     3     0     1     1     3     8    \n3 echar    32    15    101   153   95    40    500   500   500   1936 \n4 lanzar   0     0     0     0     0     0     55    125   500   680  \n5 tirar    0     0     2     0     0     8     0     7     81    98   \n6 Total    32    15    103   173   145   64    594   644   1112  2882 \n```\n\n\n:::\n:::\n\n\n\n\nIf we now compare the values of the table in the published study (reproduced as @tbl-absPaper) with @tbl-absData based on the authors' archived data, we can see that the total number of 'throw' verbs is only 2872, suggesting that ten verb occurrences are somehow missing in the summary table printed in the published paper. In the data frame `spanish.data`, these missing data points correspond to occurrences of the verb *tirar*, specifically two tokens from the 15^th^ century and eight tokens from the 18^th^ century (@tbl-absData).\n\nSince @vanhulleCategoryThrowVerbs2024 focus their analyses on the other two verbs, *echar* and *lanzar*, this discrepancy is not particularly conspicuous. However, it suggests that the version of the dataset archived on TROLLing is not exactly the same as the one that the authors presumably used for the analyses presented in the 2024 paper.[^cs_poppy-1]\n\n[^cs_poppy-1]: We contacted the first and corresponding author of the paper. They responded and confirmed that these discrepancies were likely due to small changes that were made to the dataset that was ultimately used in the analyses published in @vanhulleCategoryThrowVerbs2024. These changes were deemed necessary when either additional occurrences of inchoative constructions were found in the corpora, or false positives (i.e. occurrences of 'throw' verbs that did not enter such constructions) were later identified in the dataset. The author did not provide us with the final dataset that was used in the reported analyses.\n\n### Visualising the absolute frequencies in a tabular format\n\nAs Van Hulle & Enghels [@vanhulleCategoryThrowVerbs2024: 224] state,\n\n> \"The searches in the databases of CORDE and esTenTen18 were exhaustive, but, for reasons of feasibility, only the first 500 relevant cases were included in the final dataset.\"\n\nThat is, the corpus contains much more data than what the authors could feasibly investigate. For example, the verb *echar* appears 799 times in the 19^th^ century texts, 1,641 times in the 20^th^ texts, and 10,347 times in those from the 21^st^ century. However, in their final dataset @vanhulleCategoryThrowVerbs2024 included only 500 instances of *echar* in these centuries, as shown in @tbl-absPaper above.\n\nTo generate a table that includes the absolute token frequency in the corpus, similar to the \"absolute token frequency\" subsection of Table 5 in Van Hulle & Enghels [@vanhulleCategoryThrowVerbs2024: 227], we need to modify the values of *echar* in the 19^th^, 20^th^, and 21^st^ centuries, and *lanzar* in the 21^st^ century in `verbs.investigated` that we previously created.\n\nWe use the `mutate()` function to update specific columns and `case_when()` to define the conditions of the changes. For example, if the verb *echar* appears in the `AUX` variable and at the same time the value `19` is found in the `Century` variable, then the cell value should be changed to *799*, and so on. The formula `TRUE ~ n` ensures that the original value is retained if no condition is met. The modified table is assigned to a new data frame object, which we name `verbs.corpus`.\n\nNext, we generate a contingency table with the altered values for those verbs by applying the `pivot_wider()` function as in @tbl-absData above. The result is displayed in @tbl-absCorpus below.\n\n\n\n\n::: {#tbl-absCorpus .cell tbl-cap='Absolute token frequency of Spanish \\'throw\\' verbs as observed in the corpus'}\n\n```{.r .cell-code  code-fold=\"true\" code-summary=\"Show the `R` code to generate the table below.\"}\nverbs.corpus <- verbs.investigated |>\n  # Modifying specific columns with mutate()\n  mutate(n = case_when(\n    AUX == \"echar\" & Century == 19 ~ 799,\n    AUX == \"echar\" & Century == 20 ~ 1641,\n    AUX == \"echar\" & Century == 21 ~ 10347,\n    AUX == \"lanzar\" & Century == 21 ~ 7625,\n    # Keep the original value if no condition is met\n    TRUE ~ n))\n\n# Generating a contingency table with the altered verb values using pivot_wider()\nverbs.corpus.wide <- verbs.corpus |>\n  pivot_wider(names_from = Century, values_from = n) |>\n  mutate(across(everything(), ~ replace_na(., 0))) |>\n  arrange(AUX)\n\nverbs.corpus.wide\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 5 √ó 10\n  AUX       `13`  `14`  `15`  `16`  `17`  `18`  `19`  `20`  `21`\n  <chr>    <dbl> <dbl> <dbl> <dbl> <dbl> <dbl> <dbl> <dbl> <dbl>\n1 arrojar      0     0     0    20    47    16    38    11    28\n2 disparar     0     0     0     0     3     0     1     1     3\n3 echar       32    15   101   153    95    40   799  1641 10347\n4 lanzar       0     0     0     0     0     0    55   125  7625\n5 tirar        0     0     2     0     0     8     0     7    81\n```\n\n\n:::\n:::\n\n\n\n\nThe difference between the corpus data (@tbl-absCorpus) and the final dataset (@tbl-absData) is found only in *echar* in 19^th^, 20^th^, 21^st^, and in *lanzar* in 21^st^ centuries. Following @vanhulleCategoryThrowVerbs2024, we will use the frequency of Spanish 'throw' verbs (stored as a data frame named `verbs.corpus`) observed in the corpus (@tbl-absCorpus) to calculate the normalized frequency (see @tbl-normData below).\n\n## Normalized frequency\n\nA normalized frequency is an occurrence rate adjusted to a common base, such as per million words (pmw), to allow comparisons across datasets of different sizes.\n\n@vanhulleCategoryThrowVerbs2024 analyse Spanish corpora from different centuries, using the Corpus Diacr√≥nico del Espa√±ol (CORDE) for the 13^th^ to 20^th^ centuries and the esTenTen18 corpus for the 21^st^ century, accessed via the Sketch Engine platform. To compare frequencies from these varying-sized corpora, we need to normalize them to ensure that large frequencies are not simply due to the corpus being larger. Van Hulle & Enghels [@vanhulleCategoryThrowVerbs2024: 227, footnote 2] explain:\n\n> The normalised token frequencies are calculated dividing the absolute token frequency by these total amounts of words, multiplied by 1 million. This number then shows how many times each micro-construction occurs per 1 million words, per century.\n\nThe formula for normalized frequency is as follows:\n\n$$\nnormalized frequency = \\frac{token frequency}{total words *1000000}\n$$\n\n### Visualising normalized frequencies in a tabular format\n\nWe will now attempt to reproduce the ‚ÄúNormalized Token Frequency‚Äù sections of Tables 5 and 8 from the published paper using the authors' original data. For later comparison, the normalized frequencies as reported in Van Hulle & Enghels [@vanhulleCategoryThrowVerbs2024: 227, 232][^cs_poppy-2] are reproduced in this chapter as @tbl-normPaper.\n\n[^cs_poppy-2]: The normalized frequencies of *echar* and *lanzar* are found in Table 5 [@vanhulleCategoryThrowVerbs2024: 227], whilst those for *arrojar*, *disparar* and *tirar* are displayed in Table 8 [@vanhulleCategoryThrowVerbs2024: 232]. Note that in Tables 5 and 8 [@vanhulleCategoryThrowVerbs2024: 232] all values are rounded off to two decimal places except the normalized frequency of *disparar* in the 21^st^ which is reported as \"0.0008\".\n\n\n\n\n::: {#tbl-normPaper .cell tbl-cap='Normalized frequency (pmw) as reported in the published paper [@vanhulleCategoryThrowVerbs2024: Tables 5 and 8]'}\n::: {.cell-output-display}\n\n\n|      AUX|   13| 14|   15|   16|   17|   18|   19|    20|     21|\n|--------:|----:|--:|----:|----:|----:|----:|----:|-----:|------:|\n|  arrojar|    -|  -|    -|  0.4| 1.23| 1.11| 0.89|  0.19|   0.01|\n| disparar|    -|  -|    -|    -| 0.08|    -| 0.02|  0.02| 0.0008|\n|    echar| 4.09|  2| 4.43| 3.07| 2.49| 2.76| 18.7| 27.96|   2.91|\n|   lanzar|    -|  -|    -|    -|    -|    -| 1.31|  2.15|   2.14|\n|    tirar|    -|  -|    -|    -|    -|    -|    -|  0.12|   0.02|\n\n\n:::\n:::\n\n\n\n\nThe sizes of the corpora for each century are provided in Van Hulle & Enghels [@vanhulleCategoryThrowVerbs2024: 227, footnote 12][^cs_poppy-3]. We create a table of word counts for each century (@tbl-corpusSizes) using the `tibble()` function from the tidyverse, by concatenating (using the `c()` function) the values of `Words` and `Century` and storing these as a new data frame named `corpus_sizes`.\n\n[^cs_poppy-3]: Note that we cannot copy the word counts directly from the paper, as the authors use the continental European format with the dot `(.)` as the thousand-separator and the comma `(,)` as a decimal point (e.g., 7.829.566 for the 13^th^ century). In `R`, however, the dot is interpreted as a decimal separator so entering `7.829.566` will generate an error:\n\n\n\n\n    ::: {.cell}\n    \n    ```{.r .cell-code}\n    7.829.566\n    ```\n    :::\n\n\n\n\n    ```         \n    unexpected numeric constant in \"7.829.566\"\n    ```\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ncorpus_sizes <- tibble(Century = c(13, 14, 15, 16, 17, 18, 19, 20, 21),\n                       Words = c(7829566, 7483952, 22796824, 49912675, 38083322, 14466748, 42726881, 58686214, 3554986755))\n```\n:::\n\n::: {#tbl-corpusSizes .cell tbl-cap='Total numbers of words in the corpora'}\n\n```{.r .cell-code}\ncorpus_sizes\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 9 √ó 2\n  Century      Words\n    <dbl>      <dbl>\n1      13    7829566\n2      14    7483952\n3      15   22796824\n4      16   49912675\n5      17   38083322\n6      18   14466748\n7      19   42726881\n8      20   58686214\n9      21 3554986755\n```\n\n\n:::\n:::\n\n\n\n\nWe will apply this formula to each verb for every century. First, we use the `left_join` function from {dplyr} to combine two data frames, i.e. `verbs.corpus`, which we used to create @tbl-absCorpus, and `corpus_sizes`, which we just created (@tbl-corpusSizes), based on the common `Century` column.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nleft_join(verbs.corpus, corpus_sizes, by = \"Century\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n        AUX Century     n      Words\n1     echar      13    32    7829566\n2     echar      14    15    7483952\n3     echar      15   101   22796824\n4     tirar      15     2   22796824\n5   arrojar      16    20   49912675\n6     echar      16   153   49912675\n7   arrojar      17    47   38083322\n8  disparar      17     3   38083322\n9     echar      17    95   38083322\n10  arrojar      18    16   14466748\n11    echar      18    40   14466748\n12    tirar      18     8   14466748\n13  arrojar      19    38   42726881\n14 disparar      19     1   42726881\n15    echar      19   799   42726881\n16   lanzar      19    55   42726881\n17  arrojar      20    11   58686214\n18 disparar      20     1   58686214\n19    echar      20  1641   58686214\n20   lanzar      20   125   58686214\n21    tirar      20     7   58686214\n22  arrojar      21    28 3554986755\n23 disparar      21     3 3554986755\n24    echar      21 10347 3554986755\n25   lanzar      21  7625 3554986755\n26    tirar      21    81 3554986755\n```\n\n\n:::\n:::\n\n\n\n\nNext, we pipe the combined data frames into a `mutate()` function to add a new column named `normalized` and apply the formula `(n / Words) * 1000000` to normalize the frequency. In a second step, we round the result to two decimal places.\n\n\n\n\n::: {.cell source-line-numbers='2:3'}\n\n```{.r .cell-code}\nleft_join(verbs.corpus, corpus_sizes, by = \"Century\") |>\n  mutate(normalized = (n / Words) * 1000000) |>\n  mutate(normalized = round(normalized,\n                            digits = 2))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n        AUX Century     n      Words normalized\n1     echar      13    32    7829566       4.09\n2     echar      14    15    7483952       2.00\n3     echar      15   101   22796824       4.43\n4     tirar      15     2   22796824       0.09\n5   arrojar      16    20   49912675       0.40\n6     echar      16   153   49912675       3.07\n7   arrojar      17    47   38083322       1.23\n8  disparar      17     3   38083322       0.08\n9     echar      17    95   38083322       2.49\n10  arrojar      18    16   14466748       1.11\n11    echar      18    40   14466748       2.76\n12    tirar      18     8   14466748       0.55\n13  arrojar      19    38   42726881       0.89\n14 disparar      19     1   42726881       0.02\n15    echar      19   799   42726881      18.70\n16   lanzar      19    55   42726881       1.29\n17  arrojar      20    11   58686214       0.19\n18 disparar      20     1   58686214       0.02\n19    echar      20  1641   58686214      27.96\n20   lanzar      20   125   58686214       2.13\n21    tirar      20     7   58686214       0.12\n22  arrojar      21    28 3554986755       0.01\n23 disparar      21     3 3554986755       0.00\n24    echar      21 10347 3554986755       2.91\n25   lanzar      21  7625 3554986755       2.14\n26    tirar      21    81 3554986755       0.02\n```\n\n\n:::\n:::\n\n\n\n\nNext, we remove the `n` and `Words` columns that we no longer need here by combining the minus operator `-` and the `select()` function to \"unselect\" these columns.\n\n\n\n\n::: {.cell source-line-numbers='7:8'}\n\n```{.r .cell-code}\nverb.normalized <- left_join(verbs.corpus,\n                           corpus_sizes,\n                           by = \"Century\") |>\n  mutate(normalized = (n / Words) * 1000000) |>\n  mutate(normalized = round(normalized,\n                          digits = 2)) |> \n  select(-c(n, Words))\n\nverb.normalized\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n        AUX Century normalized\n1     echar      13       4.09\n2     echar      14       2.00\n3     echar      15       4.43\n4     tirar      15       0.09\n5   arrojar      16       0.40\n6     echar      16       3.07\n7   arrojar      17       1.23\n8  disparar      17       0.08\n9     echar      17       2.49\n10  arrojar      18       1.11\n11    echar      18       2.76\n12    tirar      18       0.55\n13  arrojar      19       0.89\n14 disparar      19       0.02\n15    echar      19      18.70\n16   lanzar      19       1.29\n17  arrojar      20       0.19\n18 disparar      20       0.02\n19    echar      20      27.96\n20   lanzar      20       2.13\n21    tirar      20       0.12\n22  arrojar      21       0.01\n23 disparar      21       0.00\n24    echar      21       2.91\n25   lanzar      21       2.14\n26    tirar      21       0.02\n```\n\n\n:::\n:::\n\n\n\n\nWe reshape the data frame `verb.normalized` from **long format** to **wide format** by replicating the `pivot_wider()` function, which we used to create @tbl-absPaper and @tbl-absCorpus. The new column names will be taken from `Century`. The values in the new column will come from `normalized`. As earlier, we sort the rows of the data frame according to the alphabetical order of `AUX` using `arrange()`. We convert the output into a data frame format with the `as.data.frame()` command and assign the output to `normalized.wide`.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nnormalized.wide <- verb.normalized |>\n  pivot_wider(names_from = Century, values_from = normalized) |>\n  arrange(AUX) |> \n  as.data.frame()\n\nnormalized.wide\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n       AUX   13 14   15   16   17   18    19    20   21\n1  arrojar   NA NA   NA 0.40 1.23 1.11  0.89  0.19 0.01\n2 disparar   NA NA   NA   NA 0.08   NA  0.02  0.02 0.00\n3    echar 4.09  2 4.43 3.07 2.49 2.76 18.70 27.96 2.91\n4   lanzar   NA NA   NA   NA   NA   NA  1.29  2.13 2.14\n5    tirar   NA NA 0.09   NA   NA 0.55    NA  0.12 0.02\n```\n\n\n:::\n:::\n\n\n\n\nNext, we use the `is.na()` function to find all missing values (`NA`) in the data frame `normalized.wide`. We replace all these `NA` values with a dash (`\"-\"`) using the `<-` operator.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nnormalized.wide[is.na(normalized.wide)] <- \"-\"\n```\n:::\n\n\n\n\nThe result can be seen in @tbl-normData.\n\n\n\n\n::: {#tbl-normData .cell tbl-cap='Normalized frequency of Spanish \\'throw\\' verbs (pmw) based on TROLLing data'}\n\n```{.r .cell-code  code-fold=\"true\" code-summary=\"Show the `R` code to generate the wide table below.\"}\n# Use left_join to merge the dataframes\nverb.normalized <- left_join(verbs.corpus,\n                             corpus_sizes,\n                             by = \"Century\") |>\n# Use mutate to create a new column with n divided by words\n  mutate(normalized = (n / Words) * 1000000) |>\n  mutate(normalized = round(normalized,\n                            digits = 2)) |> \n# Remove raw frequencies (n) and corpus sizes (Words)\n  select(-c(n, Words))\n\n# Pivot to wide format and replace NAs with 0\nnormalized.wide <- verb.normalized |>\n  pivot_wider(names_from = Century, values_from = normalized) |>\n  arrange(AUX) |> \n  as.data.frame()\n\n# replace NA with \"-\"\nnormalized.wide[is.na(normalized.wide)] <- \"-\"\n\nnormalized.wide\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n       AUX   13 14   15   16   17   18   19    20   21\n1  arrojar    -  -    -  0.4 1.23 1.11 0.89  0.19 0.01\n2 disparar    -  -    -    - 0.08    - 0.02  0.02 0.00\n3    echar 4.09  2 4.43 3.07 2.49 2.76 18.7 27.96 2.91\n4   lanzar    -  -    -    -    -    - 1.29  2.13 2.14\n5    tirar    -  - 0.09    -    - 0.55    -  0.12 0.02\n```\n\n\n:::\n:::\n\n\n\n\nAt this stage, it is important to note some differences between @tbl-normData and @tbl-normPaper. @vanhulleCategoryThrowVerbs2024 provided normalized frequencies for the three verbs *arrojar*, *disparar* and *tirar* only from the 16^th^ until the 21^st^ centuries, with no data for the 13^th^ to 15^th^ centuries. However, @tbl-normData shows the normalized frequency of *tirar* at 0.09 for the 15^th^ century and 0.55 for the 18^th^ century, filling in some missing data found in the dataset (@tbl-absData). Additionally, there are slight differences in the normalized frequencies of *lanzar* for the 19^th^ and 20^th^ centuries, calculated as 1.29 and 2.13 based on TROLLing data and displayed in @tbl-normData, compared to 1.31 and 2.15 in reported by @vanhulleCategoryThrowVerbs2024 and displayed in @tbl-normPaper.\n\nAnother point to note is the apparent discrepancy in the normalized frequency of the verb *disparar*. In @tbl-normPaper, it is reported in the original paper as 0.0008 for the 21^st^ century, while @tbl-normData displays it as 0.00. However, this difference is due to @tbl-normData using a two-digit format; when rounded to four digits, the value would indeed be 0.0008. Thus, this is not a true discrepancy.\n\n### Visualisation of the normalized frequencies as a line graph\n\nWe now visualize how the usage of Spanish 'throw' verbs in inchoative constructions has evolved from the 13^th^ to the 21^st^ century. Although such a visualization is not provided in @vanhulleCategoryThrowVerbs2024, it is mentioned in the dataset description @vanhulleReplicationDataCategory2024, and it can facilitate the interpretation of the changes in normalized frequencies documented in @tbl-normData.\n\nFor a diachronic study based on corpus data, it is reasonable to choose a connected scatterplot, which is essentially a combination of a scatterplot and a line plot. Using the {ggplot2} package, this entails combining a `geom_point()` layer on top of a `geom_line()` layer. The connected scatterplot provides a visualisation that helps to identify the usage of the five 'throw' verbs in inchoative constructions over time.\n\n@fig-normFreq is created using a `ggplot()` function that takes the data frame `verb.normalized` as its first argument and the aesthetics (`aes`) as its second argument. For the `aes` argument, we choose the `Century` column for the *x*-axis and the column `normalized` for the *y*-axis. Additionally, we specify two more optional aesthetics mappings in `aes`: \"color\" and \"group\". Both will be mapped onto the `AUX` variable, meaning that each verb will be displayed in a different color, and the line will be grouped by each verb over time. We also add a `scale_x_continuous()` layer ensures that the *x*-axis is labelled from the 13^th^ to 21^st^ century.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nggplot(verb.normalized, \n       aes(x = Century, \n           y = normalized, \n           color = AUX, \n           group = AUX)) +\n  geom_point() +  # Scatterplot points\n  geom_line() +   # Connect points with lines\n  scale_x_continuous(breaks = 13:21) + \n  labs(title = \"Normalized frequency of Spanish 'throw' verbs over time\",\n       x = \"Century\",\n       y = \"Normalized frequency (pmw)\",\n       color = \"Verbs\") +\n  theme_minimal()\n```\n\n::: {.cell-output-display}\n![Normalized frequency of Spanish 'throw' verbs over time](CS_Poppy_files/figure-html/fig-normFreq-1.png){#fig-normFreq width=672}\n:::\n:::\n\n\n\n\n@fig-normFreq shows that the verb *echar* is the most frequently used verb as an inchoative auxiliary, appearing in the corpus since the 13^th^ century, while the other verbs only began to appear from the 15^th^ century (*tirar*), the 16^th^ century (*arrojar*), the 17^th^ century (*disparar*), and the 19^th^ century (*lanzar*). According to Van Hulle & Enghels [-@vanhulleCategoryThrowVerbs2024: 223], the verb *echar* \"can be considered as the exemplary verb which opened the pathway for other 'throw' verbs towards the aspectual inchoative domain\". They further state, \\> \"The relative token frequency increases remarkably in the 19th (n=18,70) and 20th (n=27,96) centuries, which can thus be defined as the time frames in which the micro-construction with echar was most frequently used. In the 21st century data, both micro-constructions appear with a comparable normalized token frequency in the corpus\" (@vanhulleCategoryThrowVerbs2024).\n\nThe normalized frequency graphic of Spanish 'throw' verbs in @fig-normFreq effectively illustrates the authors' statement, providing a clear visual representation of how these verbs have evolved in usage over time.\n\n## Type frequency\n\nType frequency refers to the number of unique words that can appear in a specific position, or \"slot,\" within a particular grammatical construction. In the context of an inchoative construction, a specific slot refers to the position within the construction where an infinitive verb can occur.\n\nFor example, let‚Äôs look at the data in spanish.data (as shown in View(spanish.data) in the imported data, (see @fig-screenShot). Here, we see a list of verb usages, with each row representing a token, or instance, of a verb in a sentence or construction. There are 15 rows, each representing a token of a verb in specific sentences.\n\nIf we focus on the verb ***lanzar***, we can count a total of 7 tokens, meaning that ***lanzar*** appears 7 times in @fig-screenShot (in the 1^st^, 3^rd^, 5^th^, 6^th^, 7^th^, 8^th^, and 15^th^ rows). However, among these tokens, ***lanzar*** pairs twice with ***hacer*** in an inchoative construction. Because ***hacer*** is repeated, this combination with ***lanzar*** is counted as only one type. Therefore, although we have 7 **tokens** (occurrences) of ***lanzar***, we have only 6 unique **types** (distinct pairings) involving ***lanzar*** in the inchoative slot.\n\nVan Hulle & Enghels [-@vanhulleCategoryThrowVerbs2024: 226] state that one may generally assume \"that a higher type frequency indicates a higher degree of semantic productivity. As such, it is likely that a construction with a high number of different infinitives will accept even more types in the future\". Thus, type frequency is an important measure of how productive and adaptable a pattern is.\n\n### Visualising type frequencies in a tabular format\n\nWe will now attempt to reproduce the type frequencies of Spanish 'throw' verbs as displayed in the two subtables (both labelled \"type frequency\") of the original publication: one for *echar* and *lanzar* [@vanhulleCategoryThrowVerbs2024: Table 5] and the other for *arrojar*, *disparar* and *tirar* [@vanhulleCategoryThrowVerbs2024: Table 8]. The values from these two subtables are reproduced in this chapter as @tbl-typePaper.\n\n\n\n\n::: {#tbl-typePaper .cell tbl-cap='Type frequency of Spanish \\'throw\\' verbs based on the published paper'}\n::: {.cell-output-display}\n\n\n|AUX      |13 |14 |15 |16 |17 |18 |19 | 20|  21|\n|:--------|:--|:--|:--|:--|:--|:--|:--|--:|---:|\n|arrojar  |-  |-  |-  |16 |34 |13 |32 | 10|  27|\n|disparar |-  |-  |-  |-  |2  |-  |1  |  1|   3|\n|echar    |8  |3  |15 |12 |12 |17 |19 | 20|  20|\n|lanzar   |-  |-  |-  |-  |-  |-  |45 | 95| 215|\n|tirar    |-  |-  |-  |-  |-  |-  |-  |  7|  46|\n\n\n:::\n:::\n\n\n\n\nBased on the object `spanish.data` (see @fig-screenShot), which we created from on the TROLLing dataset `Spanish_ThrowVerbs_Inchoatives_20230413.csv`, we can calculate the type frequency of each 'throw' verbs in inchoative construction (see @tbl-typeData). To achieve this, we first select the first three columns of `spanish.data`, i.e. `AUX`, `Century`, `INF`. The result is a long table with the three columns and 2,882 rows. We check the first six lines of the table using the `head()` function.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntype.token <- select(spanish.data, 1:3)\nhead(type.token)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n     AUX Century      INF\n1 lanzar      21   llevar\n2  echar      21   dormir\n3 lanzar      21   probar\n4  tirar      21   atacar\n5 lanzar      21    hacer\n6 lanzar      21 estudiar\n```\n\n\n:::\n:::\n\n\n\n\nWe then calculate the number of unique combinations among these variables using the `distinct()` function. We pipe the output into a `group_by()` function, which allows us to group all the corpus occurences according to `Century` and `AUX`. Then, using the `summarize()` function, we create a new column called `Types` with the number `(n)` of types corresponding to each combination of `Century` and `AUX`. We convert the output into a data frame format using `as.data.frame()` and assign it to a new `R` object called `verb.types`.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nverb.types <- type.token |> \n  distinct(Century, AUX, INF) |> \n  group_by(Century, AUX) |> \n  summarize(Types = n()) |> \n  as.data.frame()\n```\n:::\n\n\n\n\nWe reshape the object `verb.types` from **long format** to **wide format** using the `pivot_wider()` function. The new column names will be taken from `Century`. The values in the new column will come from `Types`. We use `mutate(across(everything())` to modify all columns at once. The modification entails replacing all missing values `(NA)` with `0` using the `replace_na` function. Next, we sort the rows of the data frame in the alphabetical order of the `AUX` column using the `arrange()` function. We assign the output to `types.wide`.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntypes.wide <- verb.types |>\n  pivot_wider(names_from = Century, values_from = Types) |>\n  mutate(across(everything(), ~ replace_na(., 0))) |>\n  arrange(AUX)\n```\n:::\n\n\n\n\nThe result is displayed as @tbl-typeData.\n\n\n\n\n::: {#tbl-typeData .cell tbl-cap='Type frequency of Spanish \\'throw\\' verbs based on data'}\n\n```{.r .cell-code  code-fold=\"true\" code-summary=\"Show the `R` code to generate the table below.\"}\n# Selecting the first three columns of spanish.data\n# Creating a type frequency table labelled as type.token\ntype.token <- select(spanish.data, 1:3)\n\n# Calculating distinct combinations of Century, AUX, and INF using the distinct() function\n# Grouping data by Century and AUX using the group_by() function\n# Creating a new column Types with the summarize() function,\n# Returning the count (n) for each group\n\nverb.types <- type.token |> \n  distinct(Century, AUX, INF) |> \n  group_by(Century, AUX) |> \n  summarize(Types = n())\n\n# Converting verb.types to a data frame using the as.data.frame() function\nverb.types <- as.data.frame(verb.types)\n\n# Using the pivot_wider() function to create a contigency table\ntypes.wide <- verb.types |>\n  pivot_wider(names_from = Century, values_from = Types) |>\n  mutate(across(everything(), ~ replace_na(., 0))) |>\n  arrange(AUX)\n\n# Printing the table in elegantly formatted HTML format\ntypes.wide\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 5 √ó 10\n  AUX       `13`  `14`  `15`  `16`  `17`  `18`  `19`  `20`  `21`\n  <chr>    <int> <int> <int> <int> <int> <int> <int> <int> <int>\n1 arrojar      0     0     0    16    34    13    32    10    27\n2 disparar     0     0     0     0     2     0     1     1     3\n3 echar        8     3    15    12    12    17    18    22    20\n4 lanzar       0     0     0     0     0     0    44    95   215\n5 tirar        0     0     2     0     0     7     0     7    46\n```\n\n\n:::\n:::\n\n\n\n\nHere, too, we observe several discrepancies between @tbl-typeData and [@tbl-typePaper; a reproduction of @vanhulleCategoryThrowVerbs2024: 227]. The discrepancies involve the type frequencies of *echar* for the 19^th^ and 20^th^ centuries, reported as 19 and 20 in the original paper, and of *lanzar* for the 19^th^ century, originally reported as 45 (@tbl-typePaper). Other discrepancies include the type frequencies of the verb *tirar* in the 15^th^ and 18^th^ centuries, which are two and seven according to the TROLLing data, but both reported as zero in the published study (see also @tbl-absPaper).\n\n### Visualisation of the type frequency as a line graph\n\nUsing the type frequency data that we calculated above (see @tbl-typeData), we can largely recycle the `ggplot()` code that we used to create @fig-normFreq.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\" code-summary=\"Show the `R` code to generate the graph below.\"}\n# Using the ggplot() function with the dataframe verb.types\n# The y-axis represents the type frequency\nggplot(verb.types, \n       aes(x = Century, \n           y = Types, \n           color = AUX, \n           group = AUX)) +\n  geom_point() +  # Scatterplot points\n  geom_line() +   # Connect points with lines\n  scale_x_continuous(breaks = 13:21) + \n  labs(title = \"Productivity of Spanish 'throw' verbs over time\",\n       x = \"Century\",\n       y = \"Type frequency\",\n       color = \"Verbs\") +\n  theme_minimal()\n```\n\n::: {.cell-output-display}\n![Type frequency of Spanish 'throw' verbs over time](CS_Poppy_files/figure-html/fig-typeFreq-1.png){#fig-typeFreq width=672}\n:::\n:::\n\n::: {.cell}\n\n:::\n\n\n\n\nThe connected scatterplot displayed in @fig-typeFreq provides a visualisation that helps identify the productivity of the five 'throw' verbs in inchoative constructions with respect to their type frequency.\n\nAs Van Hulle & Enghels [-@vanhulleCategoryThrowVerbs2024: 226] state:\n\n> \"In general, it is assumed that a higher type frequency indicates a higher degree of semantic productivity. As such, it is likely that a construction with a high number of different infinitives will accept even more types in the future. In this sense, type frequency constitutes an important parameter to measure the extending productivity of a construction\".\n\nHowever, we should interpret this graphic carefully, keeping in mind that *absence of evidence is not evidence of absence*. Notably, there is almost no data for ***disparar***, which raises the question: in the real world, is this verb rarely used in an inchoative construction, or are there simply no examples in the corpus?\n\n::: callout-tip\n#### Quiz time! {.unnumbered}\n\n[**Q7.**]{style=\"color:green;\"} Which line of code can you add in the `ggplot()` code above to change the color scheme of the line graph in @fig-typeFreq to a color-blind friendly one? Click on \"Show the `R` code to generate the graph below.\" to see the code for @fig-typeFreq.\n\n\n\n\n\n```{=html}\n<form name=\"form_57682\" onsubmit=\"return validate_form_57682()\" method=\"post\">\n<input type=\"radio\" name=\"answer_57682\" id=\"answer_57682_1\" value=\"+ scale_color_viridis_b()\"/>\n<label>+ scale_color_viridis_b()</label>\n<br/>\n<input type=\"radio\" name=\"answer_57682\" id=\"answer_57682_2\" value=\"+ scale_color_continuous()\"/>\n<label>+ scale_color_continuous()</label>\n<br/>\n<input type=\"radio\" name=\"answer_57682\" id=\"answer_57682_3\" value=\"+ scale_color_viridis_d()\"/>\n<label>+ scale_color_viridis_d()</label>\n<br/>\n<input type=\"radio\" name=\"answer_57682\" id=\"answer_57682_4\" value=\"+ scale_color_viridis_c()\"/>\n<label>+ scale_color_viridis_c()</label>\n<br/>\n<input type=\"radio\" name=\"answer_57682\" id=\"answer_57682_5\" value=\"+ scale_color_blind()\"/>\n<label>+ scale_color_blind()</label>\n<br/>\n<input type=\"submit\" value=\"Check answer\"/>\n<div id=\"result_57682\"></div>\n</form>\n<script>function validate_form_57682() {var x, text; var x = document.forms['form_57682']['answer_57682'].value;if (x == '+ scale_color_viridis_d()'){text = 'Yes, well done!';} else {text = 'Not quite. Have you tried adding this line of code as a layer to the <code>ggplot()</code> object above?';} document.getElementById('result_57682').innerHTML = text; evaluate_final_score(); return false;}function evaluate_final_score(){\n         element = document.getElementById('checkdown_final_score');\n         if(element === null){return false;} else {var element, text, res1;res1 = document.getElementById('result_57682').innerText == 'Yes, well done!';text = res1;element.innerHTML = text;\n         return false;\n         }}</script>\n```\n\n```{=html}\n<div id=\"hint_12746\" onclick=\"return show_hint_12746()\">üê≠ Click on the mouse for a hint.</div>\n<div id=\"result_12746\" onclick=\"return show_hint_12746()\"></div>\n<script>function show_hint_12746(){var x = document.getElementById('result_12746').innerHTML; if(!x){document.getElementById('result_12746').innerHTML = 'The scales from the {viridis} package contain colorblind-friendly color palettes. The letters at the end of the <code>scale_color_viridis_*()</code> functions correspond to the type of data to be mapped onto the color scale: ‚Äúb‚Äù stands for ‚Äúbinned‚Äù, ‚Äúc‚Äù stands for ‚Äúcontinuous‚Äù, ‚Äúd‚Äù stands for ‚Äúdiscrete‚Äù. Which is suitable for the variable <code>AUX</code> in this dataset?';} else {document.getElementById('result_12746').innerHTML = '';}}</script>\n```\n\n\n\n\n<br> [**Q8.**]{style=\"color:green;\"} Alternatively, we could opt for a black-and-white solution like below. How can we adapt the `ggplot()` code from @fig-typeFreq to achieve this?\n\n\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](CS_Poppy_files/figure-html/productivity-line-1.png){width=672}\n:::\n:::\n\n\n```{=html}\n<form name=\"form_66539\" onsubmit=\"return validate_form_66539()\" method=\"post\">\n<input type=\"radio\" name=\"answer_66539\" id=\"answer_66539_1\" value=\"Change `aes(color = AUX)` to `aes(linetype = AUX)`\"/>\n<label>Change `aes(color = AUX)` to `aes(linetype = AUX)`</label>\n<br/>\n<input type=\"radio\" name=\"answer_66539\" id=\"answer_66539_2\" value=\"Change `aes(color = AUX)` to `aes(line = AUX)`\"/>\n<label>Change `aes(color = AUX)` to `aes(line = AUX)`</label>\n<br/>\n<input type=\"radio\" name=\"answer_66539\" id=\"answer_66539_3\" value=\"Change `geom_line()` to `geom_line(linetype = AUX)`\"/>\n<label>Change `geom_line()` to `geom_line(linetype = AUX)`</label>\n<br/>\n<input type=\"radio\" name=\"answer_66539\" id=\"answer_66539_4\" value=\"Change `geom_line()` to `geom_dotted()`\"/>\n<label>Change `geom_line()` to `geom_dotted()`</label>\n<br/>\n<input type=\"submit\" value=\"Check answer\"/>\n<div id=\"result_66539\"></div>\n</form>\n<script>function validate_form_66539() {var x, text; var x = document.forms['form_66539']['answer_66539'].value;if (x == 'Change `aes(color = AUX)` to `aes(linetype = AUX)`'){text = 'That‚Äôs right, well done!';} else {text = 'No, this won‚Äôt work. Try it out for yourself!';} document.getElementById('result_66539').innerHTML = text; evaluate_final_score(); return false;}function evaluate_final_score(){\n         element = document.getElementById('checkdown_final_score');\n         if(element === null){return false;} else {var element, text, res1, res2;res1 = document.getElementById('result_57682').innerText == 'Yes, well done!'; res2 = document.getElementById('result_66539').innerText == 'That‚Äôs right, well done!';text = res1 + res2;element.innerHTML = text;\n         return false;\n         }}</script>\n```\n\n\n\n:::\n\n## Type/token ratio (TTR)\n\nAs stated by Van Hulle & Enghels [-@vanhulleCategoryThrowVerbs2024: 226], the \"type/token ratio measures the realized productivity\" of each verb. Furthermore,\n\n> since type frequency depends to some extent on token frequency (the more tokens, the more opportunities for different types to occur), the two must be put into some kind of relationship. The simplest measure suggested in the literature is the type/token ratio \\[...\\] [@stefanowitschCorpusbasedPerspectiveEntrenchment2017: 118]\n\nType/token ratios (TTR) can range from zero and one. A TTR of zero indicates that there are no examples of the type in the given occurrences, while a TTR of one signifies that all types are unique to those given occurrences.\n\n$$\nTTR = \\frac{types}{tokens}\n$$\n\nAs type/token ratios depend on corpus size, Van Hulle & Enghels [-@vanhulleCategoryThrowVerbs2024: 227] explain that:\n\n> \"To be representative, the measures of type/token and hapax/token ratio are calculated on a maximum of 500 tokens per auxiliary. Specifically, for *echar* in the 19^th^, 20^th^ and 21^st^ century and for *lanzar* in the 21^st^ century, token frequency is reduced to 500.\"\n\n### Visualising type/token ratios in a tabular format\n\nWe will now attempt to reproduce the type/token ratio of Spanish throw verbs based on two subtables (both labelled \"type/token ratio\"): one for *echar* and *lanzar* [Table 5 from @vanhulleCategoryThrowVerbs2024: 227] and the other for *arrojar*, *disparar* and *tirar* [Table 8 from @vanhulleCategoryThrowVerbs2024: 232], which are reproduced in this chapter as @tbl-typeTokenPaper.\n\n\n\n\n::: {#tbl-typeTokenPaper .cell tbl-cap='Type/token ratio of Spanish \\'throw\\' verbs over time based on @vanhulleCategoryThrowVerbs2024'}\n::: {.cell-output-display}\n\n\n|AUX      |13   |14  |15   |16   |17   |18   |19   |   20|   21|\n|:--------|:----|:---|:----|:----|:----|:----|:----|----:|----:|\n|arrojar  |-    |-   |-    |0.8  |0.72 |0.81 |0.84 | 0.91| 0.96|\n|disparar |-    |-   |-    |-    |0.67 |-    |1    | 1.00| 1.00|\n|echar    |0.25 |0.2 |0.15 |0.08 |0.13 |0.43 |0.04 | 0.04| 0.04|\n|lanzar   |-    |-   |-    |-    |-    |-    |0.8  | 0.75| 0.43|\n|tirar    |-    |-   |-    |-    |-    |-    |-    | 1.00| 0.57|\n\n\n:::\n:::\n\n\n\n\nTo calculate type/token ratios, we first create two matching wide tables, one for the token frequencies, and another for the type frequencies. We can use the wide table labelled `token.data` from @tbl-absData, and the wide table labelled `types.wide` from @tbl-typeData as they are ordered in exactly the same way (you can check this by comparing their structures using the `str()` function).\n\nFirst, we create a new data frame using the `data.frame()` function. This data frame will take its first column from `token.data`, which contains the auxiliary verbs (`AUX`). We access this column using `token.data[, 1]`.[^cs_poppy-4]\n\n[^cs_poppy-4]: Remember that, in base `R`, the notation `[x, y]` allows us to specify rows and columns in a data frame, where `x` refers to the row and `y` refers to the column (see @sec-SquareBrackets). For example, `token.data[, 1]` means we are selecting all rows from the first column of `token.data`.\n\nNext, we calculate the type/token ratio. This is done by dividing the numeric values in `types.wide` (i.e., all columns except the first) by the corresponding values in `token.data`. To this end, we use the notation `types.wide[, -1] / token.data[, -1]`. The `[, -1]` indicates that we take all columns except the first one. We exclude the first column because it contains non-numeric values (the `AUX` column).\n\nFinally, we combine these components into our new data frame. We include the `AUX` column as the first column by selecting it with the command `token.data[, 1]`. To ensure that the column names remain unchanged, we set `check.names = FALSE` in the `data.frame()` function. This prevents `R` from altering the original column names, keeping them exactly as they are in `token.data`. We also `round()` the values of all numeric columns to just two decimals.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndata.frame(token.data[, 1], \n           types.wide[, -1] / token.data[, -1],\n           check.names = FALSE) |> \n    mutate(across(where(is.numeric), round, digits = 2))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n       AUX   13  14   15   16   17   18   19   20   21\n1  arrojar  NaN NaN  NaN 0.80 0.72 0.81 0.84 0.91 0.96\n2 disparar  NaN NaN  NaN  NaN 0.67  NaN 1.00 1.00 1.00\n3    echar 0.25 0.2 0.15 0.08 0.13 0.42 0.04 0.04 0.04\n4   lanzar  NaN NaN  NaN  NaN  NaN  NaN 0.80 0.76 0.43\n5    tirar  NaN NaN 1.00  NaN  NaN 0.88  NaN 1.00 0.57\n```\n\n\n:::\n:::\n\n\n\n\nOur table contains a lot `NaN` values. In these cells of the table, the number of tokens was zero and, as a consequence, the number of types was also zero. As it is mathematically impossible to divide zero by zero, `R` returns `NaN` values instead. To replace these `NaN` values to dashes (`\"-\"`) to match the formatting of the published tables, we use the base `R` function `is.na()`.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntype.token1 <- data.frame(token.data[, 1], \n\n                          types.wide[, -1] / token.data[, -1],\n\n                          check.names = FALSE) |> \n    mutate(across(where(is.numeric), round, digits = 2))\n\ntype.token1[is.na(type.token1)] <- \"-\"\n```\n:::\n\n\n\n\nThe result is saved as `type.token1` and is displayed below as @tbl-typeTokenData.\n\n\n\n\n::: {#tbl-typeTokenData .cell tbl-cap='Type/token ratio of Spanish \\'throw\\' verbs over time based on data'}\n::: {.cell-output .cell-output-stdout}\n\n```\n       AUX   13  14   15   16   17   18   19   20   21\n1  arrojar    -   -    -  0.8 0.72 0.81 0.84 0.91 0.96\n2 disparar    -   -    -    - 0.67    -    1 1.00 1.00\n3    echar 0.25 0.2 0.15 0.08 0.13 0.42 0.04 0.04 0.04\n4   lanzar    -   -    -    -    -    -  0.8 0.76 0.43\n5    tirar    -   -    1    -    - 0.88    - 1.00 0.57\n```\n\n\n:::\n:::\n\n\n\n\nComparing @tbl-typeTokenPaper and @tbl-typeTokenData, we find some minor discrepancies between the type/token ratios presented in the published paper and those calculated on the basis of the TROLLing data. The type/token ratio of the verb *tirar* in the 15^th^ and 18^th^ centuries, are reported as 0 and 0 in the published paper (see also @tbl-typeTokenPaper), but as 1 and 0.88 in @tbl-typeTokenData. These differences correspond to the discrepancies already identified when calculating the token frequencies (see @sec-TokenFreqTable).\n\nThe other (very minor) discrepancies involve the type/token ratio of *lanzar* for the 20^th^ century, reported as 0.75 in @tbl-typeTokenPaper but as 0.76 in @tbl-typeTokenData and *echar* in the 18^th^ century, reported as 0.43 (see @tbl-typeTokenPaper), while @tbl-typeTokenData displays it as 0.42. These differences arise from the fact that @vanhulleCategoryThrowVerbs2024 presumably did not use `R` for their calculations. The type/token ratio of *echar* in the 18^th^ century is actually 0.4250, which is rounded as 0.43 by @vanhulleCategoryThrowVerbs2024, but as 0.42 by `R` (see @tbl-typeTokenData). This somewhat confusing rounding behaviour is explained in the help file of the `round()` function:\n\n> \"Note that for rounding off a 5, the IEC 60559 standard (see also ‚ÄòIEEE 754‚Äô) is expected to be used, *‚Äògo to the even digit‚Äô*. Therefore `round(0.5)` is `0` and `round(-1.5)` is `-2`. However, this is dependent on OS services and on representation error (since e.g. `0.15` is not represented exactly, the rounding rule applies to the represented number and not to the printed number, and so `round(0.15, 1)` could be either `0.1` or `0.2`).\"\n\n### Visualising the type/token ratios as a line graph\n\nFor the visualisation of the type/token ratios (@fig-typeTokenRatio), we create a new data frame. We start by merging the data frames `verbs.investigated` and `verb.types` using the `left_join()` function, ensuring that the `Century` and `AUX` variables are aligned. This results in a single data frame, which we save as `type_token`.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntype_token <- left_join(verbs.investigated, verb.types, \n                        by = c(\"Century\", \"AUX\"))\n```\n:::\n\n\n\n\nNext, we calculate the type/token ratios by adding a new column, `TypeTokenRatio`, to the `type_token` data frame using the `mutate()` function, which applies the type/token ratio formula to each row. Finally, we use the `arrange()` function to sort the data by `Century` and `AUX` organizing the results chronologically by `Century` and alphabetically by the verb type (`AUX`).\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntype.token.ratio <- type_token  |> \n  mutate(TypeTokenRatio = Types / n) |> \n  arrange(Century, AUX)\n```\n:::\n\n\n\n\nThe output is a table with 26 rows and five columns: `AUX`, `Century`, `n`, and `Types` and `TypeTokenRatio`. We can display the first six rows of the table using the `head()` function.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nhead(type.token.ratio)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n      AUX Century   n Types TypeTokenRatio\n1   echar      13  32     8     0.25000000\n2   echar      14  15     3     0.20000000\n3   echar      15 101    15     0.14851485\n4   tirar      15   2     2     1.00000000\n5 arrojar      16  20    16     0.80000000\n6   echar      16 153    12     0.07843137\n```\n\n\n:::\n:::\n\n\n\n\nNow we can use the `type.token.ratio` data frame with the same `ggplot` code that we used to create @fig-normFreq and @fig-typeFreq, allowing us to visualize the type/token ratios of Spanish 'throw' verbs over time as @fig-typeTokenRatio.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\" code-summary=\"Show the `R` code to generate the table below.\"}\nggplot(type.token.ratio, \n       aes(x = Century, \n           y = TypeTokenRatio, \n           color = AUX, \n           group = AUX)) +\n  geom_point() +  # Scatterplot points\n  geom_line() +   # Connect points with lines\n  scale_x_continuous(breaks = 13:21) + \n  labs(title = \"The productivity of Spanish 'throw' verbs over time\",\n       x = \"Century\",\n       y = \"type/token ratio\",\n       color = \"Verbs\") +\n  theme_minimal()\n```\n\n::: {.cell-output-display}\n![type/token ratio of Spanish 'throw' Verbs Over Time](CS_Poppy_files/figure-html/fig-typeTokenRatio-1.png){#fig-typeTokenRatio width=672}\n:::\n:::\n\n::: {.cell}\n\n:::\n\n\n\n\nAccording to @vanhulleCategoryThrowVerbs2024, the verb *lanzar* is considered the \"most productive auxiliary\" due to its high type/token ratio values, despite only appearing from the 19^th^ century onward, and because it \"was able to incorporate a more varied set of infinitives\" [@vanhulleCategoryThrowVerbs2024: 228]. In contrast, the type/token ratio for *echar* is comparably low. However, as Van Hulle & Enghels [-@vanhulleCategoryThrowVerbs2024: 228] state:\n\n> \"\\[...\\] the type/token ratio for the micro-construction with *echar* is quite stable until it considerably drops from the 19^th^ century on (n=0.04). This means that, although speakers used the construction more frequently, this was mainly done with a limited group of infinitives \\[...\\]\"\n\nAdditionally, the verbs *disparar* and *tirar* have a type/token ratio of one for the 19^th^ and 21^st^ centuries, and the 15^th^ and 20^th^ centuries, respectively. This is due to the high hapax value, i.e., \"the number of types that appear only once in a text or corpus\" for the respective verbs [@vanhulleCategoryThrowVerbs2024: 226]. In the cases of *disparar* and *tirar*, each hapax refers to only one occurrence.\n\nThe above plot (@fig-typeTokenRatio) shows more clearly that *arrojar*, not *lanzar*, is actually the most semantically productive verb. When compared with *echar*, as the authors of the published paper have done, *lanzar* does indeed appear more semantically productive. However, as @vanhulleCategoryThrowVerbs2024 note, ‚Äútype/token ratio measures the realized productivity.‚Äù Based on this measure, *arrojar* is even more productive than *lanzar*, as this graphic (@fig-typeTokenRatio) clearly illustrates. @vanhulleCategoryThrowVerbs2024 do not provide such a visualization, but this chapter has shown that it can aid in interpreting the realized productivity measured by the type/token ratio.\n\n::: callout-tip\n#### Quiz time! {.unnumbered}\n\n[**Q9.**]{style=\"color:green;\"} What issue arises when interpreting the productivity of Spanish 'throw' verbs over time on the basis of @fig-typeTokenRatio?\n\n\n\n\n::: {.cell}\n::: {.cell-output-display}\n\n```{=html}\n<form name=\"form_17939\" onsubmit=\"return validate_form_17939()\" method=\"post\">\n<input type=\"radio\" name=\"answer_17939\" id=\"answer_17939_1\" value=\"Some lines suggest a linear increase or decrease in productivity over several centuries when there were, in fact, zero occurrences of that verb in one of these centuries.\"/>\n<label>Some lines suggest a linear increase or decrease in productivity over several centuries when there were, in fact, zero occurrences of that verb in one of these centuries.</label>\n<br/>\n<input type=\"radio\" name=\"answer_17939\" id=\"answer_17939_2\" value=\"The graph incorrectly suggests that type/token ratios cannot go beyond 1.00.\"/>\n<label>The graph incorrectly suggests that type/token ratios cannot go beyond 1.00.</label>\n<br/>\n<input type=\"radio\" name=\"answer_17939\" id=\"answer_17939_3\" value=\"The graph makes it difficult to compare the productivity of verbs across each century.\"/>\n<label>The graph makes it difficult to compare the productivity of verbs across each century.</label>\n<br/>\n<input type=\"radio\" name=\"answer_17939\" id=\"answer_17939_4\" value=\"The graph incorrectly suggests that there were zero occurrences of some verbs in earlier centuries.\"/>\n<label>The graph incorrectly suggests that there were zero occurrences of some verbs in earlier centuries.</label>\n<br/>\n<input type=\"radio\" name=\"answer_17939\" id=\"answer_17939_5\" value=\"The graph incorrectly suggests a decrease in productivity for all verbs.\"/>\n<label>The graph incorrectly suggests a decrease in productivity for all verbs.</label>\n<br/>\n<input type=\"submit\" value=\"Check answer\"/>\n<div id=\"result_17939\"></div>\n</form>\n<script>function validate_form_17939() {var x, text; var x = document.forms['form_17939']['answer_17939'].value;if (x == 'Some lines suggest a linear increase or decrease in productivity over several centuries when there were, in fact, zero occurrences of that verb in one of these centuries.'){text = 'That‚Äôs right!';} else {text = 'No, that‚Äôs not the case. Have you read the hint yet?';} document.getElementById('result_17939').innerHTML = text; evaluate_final_score(); return false;}function evaluate_final_score(){\n         element = document.getElementById('checkdown_final_score');\n         if(element === null){return false;} else {var element, text, res1, res2, res3;res1 = document.getElementById('result_57682').innerText == 'Yes, well done!'; res2 = document.getElementById('result_66539').innerText == 'That‚Äôs right, well done!'; res3 = document.getElementById('result_17939').innerText == 'That‚Äôs right!';text = res1 + res2 + res3;element.innerHTML = text;\n         return false;\n         }}</script>\n```\n\n:::\n\n::: {.cell-output-display}\n\n```{=html}\n<div id=\"hint_29781\" onclick=\"return show_hint_29781()\">üê≠ Click on the mouse for a hint.</div>\n<div id=\"result_29781\" onclick=\"return show_hint_29781()\"></div>\n<script>function show_hint_29781(){var x = document.getElementById('result_29781').innerHTML; if(!x){document.getElementById('result_29781').innerHTML = 'Consider, for example, the productivity of <em>tirar</em> as plotted on the graph. What does the graph suggest the type/token ratio of <em>tirar</em> is for the 16<sup>th</sup> and 17<sup>th</sup> centuries? What is it in reality according to the tabular data?';} else {document.getElementById('result_29781').innerHTML = '';}}</script>\n```\n\n:::\n:::\n\n\n\n\n<br> [**Q10.**]{style=\"color:green;\"} Based on the type/token ratios displayed in @fig-typeTokenRatio, which 'throw' verb appears to be the least productive one?\n\n\n\n\n::: {.cell}\n::: {.cell-output-display}\n\n```{=html}\n<form name=\"form_68230\" onsubmit=\"return validate_form_68230()\" method=\"post\">\n<input type=\"radio\" name=\"answer_68230\" id=\"answer_68230_1\" value=\"lanzar\"/>\n<label>lanzar</label>\n<br/>\n<input type=\"radio\" name=\"answer_68230\" id=\"answer_68230_2\" value=\"tirar\"/>\n<label>tirar</label>\n<br/>\n<input type=\"radio\" name=\"answer_68230\" id=\"answer_68230_3\" value=\"disparar\"/>\n<label>disparar</label>\n<br/>\n<input type=\"radio\" name=\"answer_68230\" id=\"answer_68230_4\" value=\"echar\"/>\n<label>echar</label>\n<br/>\n<input type=\"radio\" name=\"answer_68230\" id=\"answer_68230_5\" value=\"arrojar\"/>\n<label>arrojar</label>\n<br/>\n<input type=\"submit\" value=\"Check answer\"/>\n<div id=\"result_68230\"></div>\n</form>\n<script>function validate_form_68230() {var x, text; var x = document.forms['form_68230']['answer_68230'].value;if (x == 'echar'){text = 'Yes, indeed.';} else {text = 'No. You may want to re-read the definition of type/token ratio above.';} document.getElementById('result_68230').innerHTML = text; evaluate_final_score(); return false;}function evaluate_final_score(){\n         element = document.getElementById('checkdown_final_score');\n         if(element === null){return false;} else {var element, text, res1, res2, res3, res4;res1 = document.getElementById('result_57682').innerText == 'Yes, well done!'; res2 = document.getElementById('result_66539').innerText == 'That‚Äôs right, well done!'; res3 = document.getElementById('result_17939').innerText == 'That‚Äôs right!'; res4 = document.getElementById('result_68230').innerText == 'Yes, indeed.';text = res1 + res2 + res3 + res4;element.innerHTML = text;\n         return false;\n         }}</script>\n```\n\n:::\n:::\n\n\n\n\n<br> [**Q11.**]{style=\"color:green;\"} Based on the type/token ratios displayed in @fig-typeTokenRatio, which 'throw' verb appears to be the most productive one since the 19^th^ century?\n\n\n\n\n::: {.cell}\n::: {.cell-output-display}\n\n```{=html}\n<form name=\"form_10966\" onsubmit=\"return validate_form_10966()\" method=\"post\">\n<input type=\"radio\" name=\"answer_10966\" id=\"answer_10966_1\" value=\"arrojar\"/>\n<label>arrojar</label>\n<br/>\n<input type=\"radio\" name=\"answer_10966\" id=\"answer_10966_2\" value=\"tirar\"/>\n<label>tirar</label>\n<br/>\n<input type=\"radio\" name=\"answer_10966\" id=\"answer_10966_3\" value=\"echar\"/>\n<label>echar</label>\n<br/>\n<input type=\"radio\" name=\"answer_10966\" id=\"answer_10966_4\" value=\"lanzar\"/>\n<label>lanzar</label>\n<br/>\n<input type=\"radio\" name=\"answer_10966\" id=\"answer_10966_5\" value=\"disparar\"/>\n<label>disparar</label>\n<br/>\n<input type=\"submit\" value=\"Check answer\"/>\n<div id=\"result_10966\"></div>\n</form>\n<script>function validate_form_10966() {var x, text; var x = document.forms['form_10966']['answer_10966'].value;if (x == 'disparar'){text = 'Yes, but remember that the type/token ratios of <em>disparar</em> are based on extremely few occurrences! For the last three centuries, this auxilliary has a type/token ratio of one because only one occurrence was found per century, hence, by definition, the type/token ratio must be one. This does not reflect the productivity of the auxilliary verb in this construction; it merely reflects the fact that it only occurred once in this century.';} else {text = 'No, carefully read the question again.';} document.getElementById('result_10966').innerHTML = text; evaluate_final_score(); return false;}function evaluate_final_score(){\n         element = document.getElementById('checkdown_final_score');\n         if(element === null){return false;} else {var element, text, res1, res2, res3, res4, res5;res1 = document.getElementById('result_57682').innerText == 'Yes, well done!'; res2 = document.getElementById('result_66539').innerText == 'That‚Äôs right, well done!'; res3 = document.getElementById('result_17939').innerText == 'That‚Äôs right!'; res4 = document.getElementById('result_68230').innerText == 'Yes, indeed.'; res5 = document.getElementById('result_10966').innerText == 'Yes, but remember that the type/token ratios of disparar are based on extremely few occurrences! For the last three centuries, this auxilliary has a type/token ratio of one because only one occurrence was found per century, hence, by definition, the type/token ratio must be one. This does not reflect the productivity of the auxilliary verb in this construction; it merely reflects the fact that it only occurred once in this century.';text = res1 + res2 + res3 + res4 + res5;element.innerHTML = text;\n         return false;\n         }}</script>\n```\n\n:::\n:::\n\n\n\n:::\n\n## Conclusion\n\nYou have successfully completed [`<span id=\"checkdown_final_score\">0</span>`{=html} out of 11 quiz questions]{style=\"color:green;\"} in this chapter.\n\nThis chapter attempted to reproduce the results of a corpus linguistics study that explores the evolution of five throw verbs in Peninsular Spanish (*echar*, *lanzar*, *disparar*, *tirar*, and *arrojar*) into aspectual auxiliaries in inchoative constructions that express the beginning of an event. The authors of the original study, @vanhulleCategoryThrowVerbs2024, used historical and contemporary data to analyse the development and usage of these verbs, making their research data openly accessible. As part of this chapter, we identified some discrepancies between the results we obtained on the basis of the authors' data [@vanhulleReplicationDataCategory2024] and those published in the 2024 study, indicating that the version of the dataset uploaded onto TROLLing does not exactly match the one used for the published results.\n\nWe have also created some new data visualizations based on the authors' uploaded data, which uncover patterns in the evolution of Spanish inchoative constructions that might not be immediately apparent through the examination of the tabular results alone. These visualizations underscore the effectiveness of graphical representation as a tool for understanding linguistic shifts over time‚Äîan approach not employed in the original study.\n\n## References {.unnumbered}\n\n\n\n\n[1] S. T. Gries and N. C. Ellis. \"Statistical Measures for Usage-Based\nLinguistics\". In: _Language Learning_ 65.S1 (2015). _eprint:\nhttps://onlinelibrary.wiley.com/doi/pdf/10.1111/lang.12119, p. 228‚Äì255.\nISSN: 1467-9922. DOI: 10.1111/lang.12119.\n<https://onlinelibrary.wiley.com/doi/abs/10.1111/lang.12119>.\n\n[2] K. Pfadenhauer and E. Wiesinger, ed. _Romance motion verbs in\nlanguage change: Grammar, lexicon, discourse_. De Gruyter, Jul. 2024.\nISBN: 978-3-11-124814-1. DOI: 10.1515/9783111248141.\n<https://www.degruyter.com/document/doi/10.1515/9783111248141/html>.\n\n[3] A. Stefanowitsch and S. Flach. \"The corpus-based perspective on\nentrenchment\". In: _Entrenchment and the psychology of language\nlearning: How we reorganize and adapt linguistic knowledge_. Ed. by H.\nSchmid. De Gruyter, 2017, p. 101‚Äì127. ISBN: 978-3-11-034130-0\n978-3-11-034142-3. DOI: 10.1037/15969-006.\n<https://content.apa.org/books/15969-006>.\n\n[4] S. Van Hulle and R. Enghels. _Replication Data for: ‚ÄúThe category\nof throw verbs as productive source of the Spanish inchoative\nconstruction. DataverseNO, V1.‚Äù_. 2024. DOI: 10.18710/TR2PWJ.\n<https://dataverse.no/dataset.xhtml?persistentId=doi:10.18710/TR2PWJ>.\n\n[5] S. Van Hulle and R. Enghels. \"The category of throw verbs as\nproductive source of the Spanish inchoative construction\". In: _Romance\nmotion verbs in language change_. Ed. by K. Pfadenhauer and E.\nWiesinger. De Gruyter, Jul. 2024, p. 213‚Äì240. ISBN: 978-3-11-124814-1.\nDOI: 10.1515/9783111248141-009.\n<https://www.degruyter.com/document/doi/10.1515/9783111248141-009/html>.\n\n\n\n\n### Packages used in this chapter {.unnumbered}\n\n\n\n\n::: {.cell}\n::: {.cell-output .cell-output-stdout}\n\n```\nR version 4.4.1 (2024-06-14)\nPlatform: aarch64-apple-darwin20\nRunning under: macOS 15.1\n\nMatrix products: default\nBLAS:   /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRblas.0.dylib \nLAPACK: /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.0\n\nlocale:\n[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8\n\ntime zone: Europe/Brussels\ntzcode source: internal\n\nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods   base     \n\nother attached packages:\n [1] knitcitations_1.0.12 xfun_0.45            lubridate_1.9.3     \n [4] forcats_1.0.0        stringr_1.5.1        dplyr_1.1.4         \n [7] purrr_1.0.2          readr_2.1.5          tidyr_1.3.1         \n[10] tibble_3.2.1         ggplot2_3.5.1        tidyverse_2.0.0     \n[13] here_1.0.1           kableExtra_1.4.0     checkdown_0.0.12    \n[16] webexercises_1.1.0  \n\nloaded via a namespace (and not attached):\n [1] utf8_1.2.4        generics_0.1.3    xml2_1.3.6        stringi_1.8.4    \n [5] hms_1.1.3         digest_0.6.36     magrittr_2.0.3    timechange_0.3.0 \n [9] evaluate_0.24.0   grid_4.4.1        fastmap_1.2.0     plyr_1.8.9       \n[13] rprojroot_2.0.4   jsonlite_1.8.8    backports_1.5.0   httr_1.4.7       \n[17] fansi_1.0.6       viridisLite_0.4.2 scales_1.3.0      bibtex_0.5.1     \n[21] codetools_0.2-20  cli_3.6.3         rlang_1.1.4       munsell_0.5.1    \n[25] commonmark_1.9.1  withr_3.0.1       yaml_2.3.8        tools_4.4.1      \n[29] tzdb_0.4.0        colorspace_2.1-0  vctrs_0.6.5       R6_2.5.1         \n[33] lifecycle_1.0.4   RefManageR_1.4.0  htmlwidgets_1.6.4 pkgconfig_2.0.3  \n[37] pillar_1.9.0      gtable_0.3.5      Rcpp_1.0.12       glue_1.7.0       \n[41] systemfonts_1.1.0 tidyselect_1.2.1  rstudioapi_0.16.0 knitr_1.47       \n[45] farver_2.1.2      htmltools_0.5.8.1 labeling_0.4.3    rmarkdown_2.27   \n[49] svglite_2.1.3     compiler_4.4.1    markdown_1.13    \n```\n\n\n:::\n:::\n\n\n\n\n### Package references {.unnumbered}\n\n\n\n\n[1] G. Grolemund and H. Wickham. \"Dates and Times Made Easy with\nlubridate\". In: _Journal of Statistical Software_ 40.3 (2011), pp.\n1-25. <https://www.jstatsoft.org/v40/i03/>.\n\n[2] G. Moroz. _checkdown: Check-Fields and Check-Boxes for rmarkdown_.\nR package version 0.0.12. 2023.\n<https://agricolamz.github.io/checkdown/>.\n\n[3] G. Moroz. _Create check-fields and check-boxes with checkdown_.\n2020. <https://CRAN.R-project.org/package=checkdown>.\n\n[4] K. M√ºller. _here: A Simpler Way to Find Your Files_. R package\nversion 1.0.1. 2020. <https://here.r-lib.org/>.\n\n[5] K. M√ºller and H. Wickham. _tibble: Simple Data Frames_. R package\nversion 3.2.1. 2023. <https://tibble.tidyverse.org/>.\n\n[6] R Core Team. _R: A Language and Environment for Statistical\nComputing_. R Foundation for Statistical Computing. Vienna, Austria,\n2024. <https://www.R-project.org/>.\n\n[7] V. Spinu, G. Grolemund, and H. Wickham. _lubridate: Make Dealing\nwith Dates a Little Easier_. R package version 1.9.3. 2023.\n<https://lubridate.tidyverse.org>.\n\n[8] H. Wickham. _forcats: Tools for Working with Categorical Variables\n(Factors)_. R package version 1.0.0. 2023.\n<https://forcats.tidyverse.org/>.\n\n[9] H. Wickham. _ggplot2: Elegant Graphics for Data Analysis_.\nSpringer-Verlag New York, 2016. ISBN: 978-3-319-24277-4.\n<https://ggplot2.tidyverse.org>.\n\n[10] H. Wickham. _stringr: Simple, Consistent Wrappers for Common\nString Operations_. R package version 1.5.1. 2023.\n<https://stringr.tidyverse.org>.\n\n[11] H. Wickham. _tidyverse: Easily Install and Load the Tidyverse_. R\npackage version 2.0.0. 2023. <https://tidyverse.tidyverse.org>.\n\n[12] H. Wickham, M. Averick, J. Bryan, et al. \"Welcome to the\ntidyverse\". In: _Journal of Open Source Software_ 4.43 (2019), p. 1686.\nDOI: 10.21105/joss.01686.\n\n[13] H. Wickham, W. Chang, L. Henry, et al. _ggplot2: Create Elegant\nData Visualisations Using the Grammar of Graphics_. R package version\n3.5.1. 2024. <https://ggplot2.tidyverse.org>.\n\n[14] H. Wickham, R. Fran√ßois, L. Henry, et al. _dplyr: A Grammar of\nData Manipulation_. R package version 1.1.4. 2023.\n<https://dplyr.tidyverse.org>.\n\n[15] H. Wickham and L. Henry. _purrr: Functional Programming Tools_. R\npackage version 1.0.2. 2023. <https://purrr.tidyverse.org/>.\n\n[16] H. Wickham, J. Hester, and J. Bryan. _readr: Read Rectangular Text\nData_. R package version 2.1.5. 2024. <https://readr.tidyverse.org>.\n\n[17] H. Wickham, D. Vaughan, and M. Girlich. _tidyr: Tidy Messy Data_.\nR package version 1.3.1. 2024. <https://tidyr.tidyverse.org>.\n\n[18] Y. Xie. _Dynamic Documents with R and knitr_. 2nd. ISBN\n978-1498716963. Boca Raton, Florida: Chapman and Hall/CRC, 2015.\n<https://yihui.org/knitr/>.\n\n[19] Y. Xie. \"knitr: A Comprehensive Tool for Reproducible Research in\nR\". In: _Implementing Reproducible Computational Research_. Ed. by V.\nStodden, F. Leisch and R. D. Peng. ISBN 978-1466561595. Chapman and\nHall/CRC, 2014.\n\n[20] Y. Xie. _knitr: A General-Purpose Package for Dynamic Report\nGeneration in R_. R package version 1.47. 2024.\n<https://yihui.org/knitr/>.\n\n[21] Y. Xie. _xfun: Supporting Functions for Packages Maintained by\nYihui Xie_. R package version 0.45. 2024.\n<https://github.com/yihui/xfun>.\n\n[22] H. Zhu. _kableExtra: Construct Complex Table with kable and Pipe\nSyntax_. R package version 1.4.0. 2024.\n<http://haozhu233.github.io/kableExtra/>.\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}